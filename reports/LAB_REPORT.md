# ğŸ“Š ĞÑ‚Ñ‡Ñ‘Ñ‚: Ğ¢Ñ€ĞµĞºĞ¸Ğ½Ğ³ ML-ÑĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚Ğ¾Ğ²

**ĞŸÑ€Ğ¾ĞµĞºÑ‚:** Boston Housing Price Prediction  
**Ğ”Ğ°Ñ‚Ğ°:** 20 Ğ´ĞµĞºĞ°Ğ±Ñ€Ñ 2025  
**ĞĞ²Ñ‚Ğ¾Ñ€:** Ğ¡Ñ‚ÑƒĞ´ĞµĞ½Ñ‡ĞµÑĞºĞ¸Ğ¹ Ğ¿Ñ€Ğ¾ĞµĞºÑ‚ Ğ¿Ğ¾ IPML  

---

## ğŸ“‹ Ğ¡Ğ¾Ğ´ĞµÑ€Ğ¶Ğ°Ğ½Ğ¸Ğµ

1. [ĞĞ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ° Ğ²Ñ‹Ğ±Ñ€Ğ°Ğ½Ğ½Ğ¾Ğ³Ğ¾ Ğ¸Ğ½ÑÑ‚Ñ€ÑƒĞ¼ĞµĞ½Ñ‚Ğ° Ñ‚Ñ€ĞµĞºĞ¸Ğ½Ğ³Ğ°](#1-Ğ½Ğ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ°-Ğ²Ñ‹Ğ±Ñ€Ğ°Ğ½Ğ½Ğ¾Ğ³Ğ¾-Ğ¸Ğ½ÑÑ‚Ñ€ÑƒĞ¼ĞµĞ½Ñ‚Ğ°)
2. [ĞŸÑ€Ğ¾Ğ²ĞµĞ´ĞµĞ½Ğ¸Ğµ ÑĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚Ğ¾Ğ²](#2-Ğ¿Ñ€Ğ¾Ğ²ĞµĞ´ĞµĞ½Ğ¸Ğµ-ÑĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚Ğ¾Ğ²)
3. [Ğ˜Ğ½Ñ‚ĞµĞ³Ñ€Ğ°Ñ†Ğ¸Ñ Ñ ĞºĞ¾Ğ´Ğ¾Ğ¼](#3-Ğ¸Ğ½Ñ‚ĞµĞ³Ñ€Ğ°Ñ†Ğ¸Ñ-Ñ-ĞºĞ¾Ğ´Ğ¾Ğ¼)
4. [Ğ˜Ğ½ÑÑ‚Ñ€ÑƒĞºÑ†Ğ¸Ğ¸ Ğ¿Ğ¾ Ğ·Ğ°Ğ¿ÑƒÑĞºÑƒ](#4-Ğ¸Ğ½ÑÑ‚Ñ€ÑƒĞºÑ†Ğ¸Ğ¸-Ğ¿Ğ¾-Ğ·Ğ°Ğ¿ÑƒÑĞºÑƒ)
5. [ĞĞ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ° Ğ¸Ğ½ÑÑ‚Ñ€ÑƒĞ¼ĞµĞ½Ñ‚Ğ° Ğ¾Ñ€ĞºĞµÑÑ‚Ñ€Ğ°Ñ†Ğ¸Ğ¸](#5-Ğ½Ğ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ°-Ğ¸Ğ½ÑÑ‚Ñ€ÑƒĞ¼ĞµĞ½Ñ‚Ğ°-Ğ¾Ñ€ĞºĞµÑÑ‚Ñ€Ğ°Ñ†Ğ¸Ğ¸)
6. [ĞĞ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ° Ğ¸Ğ½ÑÑ‚Ñ€ÑƒĞ¼ĞµĞ½Ñ‚Ğ° ĞºĞ¾Ğ½Ñ„Ğ¸Ğ³ÑƒÑ€Ğ°Ñ†Ğ¸Ğ¹](#6-Ğ½Ğ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ°-Ğ¸Ğ½ÑÑ‚Ñ€ÑƒĞ¼ĞµĞ½Ñ‚Ğ°-ĞºĞ¾Ğ½Ñ„Ğ¸Ğ³ÑƒÑ€Ğ°Ñ†Ğ¸Ğ¹)
7. [Ğ˜Ğ½Ñ‚ĞµĞ³Ñ€Ğ°Ñ†Ğ¸Ñ Ğ¸ Ñ‚ĞµÑÑ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ ÑĞ¸ÑÑ‚ĞµĞ¼](#7-Ğ¸Ğ½Ñ‚ĞµĞ³Ñ€Ğ°Ñ†Ğ¸Ñ-Ğ¸-Ñ‚ĞµÑÑ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ-ÑĞ¸ÑÑ‚ĞµĞ¼)

---

## 1. ĞĞ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ° Ğ²Ñ‹Ğ±Ñ€Ğ°Ğ½Ğ½Ğ¾Ğ³Ğ¾ Ğ¸Ğ½ÑÑ‚Ñ€ÑƒĞ¼ĞµĞ½Ñ‚Ğ° Ñ‚Ñ€ĞµĞºĞ¸Ğ½Ğ³Ğ°

### 1.1 Ğ£ÑÑ‚Ğ°Ğ½Ğ¾Ğ²ĞºĞ° Ğ¸ Ğ½Ğ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ° Ğ²Ñ‹Ğ±Ñ€Ğ°Ğ½Ğ½Ğ¾Ğ³Ğ¾ Ğ¸Ğ½ÑÑ‚Ñ€ÑƒĞ¼ĞµĞ½Ñ‚Ğ° (MLflow)

**Ğ’Ñ‹Ğ±Ñ€Ğ°Ğ½Ğ½Ñ‹Ğ¹ ÑÑ‚ĞµĞº Ñ‚ĞµÑ…Ğ½Ğ¾Ğ»Ğ¾Ğ³Ğ¸Ğ¹:**

| Ğ˜Ğ½ÑÑ‚Ñ€ÑƒĞ¼ĞµĞ½Ñ‚ | Ğ’ĞµÑ€ÑĞ¸Ñ | ĞĞ°Ğ·Ğ½Ğ°Ñ‡ĞµĞ½Ğ¸Ğµ |
|------------|--------|------------|
| **MLflow** | 2.18.0+ | Ğ¢Ñ€ĞµĞºĞ¸Ğ½Ğ³ ÑĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚Ğ¾Ğ², Model Registry |
| **MinIO** | latest | S3-ÑĞ¾Ğ²Ğ¼ĞµÑÑ‚Ğ¸Ğ¼Ğ¾Ğµ Ñ…Ñ€Ğ°Ğ½Ğ¸Ğ»Ğ¸Ñ‰Ğµ Ğ°Ñ€Ñ‚ĞµÑ„Ğ°ĞºÑ‚Ğ¾Ğ² |
| **DVC** | 3.64.2+ | Ğ’ĞµÑ€ÑĞ¸Ğ¾Ğ½Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… |
| **Nginx** | alpine | Reverse proxy Ñ Basic Auth |
| **Docker** | â€” | ĞšĞ¾Ğ½Ñ‚ĞµĞ¹Ğ½ĞµÑ€Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ Ğ¸Ğ½Ñ„Ñ€Ğ°ÑÑ‚Ñ€ÑƒĞºÑ‚ÑƒÑ€Ñ‹ |

**Ğ£ÑÑ‚Ğ°Ğ½Ğ¾Ğ²ĞºĞ° Ğ·Ğ°Ğ²Ğ¸ÑĞ¸Ğ¼Ğ¾ÑÑ‚ĞµĞ¹:**

```bash
# Ğ§ĞµÑ€ĞµĞ· uv (Ğ¿Ğ°ĞºĞµÑ‚Ğ½Ñ‹Ğ¹ Ğ¼ĞµĞ½ĞµĞ´Ğ¶ĞµÑ€)
uv add mlflow boto3

# ĞĞ±Ğ½Ğ¾Ğ²Ğ»ĞµĞ½Ğ¸Ğµ pyproject.toml
```

**Ğ¤Ğ°Ğ¹Ğ» `pyproject.toml`:**

```toml
[project]
dependencies = [
    "mlflow>=2.18.0",
    "boto3>=1.35.0",
    "dvc[s3]>=3.64.2",
    # ... Ğ´Ñ€ÑƒĞ³Ğ¸Ğµ Ğ·Ğ°Ğ²Ğ¸ÑĞ¸Ğ¼Ğ¾ÑÑ‚Ğ¸
]
```

### 1.2 ĞĞ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ° Ğ±Ğ°Ğ·Ñ‹ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…/Ğ¾Ğ±Ğ»Ğ°Ñ‡Ğ½Ğ¾Ğ³Ğ¾ Ñ…Ñ€Ğ°Ğ½Ğ¸Ğ»Ğ¸Ñ‰Ğ° (MinIO)

**ĞÑ€Ñ…Ğ¸Ñ‚ĞµĞºÑ‚ÑƒÑ€Ğ° Ñ€ĞµÑˆĞµĞ½Ğ¸Ñ:**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        ML Experiment Lifecycle                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  ĞšĞ¾Ğ´/Ğ¡ĞºÑ€Ğ¸Ğ¿Ñ‚Ñ‹ â”‚â”€â”€â”€â–¶â”‚   MLflow     â”‚â”€â”€â”€â–¶â”‚      MinIO           â”‚   â”‚
â”‚  â”‚  Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ    â”‚    â”‚   Tracking   â”‚    â”‚  (Artifact Store)    â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚   Server     â”‚    â”‚                      â”‚   â”‚
â”‚                      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚   â”‚
â”‚                             â”‚            â”‚  â”‚ mlflow-artifactsâ”‚  â”‚   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚            â”‚  â”‚  â””â”€ models/     â”‚  â”‚   â”‚
â”‚  â”‚     DVC      â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚  â”‚  â””â”€ metrics/    â”‚  â”‚   â”‚
â”‚  â”‚  (Ğ’ĞµÑ€ÑĞ¸Ğ¸     â”‚           â”‚            â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚   â”‚
â”‚  â”‚   Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…)    â”‚           â”‚            â”‚                      â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚            â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚   â”‚
â”‚        â”‚                    â”‚            â”‚  â”‚boston-housing- â”‚  â”‚   â”‚
â”‚        â–¼                    â”‚            â”‚  â”‚     data       â”‚  â”‚   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚            â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚   â”‚
â”‚  â”‚     Git      â”‚â—€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚  â”‚  (.dvc Ñ„Ğ°Ğ¹Ğ»Ñ‹)â”‚                                                   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                                   â”‚
â”‚                                                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Docker-ĞºĞ¾Ğ½Ñ„Ğ¸Ğ³ÑƒÑ€Ğ°Ñ†Ğ¸Ñ MinIO (`docker/Dockerfile.minio`):**

```dockerfile
FROM minio/minio:latest

LABEL maintainer="Boston Housing ML Project"
LABEL description="MinIO storage Ğ´Ğ»Ñ Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ğ¸Ñ ML Ğ°Ñ€Ñ‚ĞµÑ„Ğ°ĞºÑ‚Ğ¾Ğ²"

ENV MINIO_ROOT_USER=minioadmin0
ENV MINIO_ROOT_PASSWORD=minioadmin1230
ENV MINIO_CONSOLE_ADDRESS=":9001"

EXPOSE 9000 9001
VOLUME ["/data"]

HEALTHCHECK --interval=30s --timeout=20s --start-period=10s --retries=3 \
    CMD curl -f http://localhost:9000/minio/health/live || exit 1

CMD ["server", "/data", "--console-address", ":9001"]
```

**Ğ‘Ğ°ĞºĞµÑ‚Ñ‹ Ğ² MinIO:**

| Ğ‘Ğ°ĞºĞµÑ‚ | ĞĞ°Ğ·Ğ½Ğ°Ñ‡ĞµĞ½Ğ¸Ğµ |
|-------|------------|
| `boston-housing-data` | Ğ”Ğ°Ğ½Ğ½Ñ‹Ğµ Ğ¸ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ (DVC) |
| `mlflow-artifacts` | ĞÑ€Ñ‚ĞµÑ„Ğ°ĞºÑ‚Ñ‹ MLflow (Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸, Ğ¼ĞµÑ‚Ñ€Ğ¸ĞºĞ¸, Ğ³Ñ€Ğ°Ñ„Ğ¸ĞºĞ¸) |

**Ğ¡ĞºÑ€Ğ¸Ğ½ÑˆĞ¾Ñ‚ MinIO Object Browser:**

![MinIO Object Browser](figures/minio.png)

*Ğ Ğ¸Ñ. 1: Ğ’ĞµĞ±-ĞºĞ¾Ğ½ÑĞ¾Ğ»ÑŒ MinIO Ñ Ğ±Ğ°ĞºĞµÑ‚Ğ°Ğ¼Ğ¸ Ğ´Ğ»Ñ Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ğ¸Ñ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… DVC Ğ¸ Ğ°Ñ€Ñ‚ĞµÑ„Ğ°ĞºÑ‚Ğ¾Ğ² MLflow*

### 1.3 Ğ¡Ğ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ğµ Ğ¿Ñ€Ğ¾ĞµĞºÑ‚Ğ° Ğ¸ ÑĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚Ğ¾Ğ²

**Ğ—Ğ°Ğ¿ÑƒÑĞº Ğ¸Ğ½Ñ„Ñ€Ğ°ÑÑ‚Ñ€ÑƒĞºÑ‚ÑƒÑ€Ñ‹:**s

```bash
# Ğ—Ğ°Ğ¿ÑƒÑĞº MinIO Ğ¸ MLflow
docker-compose up -d minio mlflow nginx

# Ğ¡Ğ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ğµ Ğ±Ğ°ĞºĞµÑ‚Ğ¾Ğ²
mc alias set local http://localhost:9000 minioadmin0 minioadmin1230
mc mb local/boston-housing-data
mc mb local/mlflow-artifacts
```

**Ğ¡Ğ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ğµ ÑĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚Ğ° Ğ² MLflow:**

```python
import mlflow

mlflow.set_tracking_uri("http://localhost:5000")
mlflow.set_experiment("boston-housing")
```

### 1.4 ĞĞ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ° Ğ°ÑƒÑ‚ĞµĞ½Ñ‚Ğ¸Ñ„Ğ¸ĞºĞ°Ñ†Ğ¸Ğ¸ Ğ¸ Ğ´Ğ¾ÑÑ‚ÑƒĞ¿Ğ°

Ğ ĞµĞ°Ğ»Ğ¸Ğ·Ğ¾Ğ²Ğ°Ğ½Ğ° **Ğ´Ğ²ÑƒÑ…ÑƒÑ€Ğ¾Ğ²Ğ½ĞµĞ²Ğ°Ñ Ğ°ÑƒÑ‚ĞµĞ½Ñ‚Ğ¸Ñ„Ğ¸ĞºĞ°Ñ†Ğ¸Ñ**:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    ĞÑ€Ñ…Ğ¸Ñ‚ĞµĞºÑ‚ÑƒÑ€Ğ° Ğ°ÑƒÑ‚ĞµĞ½Ñ‚Ğ¸Ñ„Ğ¸ĞºĞ°Ñ†Ğ¸Ğ¸                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                                    â”‚
â”‚  â”‚   Ğ‘Ñ€Ğ°ÑƒĞ·ĞµÑ€    â”‚â”€â”€â”€â”€â”€â”                                              â”‚
â”‚  â”‚   (UI)       â”‚     â”‚                                              â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚                                              â”‚
â”‚                       â–¼                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                     â”‚
â”‚  â”‚ Python SDK   â”‚   â”‚     Nginx (Ğ¿Ğ¾Ñ€Ñ‚ 5000)    â”‚                     â”‚
â”‚  â”‚ (mlflow.*)   â”‚â”€â”€â–¶â”‚   Basic Auth (htpasswd)  â”‚                     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                     â”‚
â”‚        â”‚                        â”‚                                    â”‚
â”‚        â”‚                        â–¼                                    â”‚
â”‚        â”‚            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                     â”‚
â”‚        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚  MLflow Server (Ğ²Ğ½ÑƒÑ‚Ñ€.)  â”‚                     â”‚
â”‚                     â”‚   Basic Auth (built-in)  â”‚                     â”‚
â”‚                     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                     â”‚
â”‚                                 â”‚                                    â”‚
â”‚                                 â–¼                                    â”‚
â”‚                     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                     â”‚
â”‚                     â”‚    MinIO (S3 Ğ°Ñ€Ñ‚ĞµÑ„Ğ°ĞºÑ‚Ñ‹)  â”‚                     â”‚
â”‚                     â”‚    Access Key + Secret   â”‚                     â”‚
â”‚                     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                     â”‚
â”‚                                                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Ğ£Ñ€Ğ¾Ğ²Ğ½Ğ¸ Ğ·Ğ°Ñ‰Ğ¸Ñ‚Ñ‹:**

| Ğ£Ñ€Ğ¾Ğ²ĞµĞ½ÑŒ | ĞšĞ¾Ğ¼Ğ¿Ğ¾Ğ½ĞµĞ½Ñ‚ | ĞœĞµÑ‚Ğ¾Ğ´ Ğ·Ğ°Ñ‰Ğ¸Ñ‚Ñ‹ |
|---------|-----------|--------------|
| 1 | MinIO (S3) | Access Key + Secret Key |
| 2 | Nginx (UI/Ğ±Ñ€Ğ°ÑƒĞ·ĞµÑ€) | Basic Auth (htpasswd) |
| 3 | MLflow (API/SDK) | Basic Auth (Ğ²ÑÑ‚Ñ€Ğ¾ĞµĞ½Ğ½Ñ‹Ğ¹) |

**ĞšĞ¾Ğ½Ñ„Ğ¸Ğ³ÑƒÑ€Ğ°Ñ†Ğ¸Ñ `.env`:**

```bash
# MinIO
MINIO_ROOT_USER=minioadmin0
MINIO_ROOT_PASSWORD=minioadmin1230

# MLflow Admin
MLFLOW_ADMIN_USERNAME=admin
MLFLOW_ADMIN_PASSWORD=secure_password_123

# MLflow Tracking (Ğ´Ğ»Ñ Python SDK)
MLFLOW_TRACKING_URI=http://localhost:5000
MLFLOW_TRACKING_USERNAME=admin
MLFLOW_TRACKING_PASSWORD=secure_password_123

# S3/MinIO Ğ´Ğ»Ñ Ğ°Ñ€Ñ‚ĞµÑ„Ğ°ĞºÑ‚Ğ¾Ğ²
MLFLOW_S3_ENDPOINT_URL=http://localhost:9000
AWS_ACCESS_KEY_ID=minioadmin0
AWS_SECRET_ACCESS_KEY=minioadmin1230
```

**Ğ”Ğ¾ÑÑ‚ÑƒĞ¿ Ğº ÑĞµÑ€Ğ²Ğ¸ÑĞ°Ğ¼:**

| Ğ¡ĞµÑ€Ğ²Ğ¸Ñ | URL | ĞĞ¿Ğ¸ÑĞ°Ğ½Ğ¸Ğµ |
|--------|-----|----------|
| MLflow UI | http://localhost:5000 | Ğ’ĞµĞ±-Ğ¸Ğ½Ñ‚ĞµÑ€Ñ„ĞµĞ¹Ñ MLflow |
| MinIO Console | http://localhost:9001 | Ğ£Ğ¿Ñ€Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ğµ Ñ…Ñ€Ğ°Ğ½Ğ¸Ğ»Ğ¸Ñ‰ĞµĞ¼ |
| MinIO S3 API | http://localhost:9000 | S3 API Ğ´Ğ»Ñ Ğ°Ñ€Ñ‚ĞµÑ„Ğ°ĞºÑ‚Ğ¾Ğ² |

---

## 2. ĞŸÑ€Ğ¾Ğ²ĞµĞ´ĞµĞ½Ğ¸Ğµ ÑĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚Ğ¾Ğ²

### 2.1 ĞŸÑ€Ğ¾Ğ²ĞµĞ´ĞµĞ½Ğ¸Ğµ 15+ ÑĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚Ğ¾Ğ² Ñ Ñ€Ğ°Ğ·Ğ½Ñ‹Ğ¼Ğ¸ Ğ°Ğ»Ğ³Ğ¾Ñ€Ğ¸Ñ‚Ğ¼Ğ°Ğ¼Ğ¸

ĞŸÑ€Ğ¾Ğ²ĞµĞ´ĞµĞ½Ñ‹ ÑĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚Ñ‹ Ñ Ñ€Ğ°Ğ·Ğ»Ğ¸Ñ‡Ğ½Ñ‹Ğ¼Ğ¸ Ğ°Ğ»Ğ³Ğ¾Ñ€Ğ¸Ñ‚Ğ¼Ğ°Ğ¼Ğ¸ Ğ¼Ğ°ÑˆĞ¸Ğ½Ğ½Ğ¾Ğ³Ğ¾ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ:

| # | ĞĞ»Ğ³Ğ¾Ñ€Ğ¸Ñ‚Ğ¼ | ĞŸĞ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ñ‹ | RÂ² Score | RMSE |
|---|----------|-----------|----------|------|
| 1 | Random Forest | n=100, d=10 | 0.8512 | 3.30 |
| 2 | Random Forest | n=200, d=15 | 0.8665 | 3.13 |
| 3 | Random Forest | n=50, d=5 | 0.8234 | 3.60 |
| 4 | Random Forest | n=300, d=20 | 0.8701 | 3.08 |
| 5 | Gradient Boosting | n=100, d=5 | 0.8543 | 3.27 |
| 6 | Gradient Boosting | n=200, d=10 | 0.8712 | 3.07 |
| 7 | Ridge Regression | alpha=1.0 | 0.7234 | 4.50 |
| 8 | Lasso Regression | alpha=0.1 | 0.7156 | 4.57 |
| 9 | ElasticNet | alpha=0.5, l1_ratio=0.5 | 0.7089 | 4.62 |
| 10 | SVR | C=1.0, kernel=rbf | 0.7823 | 3.99 |
| 11 | KNN | n_neighbors=5 | 0.6512 | 5.05 |
| 12 | Decision Tree | d=10 | 0.7456 | 4.32 |
| 13 | AdaBoost | n=100 | 0.8123 | 3.71 |
| 14 | Bagging | n=50 | 0.8345 | 3.48 |
| 15 | Extra Trees | n=200, d=15 | 0.8623 | 3.18 |
| 16 | Huber Regressor | epsilon=1.35 | 0.7012 | 4.68 |

**Ğ¡ĞºÑ€Ğ¸Ğ½ÑˆĞ¾Ñ‚ Ğ³Ñ€ÑƒĞ¿Ğ¿Ğ¸Ñ€Ğ¾Ğ²ĞºĞ¸ ÑĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚Ğ¾Ğ²:**

![Groups](figures/groups.png)

*Ğ Ğ¸Ñ. 2: Ğ“Ñ€ÑƒĞ¿Ğ¿Ğ¸Ñ€Ğ¾Ğ²ĞºĞ° ÑĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚Ğ¾Ğ² Ğ² MLflow UI*

### 2.2 ĞĞ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ° Ğ»Ğ¾Ğ³Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ Ğ¼ĞµÑ‚Ñ€Ğ¸Ğº, Ğ¿Ğ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ğ¾Ğ² Ğ¸ Ğ°Ñ€Ñ‚ĞµÑ„Ğ°ĞºÑ‚Ğ¾Ğ²

**Ğ›Ğ¾Ğ³Ğ¸Ñ€ÑƒĞµĞ¼Ñ‹Ğµ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ:**

| Ğ¢Ğ¸Ğ¿ | ĞŸÑ€Ğ¸Ğ¼ĞµÑ€Ñ‹ |
|-----|---------|
| **ĞŸĞ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ñ‹** | `n_estimators`, `max_depth`, `learning_rate`, `test_size` |
| **ĞœĞµÑ‚Ñ€Ğ¸ĞºĞ¸** | `r2_score`, `rmse`, `mae`, `mape` |
| **ĞÑ€Ñ‚ĞµÑ„Ğ°ĞºÑ‚Ñ‹** | ĞœĞ¾Ğ´ĞµĞ»Ğ¸ (`.pkl`), Ğ³Ñ€Ğ°Ñ„Ğ¸ĞºĞ¸ Ğ²Ğ°Ğ¶Ğ½Ğ¾ÑÑ‚Ğ¸ Ğ¿Ñ€Ğ¸Ğ·Ğ½Ğ°ĞºĞ¾Ğ², CSV Ñ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ğ°Ğ¼Ğ¸ |
| **Ğ¢ĞµĞ³Ğ¸** | `model_type`, `framework`, `dataset` |

**ĞŸÑ€Ğ¸Ğ¼ĞµÑ€ Ğ»Ğ¾Ğ³Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ:**

```python
import mlflow

with mlflow.start_run(run_name="rf-baseline"):
    # ĞŸĞ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ñ‹
    mlflow.log_params({
        "n_estimators": 200,
        "max_depth": 15,
        "min_samples_split": 5,
    })

    # ĞœĞµÑ‚Ñ€Ğ¸ĞºĞ¸
    mlflow.log_metrics({
        "r2_score": 0.8665,
        "rmse": 3.13,
        "mae": 2.09,
    })

    # ĞÑ€Ñ‚ĞµÑ„Ğ°ĞºÑ‚Ñ‹
    mlflow.sklearn.log_model(model, "model")
    mlflow.log_artifact("feature_importance.csv")

    # Ğ¢ĞµĞ³Ğ¸
    mlflow.set_tags({
        "model_type": "RandomForest",
        "framework": "sklearn",
    })
```

**Ğ¡ĞºÑ€Ğ¸Ğ½ÑˆĞ¾Ñ‚ Ğ¼ĞµÑ‚Ñ€Ğ¸ĞºĞ¸ RÂ² Score:**

![R2 Score](figures/r2_score.png)

*Ğ Ğ¸Ñ. 3: Ğ¡Ñ€Ğ°Ğ²Ğ½ĞµĞ½Ğ¸Ğµ Ğ¼ĞµÑ‚Ñ€Ğ¸ĞºĞ¸ RÂ² Score Ğ´Ğ»Ñ Ñ€Ğ°Ğ·Ğ»Ğ¸Ñ‡Ğ½Ñ‹Ñ… ÑĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚Ğ¾Ğ²*

**Ğ¡ĞºÑ€Ğ¸Ğ½ÑˆĞ¾Ñ‚ Ğ²Ñ€ĞµĞ¼ĞµĞ½Ğ¸ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ:**

![Train Time](figures/train_time_seconds.png)

*Ğ Ğ¸Ñ. 4: Ğ’Ñ€ĞµĞ¼Ñ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ Ğ² ÑĞµĞºÑƒĞ½Ğ´Ğ°Ñ…*

### 2.3 Ğ¡Ğ¸ÑÑ‚ĞµĞ¼Ğ° ÑÑ€Ğ°Ğ²Ğ½ĞµĞ½Ğ¸Ñ ÑĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚Ğ¾Ğ²

MLflow Ğ¿Ñ€ĞµĞ´Ğ¾ÑÑ‚Ğ°Ğ²Ğ»ÑĞµÑ‚ Ğ¼Ğ¾Ñ‰Ğ½Ñ‹Ğµ Ğ¸Ğ½ÑÑ‚Ñ€ÑƒĞ¼ĞµĞ½Ñ‚Ñ‹ Ğ´Ğ»Ñ ÑÑ€Ğ°Ğ²Ğ½ĞµĞ½Ğ¸Ñ:

**Ğ§ĞµÑ€ĞµĞ· UI:**
- Ğ¢Ğ°Ğ±Ğ»Ğ¸Ñ†Ğ° ÑĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚Ğ¾Ğ² Ñ ÑĞ¾Ñ€Ñ‚Ğ¸Ñ€Ğ¾Ğ²ĞºĞ¾Ğ¹ Ğ¿Ğ¾ Ğ¼ĞµÑ‚Ñ€Ğ¸ĞºĞ°Ğ¼
- Ğ“Ñ€Ğ°Ñ„Ğ¸ĞºĞ¸ ÑÑ€Ğ°Ğ²Ğ½ĞµĞ½Ğ¸Ñ (Parallel Coordinates, Scatter Plot)
- Ğ’Ğ¸Ğ·ÑƒĞ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ Ğ¸Ğ·Ğ¼ĞµĞ½ĞµĞ½Ğ¸Ñ Ğ¼ĞµÑ‚Ñ€Ğ¸Ğº Ğ¿Ğ¾ Ğ²Ñ€ĞµĞ¼ĞµĞ½Ğ¸

**Ğ§ĞµÑ€ĞµĞ· API:**

```python
from mlflow.tracking import MlflowClient

client = MlflowClient()

# ĞŸĞ¾Ğ»ÑƒÑ‡ĞµĞ½Ğ¸Ğµ Ñ‚Ğ¾Ğ¿-10 Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ Ğ¿Ğ¾ RÂ² Score
runs = client.search_runs(
    experiment_ids=["1"],
    order_by=["metrics.r2_score DESC"],
    max_results=10,
)

for run in runs:
    r2 = run.data.metrics.get("r2_score", 0)
    params = run.data.params
    print(f"Run {run.info.run_id[:8]}: RÂ²={r2:.4f}")
```

**Ğ§ĞµÑ€ĞµĞ· CLI:**

```bash
# Ğ¡Ğ¿Ğ¸ÑĞ¾Ğº ÑĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚Ğ¾Ğ²
mlflow experiments search

# ĞŸĞ¾Ğ¸ÑĞº Ğ·Ğ°Ğ¿ÑƒÑĞºĞ¾Ğ² Ñ Ñ„Ğ¸Ğ»ÑŒÑ‚Ñ€Ğ°Ñ†Ğ¸ĞµĞ¹
mlflow runs list --experiment-id 1

# Ğ¡Ñ€Ğ°Ğ²Ğ½ĞµĞ½Ğ¸Ğµ Ğ´Ğ²ÑƒÑ… Ğ·Ğ°Ğ¿ÑƒÑĞºĞ¾Ğ²
mlflow runs compare <run_id_1> <run_id_2>
```

### 2.4 Ğ¤Ğ¸Ğ»ÑŒÑ‚Ñ€Ğ°Ñ†Ğ¸Ñ Ğ¸ Ğ¿Ğ¾Ğ¸ÑĞº ÑĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚Ğ¾Ğ²

**Ğ’Ğ¾Ğ·Ğ¼Ğ¾Ğ¶Ğ½Ğ¾ÑÑ‚Ğ¸ Ñ„Ğ¸Ğ»ÑŒÑ‚Ñ€Ğ°Ñ†Ğ¸Ğ¸ Ğ² MLflow:**

```python
# ĞŸĞ¾Ğ¸ÑĞº Ğ¿Ğ¾ Ğ¼ĞµÑ‚Ñ€Ğ¸ĞºĞ°Ğ¼
runs = client.search_runs(
    experiment_ids=["1"],
    filter_string="metrics.r2_score > 0.85",
)

# ĞŸĞ¾Ğ¸ÑĞº Ğ¿Ğ¾ Ğ¿Ğ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ğ°Ğ¼
runs = client.search_runs(
    experiment_ids=["1"],
    filter_string="params.n_estimators = '200'",
)

# ĞŸĞ¾Ğ¸ÑĞº Ğ¿Ğ¾ Ñ‚ĞµĞ³Ğ°Ğ¼
runs = client.search_runs(
    experiment_ids=["1"],
    filter_string="tags.model_type = 'RandomForest'",
)

# ĞšĞ¾Ğ¼Ğ±Ğ¸Ğ½Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ğ¹ Ğ¿Ğ¾Ğ¸ÑĞº
runs = client.search_runs(
    experiment_ids=["1"],
    filter_string="""
        metrics.r2_score > 0.80
        AND params.max_depth != 'None'
        AND tags.framework = 'sklearn'
    """,
    order_by=["metrics.rmse ASC"],
)
```

**Ğ¡ĞºÑ€Ğ¸Ğ½ÑˆĞ¾Ñ‚ Ñ„Ğ¸Ğ»ÑŒÑ‚Ñ€Ğ°Ñ†Ğ¸Ğ¸ ÑĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚Ğ¾Ğ²:**

![Filters](figures/filters.png)

*Ğ Ğ¸Ñ. 5: Ğ˜Ğ½Ñ‚ĞµÑ€Ñ„ĞµĞ¹Ñ Ñ„Ğ¸Ğ»ÑŒÑ‚Ñ€Ğ°Ñ†Ğ¸Ğ¸ Ğ¸ Ğ¿Ğ¾Ğ¸ÑĞºĞ° ÑĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚Ğ¾Ğ² Ğ² MLflow UI*

---

## 3. Ğ˜Ğ½Ñ‚ĞµĞ³Ñ€Ğ°Ñ†Ğ¸Ñ Ñ ĞºĞ¾Ğ´Ğ¾Ğ¼

### 3.1 Ğ˜Ğ½Ñ‚ĞµĞ³Ñ€Ğ°Ñ†Ğ¸Ñ MLflow Ğ² Python ĞºĞ¾Ğ´

**ĞœĞ¾Ğ´ÑƒĞ»ÑŒ ĞºĞ¾Ğ½Ñ„Ğ¸Ğ³ÑƒÑ€Ğ°Ñ†Ğ¸Ğ¸ `src/config/mlflow_config.py`:**

```python
"""ĞšĞ¾Ğ½Ñ„Ğ¸Ğ³ÑƒÑ€Ğ°Ñ†Ğ¸Ñ MLflow Ğ´Ğ»Ñ Ğ¿Ñ€Ğ¾ĞµĞºÑ‚Ğ°."""

import os

# MLflow Tracking
MLFLOW_TRACKING_URI = os.getenv("MLFLOW_TRACKING_URI", "http://localhost:5000")
MLFLOW_EXPERIMENT_NAME = os.getenv("MLFLOW_EXPERIMENT_NAME", "boston-housing")

# MinIO/S3 Ğ´Ğ»Ñ Ğ°Ñ€Ñ‚ĞµÑ„Ğ°ĞºÑ‚Ğ¾Ğ²
MLFLOW_S3_ENDPOINT_URL = os.getenv("MLFLOW_S3_ENDPOINT_URL", "http://localhost:9000")
AWS_ACCESS_KEY_ID = os.getenv("AWS_ACCESS_KEY_ID", "minioadmin0")
AWS_SECRET_ACCESS_KEY = os.getenv("AWS_SECRET_ACCESS_KEY", "minioadmin1230")


def setup_mlflow_env():
    """ĞĞ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ° Ğ¿ĞµÑ€ĞµĞ¼ĞµĞ½Ğ½Ñ‹Ñ… Ğ¾ĞºÑ€ÑƒĞ¶ĞµĞ½Ğ¸Ñ Ğ´Ğ»Ñ MLflow + S3."""
    os.environ["MLFLOW_S3_ENDPOINT_URL"] = MLFLOW_S3_ENDPOINT_URL
    os.environ["AWS_ACCESS_KEY_ID"] = AWS_ACCESS_KEY_ID
    os.environ["AWS_SECRET_ACCESS_KEY"] = AWS_SECRET_ACCESS_KEY
```

### 3.2 Ğ”ĞµĞºĞ¾Ñ€Ğ°Ñ‚Ğ¾Ñ€Ñ‹ Ğ´Ğ»Ñ Ğ°Ğ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¾Ğ³Ğ¾ Ğ»Ğ¾Ğ³Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ

**ĞœĞ¾Ğ´ÑƒĞ»ÑŒ `src/tracking/decorators.py`:**

```python
"""Ğ”ĞµĞºĞ¾Ñ€Ğ°Ñ‚Ğ¾Ñ€Ñ‹ Ğ´Ğ»Ñ Ğ°Ğ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¾Ğ³Ğ¾ Ğ»Ğ¾Ğ³Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ Ğ² MLflow."""

import functools
import time
from typing import Any, Callable

import mlflow
from loguru import logger


def mlflow_run(
    experiment_name: str = "boston-housing",
    run_name: str | None = None,
    tags: dict | None = None,
):
    """
    Ğ”ĞµĞºĞ¾Ñ€Ğ°Ñ‚Ğ¾Ñ€ Ğ´Ğ»Ñ Ğ°Ğ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¾Ğ³Ğ¾ ÑĞ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ñ MLflow run.

    ĞŸÑ€Ğ¸Ğ¼ĞµÑ€ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ:
        @mlflow_run(experiment_name="my-exp", run_name="baseline")
        def train_model(params):
            ...
    """
    def decorator(func: Callable) -> Callable:
        @functools.wraps(func)
        def wrapper(*args, **kwargs) -> Any:
            mlflow.set_experiment(experiment_name)

            with mlflow.start_run(run_name=run_name, tags=tags):
                # Ğ›Ğ¾Ğ³Ğ¸Ñ€ÑƒĞµĞ¼ Ğ²Ñ€ĞµĞ¼Ñ Ğ½Ğ°Ñ‡Ğ°Ğ»Ğ°
                start_time = time.time()
                mlflow.log_param("start_time", start_time)

                # Ğ’Ñ‹Ğ¿Ğ¾Ğ»Ğ½ÑĞµĞ¼ Ñ„ÑƒĞ½ĞºÑ†Ğ¸Ñ
                result = func(*args, **kwargs)

                # Ğ›Ğ¾Ğ³Ğ¸Ñ€ÑƒĞµĞ¼ Ğ²Ñ€ĞµĞ¼Ñ Ğ²Ñ‹Ğ¿Ğ¾Ğ»Ğ½ĞµĞ½Ğ¸Ñ
                duration = time.time() - start_time
                mlflow.log_metric("duration_seconds", duration)

                logger.info(f"Ğ­ĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚ Ğ·Ğ°Ğ²ĞµÑ€ÑˆÑ‘Ğ½ Ğ·Ğ° {duration:.2f}Ñ")
                return result

        return wrapper
    return decorator


def log_params_decorator(func: Callable) -> Callable:
    """
    Ğ”ĞµĞºĞ¾Ñ€Ğ°Ñ‚Ğ¾Ñ€ Ğ´Ğ»Ñ Ğ°Ğ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¾Ğ³Ğ¾ Ğ»Ğ¾Ğ³Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ Ğ¿Ğ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ğ¾Ğ² Ñ„ÑƒĞ½ĞºÑ†Ğ¸Ğ¸.

    ĞŸÑ€Ğ¸Ğ¼ĞµÑ€:
        @log_params_decorator
        def train(n_estimators=100, max_depth=10):
            ...
    """
    @functools.wraps(func)
    def wrapper(*args, **kwargs) -> Any:
        # Ğ›Ğ¾Ğ³Ğ¸Ñ€ÑƒĞµĞ¼ Ğ²ÑĞµ kwargs ĞºĞ°Ğº Ğ¿Ğ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ñ‹
        if kwargs:
            mlflow.log_params(kwargs)
        return func(*args, **kwargs)
    return wrapper


def log_metrics_decorator(metric_keys: list[str]):
    """
    Ğ”ĞµĞºĞ¾Ñ€Ğ°Ñ‚Ğ¾Ñ€ Ğ´Ğ»Ñ Ğ°Ğ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¾Ğ³Ğ¾ Ğ»Ğ¾Ğ³Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ Ğ¼ĞµÑ‚Ñ€Ğ¸Ğº Ğ¸Ğ· Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ğ°.

    ĞŸÑ€Ğ¸Ğ¼ĞµÑ€:
        @log_metrics_decorator(["r2_score", "rmse"])
        def evaluate(model, X, y) -> dict:
            return {"r2_score": 0.85, "rmse": 3.2}
    """
    def decorator(func: Callable) -> Callable:
        @functools.wraps(func)
        def wrapper(*args, **kwargs) -> dict:
            result = func(*args, **kwargs)

            if isinstance(result, dict):
                metrics_to_log = {
                    k: v for k, v in result.items()
                    if k in metric_keys and isinstance(v, (int, float))
                }
                if metrics_to_log:
                    mlflow.log_metrics(metrics_to_log)

            return result
        return wrapper
    return decorator
```

**ĞŸÑ€Ğ¸Ğ¼ĞµÑ€ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ Ğ´ĞµĞºĞ¾Ñ€Ğ°Ñ‚Ğ¾Ñ€Ğ¾Ğ²:**

```python
from src.tracking.decorators import mlflow_run, log_params_decorator, log_metrics_decorator

@mlflow_run(experiment_name="boston-housing", run_name="rf-experiment")
@log_params_decorator
def train_model(n_estimators=100, max_depth=10, **params):
    model = RandomForestRegressor(n_estimators=n_estimators, max_depth=max_depth)
    model.fit(X_train, y_train)
    return model

@log_metrics_decorator(["r2_score", "rmse", "mae"])
def evaluate_model(model, X_test, y_test) -> dict:
    y_pred = model.predict(X_test)
    return {
        "r2_score": r2_score(y_test, y_pred),
        "rmse": np.sqrt(mean_squared_error(y_test, y_pred)),
        "mae": mean_absolute_error(y_test, y_pred),
    }

# Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ
model = train_model(n_estimators=200, max_depth=15)
metrics = evaluate_model(model, X_test, y_test)
```

### 3.3 ĞšĞ¾Ğ½Ñ‚ĞµĞºÑÑ‚Ğ½Ñ‹Ğµ Ğ¼ĞµĞ½ĞµĞ´Ğ¶ĞµÑ€Ñ‹

**ĞœĞ¾Ğ´ÑƒĞ»ÑŒ `src/tracking/mlflow_tracker.py`:**

```python
"""MLflow Ñ‚Ñ€ĞµĞºĞµÑ€ Ñ Ğ¿Ğ¾Ğ´Ğ´ĞµÑ€Ğ¶ĞºĞ¾Ğ¹ ĞºĞ¾Ğ½Ñ‚ĞµĞºÑÑ‚Ğ½Ğ¾Ğ³Ğ¾ Ğ¼ĞµĞ½ĞµĞ´Ğ¶ĞµÑ€Ğ°."""

from typing import Any
from pathlib import Path

import mlflow
from mlflow.models.signature import infer_signature
from loguru import logger

from src.config.mlflow_config import (
    MLFLOW_TRACKING_URI,
    MLFLOW_EXPERIMENT_NAME,
    setup_mlflow_env,
)


class MLflowExperimentTracker:
    """ĞšĞ¾Ğ½Ñ‚ĞµĞºÑÑ‚Ğ½Ñ‹Ğ¹ Ğ¼ĞµĞ½ĞµĞ´Ğ¶ĞµÑ€ Ğ´Ğ»Ñ Ñ‚Ñ€ĞµĞºĞ¸Ğ½Ğ³Ğ° ML ÑĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚Ğ¾Ğ²."""

    def __init__(
        self,
        experiment_name: str = MLFLOW_EXPERIMENT_NAME,
        tracking_uri: str = MLFLOW_TRACKING_URI,
    ):
        setup_mlflow_env()
        mlflow.set_tracking_uri(tracking_uri)
        mlflow.set_experiment(experiment_name)

        self.experiment_name = experiment_name
        self.run = None
        logger.info(f"MLflow Ñ‚Ñ€ĞµĞºĞµÑ€: {tracking_uri}, ÑĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚: {experiment_name}")

    def start_run(self, run_name: str | None = None, tags: dict | None = None):
        """ĞĞ°Ñ‡Ğ°Ğ»Ğ¾ Ğ½Ğ¾Ğ²Ğ¾Ğ³Ğ¾ Ğ·Ğ°Ğ¿ÑƒÑĞºĞ° ÑĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚Ğ°."""
        self.run = mlflow.start_run(run_name=run_name, tags=tags)
        logger.info(f"Ğ—Ğ°Ğ¿ÑƒÑ‰ĞµĞ½ run: {self.run.info.run_id}")
        return self

    def __enter__(self):
        """ĞŸĞ¾Ğ´Ğ´ĞµÑ€Ğ¶ĞºĞ° ĞºĞ¾Ğ½Ñ‚ĞµĞºÑÑ‚Ğ½Ğ¾Ğ³Ğ¾ Ğ¼ĞµĞ½ĞµĞ´Ğ¶ĞµÑ€Ğ°."""
        if self.run is None:
            self.start_run()
        return self

    def __exit__(self, exc_type, exc_val, exc_tb):
        """Ğ—Ğ°Ğ²ĞµÑ€ÑˆĞµĞ½Ğ¸Ğµ ÑĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚Ğ°."""
        mlflow.end_run()
        self.run = None

    def log_params(self, params: dict[str, Any]):
        """Ğ›Ğ¾Ğ³Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ¿Ğ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ğ¾Ğ²."""
        mlflow.log_params(params)

    def log_metrics(self, metrics: dict[str, float], step: int | None = None):
        """Ğ›Ğ¾Ğ³Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ¼ĞµÑ‚Ñ€Ğ¸Ğº."""
        mlflow.log_metrics(metrics, step=step)

    def log_artifact(self, local_path: str | Path, artifact_path: str | None = None):
        """Ğ›Ğ¾Ğ³Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ°Ñ€Ñ‚ĞµÑ„Ğ°ĞºÑ‚Ğ°."""
        mlflow.log_artifact(str(local_path), artifact_path)

    def log_model(self, model, artifact_path: str, input_example=None,
                  registered_model_name: str | None = None):
        """Ğ›Ğ¾Ğ³Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ sklearn Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸."""
        signature = None
        if input_example is not None:
            predictions = model.predict(input_example)
            signature = infer_signature(input_example, predictions)

        mlflow.sklearn.log_model(
            model, artifact_path,
            signature=signature,
            input_example=input_example,
            registered_model_name=registered_model_name,
        )

    def set_tags(self, tags: dict[str, str]):
        """Ğ£ÑÑ‚Ğ°Ğ½Ğ¾Ğ²ĞºĞ° Ñ‚ĞµĞ³Ğ¾Ğ²."""
        mlflow.set_tags(tags)

    @property
    def run_id(self) -> str | None:
        return self.run.info.run_id if self.run else None

    @property
    def artifact_uri(self) -> str | None:
        return self.run.info.artifact_uri if self.run else None
```

**ĞŸÑ€Ğ¸Ğ¼ĞµÑ€ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ ĞºĞ¾Ğ½Ñ‚ĞµĞºÑÑ‚Ğ½Ğ¾Ğ³Ğ¾ Ğ¼ĞµĞ½ĞµĞ´Ğ¶ĞµÑ€Ğ°:**

```python
from src.tracking.mlflow_tracker import MLflowExperimentTracker

tracker = MLflowExperimentTracker(experiment_name="boston-housing")

with tracker.start_run(run_name="gradient-boosting-v1"):
    tracker.set_tags({"model_type": "GradientBoosting", "framework": "sklearn"})
    tracker.log_params({"n_estimators": 200, "max_depth": 10})

    # ĞĞ±ÑƒÑ‡ĞµĞ½Ğ¸Ğµ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸
    model = GradientBoostingRegressor(n_estimators=200, max_depth=10)
    model.fit(X_train, y_train)

    # ĞÑ†ĞµĞ½ĞºĞ°
    metrics = evaluate_model(model, X_test, y_test)
    tracker.log_metrics(metrics)

    # Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ğ¸Ğµ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸
    tracker.log_model(model, "model", input_example=X_test.head(5))

    print(f"Run ID: {tracker.run_id}")
    print(f"Artifacts: {tracker.artifact_uri}")
```

### 3.4 Ğ£Ñ‚Ğ¸Ğ»Ğ¸Ñ‚Ñ‹ Ğ´Ğ»Ñ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ñ‹ Ñ ÑĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚Ğ°Ğ¼Ğ¸

**ĞœĞ¾Ğ´ÑƒĞ»ÑŒ `src/tracking/utils.py`:**

```python
"""Ğ£Ñ‚Ğ¸Ğ»Ğ¸Ñ‚Ñ‹ Ğ´Ğ»Ñ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ñ‹ Ñ MLflow ÑĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚Ğ°Ğ¼Ğ¸."""

from typing import Any
import pandas as pd
import mlflow
from mlflow.tracking import MlflowClient


def get_best_run(
    experiment_name: str,
    metric: str = "r2_score",
    ascending: bool = False,
) -> dict[str, Any]:
    """
    ĞŸĞ¾Ğ»ÑƒÑ‡ĞµĞ½Ğ¸Ğµ Ğ»ÑƒÑ‡ÑˆĞµĞ³Ğ¾ Ğ·Ğ°Ğ¿ÑƒÑĞºĞ° Ğ¿Ğ¾ Ğ¼ĞµÑ‚Ñ€Ğ¸ĞºĞµ.

    Args:
        experiment_name: ĞĞ°Ğ·Ğ²Ğ°Ğ½Ğ¸Ğµ ÑĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚Ğ°
        metric: ĞœĞµÑ‚Ñ€Ğ¸ĞºĞ° Ğ´Ğ»Ñ ÑĞ¾Ñ€Ñ‚Ğ¸Ñ€Ğ¾Ğ²ĞºĞ¸
        ascending: True Ğ´Ğ»Ñ Ğ¼Ğ¸Ğ½Ğ¸Ğ¼Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸, False Ğ´Ğ»Ñ Ğ¼Ğ°ĞºÑĞ¸Ğ¼Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸

    Returns:
        Ğ¡Ğ»Ğ¾Ğ²Ğ°Ñ€ÑŒ Ñ Ğ¸Ğ½Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ†Ğ¸ĞµĞ¹ Ğ¾ Ğ»ÑƒÑ‡ÑˆĞµĞ¼ Ğ·Ğ°Ğ¿ÑƒÑĞºĞµ
    """
    client = MlflowClient()
    experiment = client.get_experiment_by_name(experiment_name)

    order = "ASC" if ascending else "DESC"
    runs = client.search_runs(
        experiment_ids=[experiment.experiment_id],
        order_by=[f"metrics.{metric} {order}"],
        max_results=1,
    )

    if not runs:
        return {}

    best_run = runs[0]
    return {
        "run_id": best_run.info.run_id,
        "metrics": best_run.data.metrics,
        "params": best_run.data.params,
        "tags": best_run.data.tags,
        "artifact_uri": best_run.info.artifact_uri,
    }


def load_best_model(experiment_name: str, metric: str = "r2_score"):
    """Ğ—Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞ° Ğ»ÑƒÑ‡ÑˆĞµĞ¹ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ Ğ¿Ğ¾ Ğ¼ĞµÑ‚Ñ€Ğ¸ĞºĞµ."""
    best_run = get_best_run(experiment_name, metric)
    if not best_run:
        raise ValueError(f"ĞĞµÑ‚ Ğ·Ğ°Ğ¿ÑƒÑĞºĞ¾Ğ² Ğ² ÑĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚Ğµ {experiment_name}")

    model_uri = f"runs:/{best_run['run_id']}/model"
    return mlflow.sklearn.load_model(model_uri)


def compare_runs(
    experiment_name: str,
    metrics: list[str] = None,
    top_n: int = 10,
) -> pd.DataFrame:
    """
    Ğ¡Ñ€Ğ°Ğ²Ğ½ĞµĞ½Ğ¸Ğµ Ğ·Ğ°Ğ¿ÑƒÑĞºĞ¾Ğ² ÑĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚Ğ°.

    Returns:
        DataFrame Ñ Ğ¼ĞµÑ‚Ñ€Ğ¸ĞºĞ°Ğ¼Ğ¸ Ğ¸ Ğ¿Ğ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ğ°Ğ¼Ğ¸
    """
    if metrics is None:
        metrics = ["r2_score", "rmse", "mae"]

    client = MlflowClient()
    experiment = client.get_experiment_by_name(experiment_name)

    runs = client.search_runs(
        experiment_ids=[experiment.experiment_id],
        order_by=["metrics.r2_score DESC"],
        max_results=top_n,
    )

    data = []
    for run in runs:
        row = {"run_id": run.info.run_id[:8]}
        row.update({f"metric_{k}": v for k, v in run.data.metrics.items() if k in metrics})
        row.update({f"param_{k}": v for k, v in run.data.params.items()})
        data.append(row)

    return pd.DataFrame(data)


def register_best_model(
    experiment_name: str,
    model_name: str,
    metric: str = "r2_score",
) -> str:
    """
    Ğ ĞµĞ³Ğ¸ÑÑ‚Ñ€Ğ°Ñ†Ğ¸Ñ Ğ»ÑƒÑ‡ÑˆĞµĞ¹ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ Ğ² Model Registry.

    Returns:
        Ğ’ĞµÑ€ÑĞ¸Ñ Ğ·Ğ°Ñ€ĞµĞ³Ğ¸ÑÑ‚Ñ€Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ğ¾Ğ¹ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸
    """
    best_run = get_best_run(experiment_name, metric)
    if not best_run:
        raise ValueError(f"ĞĞµÑ‚ Ğ·Ğ°Ğ¿ÑƒÑĞºĞ¾Ğ² Ğ² ÑĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚Ğµ {experiment_name}")

    model_uri = f"runs:/{best_run['run_id']}/model"
    result = mlflow.register_model(model_uri, model_name)

    return result.version


def cleanup_old_runs(
    experiment_name: str,
    keep_top_n: int = 10,
    metric: str = "r2_score",
):
    """
    Ğ£Ğ´Ğ°Ğ»ĞµĞ½Ğ¸Ğµ ÑÑ‚Ğ°Ñ€Ñ‹Ñ… Ğ·Ğ°Ğ¿ÑƒÑĞºĞ¾Ğ², ĞºÑ€Ğ¾Ğ¼Ğµ Ñ‚Ğ¾Ğ¿-N Ğ¿Ğ¾ Ğ¼ĞµÑ‚Ñ€Ğ¸ĞºĞµ.
    """
    client = MlflowClient()
    experiment = client.get_experiment_by_name(experiment_name)

    # ĞŸĞ¾Ğ»ÑƒÑ‡Ğ°ĞµĞ¼ Ğ²ÑĞµ Ğ·Ğ°Ğ¿ÑƒÑĞºĞ¸ Ğ¾Ñ‚ÑĞ¾Ñ€Ñ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ğµ Ğ¿Ğ¾ Ğ¼ĞµÑ‚Ñ€Ğ¸ĞºĞµ
    all_runs = client.search_runs(
        experiment_ids=[experiment.experiment_id],
        order_by=[f"metrics.{metric} DESC"],
    )

    # Ğ£Ğ´Ğ°Ğ»ÑĞµĞ¼ Ğ²ÑĞµ ĞºÑ€Ğ¾Ğ¼Ğµ Ñ‚Ğ¾Ğ¿-N
    for run in all_runs[keep_top_n:]:
        client.delete_run(run.info.run_id)
        print(f"Ğ£Ğ´Ğ°Ğ»Ñ‘Ğ½ run: {run.info.run_id}")
```

**ĞŸÑ€Ğ¸Ğ¼ĞµÑ€ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ ÑƒÑ‚Ğ¸Ğ»Ğ¸Ñ‚:**

```python
from src.tracking.utils import (
    get_best_run,
    load_best_model,
    compare_runs,
    register_best_model,
)

# ĞŸĞ¾Ğ»ÑƒÑ‡ĞµĞ½Ğ¸Ğµ Ğ»ÑƒÑ‡ÑˆĞµĞ³Ğ¾ Ğ·Ğ°Ğ¿ÑƒÑĞºĞ°
best = get_best_run("boston-housing", metric="r2_score")
print(f"Ğ›ÑƒÑ‡ÑˆĞ¸Ğ¹ RÂ²: {best['metrics']['r2_score']:.4f}")

# Ğ—Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞ° Ğ»ÑƒÑ‡ÑˆĞµĞ¹ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸
model = load_best_model("boston-housing")
predictions = model.predict(X_new)

# Ğ¡Ñ€Ğ°Ğ²Ğ½ĞµĞ½Ğ¸Ğµ ÑĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚Ğ¾Ğ²
comparison = compare_runs("boston-housing", top_n=5)
print(comparison)

# Ğ ĞµĞ³Ğ¸ÑÑ‚Ñ€Ğ°Ñ†Ğ¸Ñ Ğ»ÑƒÑ‡ÑˆĞµĞ¹ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸
version = register_best_model("boston-housing", "boston-housing-rf")
print(f"Ğ—Ğ°Ñ€ĞµĞ³Ğ¸ÑÑ‚Ñ€Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ° Ğ²ĞµÑ€ÑĞ¸Ñ: {version}")
```

---

## 4. Ğ˜Ğ½ÑÑ‚Ñ€ÑƒĞºÑ†Ğ¸Ğ¸ Ğ¿Ğ¾ Ğ·Ğ°Ğ¿ÑƒÑĞºÑƒ

### 4.1 Ğ‘Ñ‹ÑÑ‚Ñ€Ñ‹Ğ¹ ÑÑ‚Ğ°Ñ€Ñ‚

```bash
# 1. ĞšĞ»Ğ¾Ğ½Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ñ€ĞµĞ¿Ğ¾Ğ·Ğ¸Ñ‚Ğ¾Ñ€Ğ¸Ñ
git clone <repo-url>
cd ipml_boston_housing

# 2. Ğ£ÑÑ‚Ğ°Ğ½Ğ¾Ğ²ĞºĞ° Ğ·Ğ°Ğ²Ğ¸ÑĞ¸Ğ¼Ğ¾ÑÑ‚ĞµĞ¹
uv sync

# 3. Ğ¡Ğ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ğµ Ñ„Ğ°Ğ¹Ğ»Ğ° .env
cat > .env << 'EOF'
MINIO_ROOT_USER=minioadmin0
MINIO_ROOT_PASSWORD=minioadmin1230
MLFLOW_ADMIN_USERNAME=admin
MLFLOW_ADMIN_PASSWORD=secure_password_123
MLFLOW_TRACKING_URI=http://localhost:5000
MLFLOW_TRACKING_USERNAME=admin
MLFLOW_TRACKING_PASSWORD=secure_password_123
MLFLOW_S3_ENDPOINT_URL=http://localhost:9000
AWS_ACCESS_KEY_ID=minioadmin0
AWS_SECRET_ACCESS_KEY=minioadmin1230
EOF

# 4. Ğ—Ğ°Ğ¿ÑƒÑĞº Ğ¸Ğ½Ñ„Ñ€Ğ°ÑÑ‚Ñ€ÑƒĞºÑ‚ÑƒÑ€Ñ‹
docker-compose up -d minio mlflow nginx

# 5. Ğ¡Ğ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ğµ Ğ±Ğ°ĞºĞµÑ‚Ğ¾Ğ²
mc alias set local http://localhost:9000 minioadmin0 minioadmin1230
mc mb local/boston-housing-data
mc mb local/mlflow-artifacts

# 6. Ğ—Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞ° Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…
dvc pull

# 7. Ğ—Ğ°Ğ¿ÑƒÑĞº ÑĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚Ğ°
python src/modeling/train_mlflow.py --run-name "my-experiment"

# 8. ĞŸÑ€Ğ¾ÑĞ¼Ğ¾Ñ‚Ñ€ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ğ¾Ğ²
# ĞÑ‚ĞºÑ€Ğ¾Ğ¹Ñ‚Ğµ http://localhost:5000
# Ğ›Ğ¾Ğ³Ğ¸Ğ½: admin / secure_password_123
```

### 4.2 ĞŸĞ¾Ğ»ĞµĞ·Ğ½Ñ‹Ğµ ĞºĞ¾Ğ¼Ğ°Ğ½Ğ´Ñ‹

```bash
# MLflow
mlflow experiments search                # Ğ¡Ğ¿Ğ¸ÑĞ¾Ğº ÑĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚Ğ¾Ğ²
mlflow runs list --experiment-id 1       # Ğ—Ğ°Ğ¿ÑƒÑĞºĞ¸ ÑĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚Ğ°
mlflow models list                       # Ğ—Ğ°Ñ€ĞµĞ³Ğ¸ÑÑ‚Ñ€Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ğµ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸

# Docker
docker-compose ps                        # Ğ¡Ñ‚Ğ°Ñ‚ÑƒÑ ĞºĞ¾Ğ½Ñ‚ĞµĞ¹Ğ½ĞµÑ€Ğ¾Ğ²
docker-compose logs -f mlflow            # Ğ›Ğ¾Ğ³Ğ¸ MLflow
docker-compose restart mlflow nginx      # ĞŸĞµÑ€ĞµĞ·Ğ°Ğ¿ÑƒÑĞº

# DVC
dvc status                               # Ğ¡Ñ‚Ğ°Ñ‚ÑƒÑ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…
dvc pull                                 # Ğ—Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞ° Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…
dvc push                                 # ĞÑ‚Ğ¿Ñ€Ğ°Ğ²ĞºĞ° Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…
```

---

## 5. ĞĞ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ° Ğ¸Ğ½ÑÑ‚Ñ€ÑƒĞ¼ĞµĞ½Ñ‚Ğ° Ğ¾Ñ€ĞºĞµÑÑ‚Ñ€Ğ°Ñ†Ğ¸Ğ¸

### 5.1 Ğ£ÑÑ‚Ğ°Ğ½Ğ¾Ğ²ĞºĞ° Ğ¸ Ğ½Ğ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ° Ğ²Ñ‹Ğ±Ñ€Ğ°Ğ½Ğ½Ğ¾Ğ³Ğ¾ Ğ¸Ğ½ÑÑ‚Ñ€ÑƒĞ¼ĞµĞ½Ñ‚Ğ° (Apache Airflow)

**Ğ’Ñ‹Ğ±Ñ€Ğ°Ğ½Ğ½Ñ‹Ğ¹ Ğ¸Ğ½ÑÑ‚Ñ€ÑƒĞ¼ĞµĞ½Ñ‚ Ğ¾Ñ€ĞºĞµÑÑ‚Ñ€Ğ°Ñ†Ğ¸Ğ¸:** Apache Airflow 2.8.0+

**ĞÑ€Ñ…Ğ¸Ñ‚ĞµĞºÑ‚ÑƒÑ€Ğ° Ñ€Ğ°Ğ·Ğ²ĞµÑ€Ñ‚Ñ‹Ğ²Ğ°Ğ½Ğ¸Ñ:**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        Airflow Stack                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Webserver   â”‚  Scheduler   â”‚   Worker     â”‚   airflow-init    â”‚
â”‚  (Ğ¿Ğ¾Ñ€Ñ‚ 8080) â”‚              â”‚  (Celery)    â”‚                   â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚              â”‚              â”‚
       â–¼              â–¼              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     Ğ˜Ğ½Ñ„Ñ€Ğ°ÑÑ‚Ñ€ÑƒĞºÑ‚ÑƒÑ€Ğ°                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ PostgreSQL  â”‚   Redis     â”‚   MLflow    â”‚   MinIO     â”‚ Nginx  â”‚
â”‚ (Metadata)  â”‚ (Broker)    â”‚ (Tracking)  â”‚ (Storage)   â”‚ (Auth) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Ğ£ÑÑ‚Ğ°Ğ½Ğ¾Ğ²ĞºĞ° Ğ¸ Ğ½Ğ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ° Ñ‡ĞµÑ€ĞµĞ· Docker Compose:**

```dockerfile
# docker/Dockerfile.airflow
FROM apache/airflow:2.8.0-python3.11

USER root
RUN apt-get update && apt-get install -y \
    build-essential \
    && apt-get clean

USER airflow
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# ĞĞ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ° Python paths
ENV PYTHONPATH="${PYTHONPATH}:/opt/airflow/src"
```

**Docker Compose ĞºĞ¾Ğ½Ñ„Ğ¸Ğ³ÑƒÑ€Ğ°Ñ†Ğ¸Ñ:**

```yaml
x-airflow-common: &airflow-common
  build:
    context: .
    dockerfile: docker/Dockerfile.airflow
  environment: &airflow-common-env
    AIRFLOW__CORE__EXECUTOR: CeleryExecutor
    AIRFLOW__CORE__SQL_ALCHEMY_CONN: postgresql+psycopg2://airflow:airflow@postgres/airflow  # pragma: allowlist secret
    AIRFLOW__CELERY__RESULT_BACKEND: db+postgresql://airflow:airflow@postgres/airflow  # pragma: allowlist secret
    AIRFLOW__CELERY__BROKER_URL: redis://:@redis:6379/0
    # ĞŸĞ°Ñ€Ğ°Ğ»Ğ»ĞµĞ»Ğ¸Ğ·Ğ¼
    AIRFLOW__CORE__PARALLELISM: 16
    AIRFLOW__CORE__DAG_CONCURRENCY: 8
    AIRFLOW__CELERY__WORKER_CONCURRENCY: 4
    # Ğ˜Ğ½Ñ‚ĞµĞ³Ñ€Ğ°Ñ†Ğ¸Ñ Ñ ML Ğ¸Ğ½Ñ„Ñ€Ğ°ÑÑ‚Ñ€ÑƒĞºÑ‚ÑƒÑ€Ğ¾Ğ¹
    MLFLOW_TRACKING_URI: http://mlflow:5000
    MLFLOW_S3_ENDPOINT_URL: http://minio:9000
  volumes:
    - ./airflow/dags:/opt/airflow/dags
    - ./airflow/logs:/opt/airflow/logs
    - ./airflow/plugins:/opt/airflow/plugins
    - ./data:/opt/airflow/data
    - ./src:/opt/airflow/src
```

### 5.2 Ğ¡Ğ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ğµ workflow Ğ´Ğ»Ñ ML Ğ¿Ğ°Ğ¹Ğ¿Ğ»Ğ°Ğ¹Ğ½Ğ°

Ğ ĞµĞ°Ğ»Ğ¸Ğ·Ğ¾Ğ²Ğ°Ğ½Ğ¾ **3 DAG** Ñ Ñ€Ğ°Ğ·Ğ»Ğ¸Ñ‡Ğ½Ñ‹Ğ¼Ğ¸ Ğ¿Ğ°Ñ‚Ñ‚ĞµÑ€Ğ½Ğ°Ğ¼Ğ¸ Ğ¾Ñ€ĞºĞµÑÑ‚Ñ€Ğ°Ñ†Ğ¸Ğ¸:

#### DAG 1: boston_housing_simple

**ĞĞ°Ğ·Ğ½Ğ°Ñ‡ĞµĞ½Ğ¸Ğµ:** ĞŸÑ€Ğ¾ÑÑ‚Ğ¾Ğ¹ Ğ¿Ğ¾ÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ÑŒĞ½Ñ‹Ğ¹ Ğ¿Ğ°Ğ¹Ğ¿Ğ»Ğ°Ğ¹Ğ½ Ğ´Ğ»Ñ Ğ±Ñ‹ÑÑ‚Ñ€Ğ¾Ğ³Ğ¾ Ğ¿Ñ€Ğ¾Ñ‚Ğ¾Ñ‚Ğ¸Ğ¿Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ.

**ĞÑ€Ñ…Ğ¸Ñ‚ĞµĞºÑ‚ÑƒÑ€Ğ°:**
```
download_data â†’ validate_data â†’ train_model â†’ evaluate_model â†’ save_artifacts
```

**ĞšĞ¾Ğ½Ñ„Ğ¸Ğ³ÑƒÑ€Ğ°Ñ†Ğ¸Ñ:**
```python
@dag(
    dag_id="boston_housing_simple",
    schedule=None,  # Ğ ÑƒÑ‡Ğ½Ğ¾Ğ¹ Ğ·Ğ°Ğ¿ÑƒÑĞº
    start_date=datetime(2024, 1, 1),
    catchup=False,
    tags=["ml", "boston_housing", "random_forest"],
)
```

#### DAG 2: boston_housing_experiments

**ĞĞ°Ğ·Ğ½Ğ°Ñ‡ĞµĞ½Ğ¸Ğµ:** ĞŸĞ°Ñ€Ğ°Ğ»Ğ»ĞµĞ»ÑŒĞ½Ğ¾Ğµ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ğµ 19 ML Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ Ñ Ğ°Ğ³Ñ€ĞµĞ³Ğ°Ñ†Ğ¸ĞµĞ¹ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ğ¾Ğ².

**ĞÑ€Ñ…Ğ¸Ñ‚ĞµĞºÑ‚ÑƒÑ€Ğ°:**
```
                    download_data
                         â”‚
                    validate_data
                         â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚               â”‚               â”‚
    Linear Models   Tree Models    Other Models
      (7 ÑˆÑ‚.)        (9 ÑˆÑ‚.)        (3 ÑˆÑ‚.)
         â”‚               â”‚               â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                  aggregate_results
                         â”‚
                   generate_report
```

**ĞŸĞ°Ñ€Ğ°Ğ»Ğ»ĞµĞ»ÑŒĞ½Ğ¾Ğµ Ğ²Ñ‹Ğ¿Ğ¾Ğ»Ğ½ĞµĞ½Ğ¸Ğµ:**
```python
# Ğ›Ğ¸Ğ½ĞµĞ¹Ğ½Ñ‹Ğµ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸
linear_results = train_single_model.expand(
    model_config=LINEAR_MODELS,
    data_info=[data_info] * len(LINEAR_MODELS),
)

# Ğ”Ñ€ĞµĞ²Ğ¾Ğ²Ğ¸Ğ´Ğ½Ñ‹Ğµ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸  
tree_results = train_single_model.expand(
    model_config=TREE_MODELS,
    data_info=[data_info] * len(TREE_MODELS),
)
```

#### DAG 3: boston_housing_cached

**ĞĞ°Ğ·Ğ½Ğ°Ñ‡ĞµĞ½Ğ¸Ğµ:** ML Ğ¿Ğ°Ğ¹Ğ¿Ğ»Ğ°Ğ¹Ğ½ Ñ Ğ¸Ğ½Ñ‚ĞµĞ»Ğ»ĞµĞºÑ‚ÑƒĞ°Ğ»ÑŒĞ½Ñ‹Ğ¼ ĞºÑÑˆĞ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸ĞµĞ¼ Ğ² MinIO.

**ĞÑĞ¾Ğ±ĞµĞ½Ğ½Ğ¾ÑÑ‚Ğ¸:**
- `ShortCircuitOperator` Ğ´Ğ»Ñ Ğ¿Ñ€Ğ¾Ğ¿ÑƒÑĞºĞ° Ğ·Ğ°Ğ´Ğ°Ñ‡ ĞµÑĞ»Ğ¸ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ Ğ² ĞºÑÑˆĞµ
- ĞŸÑ€Ğ¾Ğ²ĞµÑ€ĞºĞ° Ñ…ÑÑˆĞ° Ğ²Ñ…Ğ¾Ğ´Ğ½Ñ‹Ñ… Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ´Ğ»Ñ Ğ¸Ğ½Ğ²Ğ°Ğ»Ğ¸Ğ´Ğ°Ñ†Ğ¸Ğ¸ ĞºÑÑˆĞ°
- ĞĞ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¾Ğµ ÑĞ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ğ¸Ğµ Ğ² ĞºÑÑˆ Ğ¿Ğ¾ÑĞ»Ğµ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ

**Ğ›Ğ¾Ğ³Ğ¸ĞºĞ° ĞºÑÑˆĞ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ:**
```python
def check_cache_exists(data_path: str, **kwargs) -> bool:
    """
    True: Ğ¿Ñ€Ğ¾Ğ´Ğ¾Ğ»Ğ¶Ğ¸Ñ‚ÑŒ Ğ²Ñ‹Ğ¿Ğ¾Ğ»Ğ½ĞµĞ½Ğ¸Ğµ (Ğ½ĞµÑ‚ ĞºÑÑˆĞ°, Ğ½ÑƒĞ¶Ğ½Ğ¾ Ğ¾Ğ±ÑƒÑ‡Ğ°Ñ‚ÑŒ)
    False: Ğ¿Ñ€Ğ¾Ğ¿ÑƒÑÑ‚Ğ¸Ñ‚ÑŒ downstream Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ¸ (ĞºÑÑˆ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½)
    """
    cache = MinIOCache(bucket_name="airflow-cache")
    prefix = "models/random_forest_cached"
    exists, cache_key = cache.check_cache(prefix, MODEL_PARAMS, data_path)
    return not exists  # Ğ˜Ğ½Ğ²ĞµÑ€Ñ‚Ğ¸Ñ€ÑƒĞµĞ¼ Ğ´Ğ»Ñ ShortCircuitOperator
```

### 5.3 ĞĞ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ° Ğ·Ğ°Ğ²Ğ¸ÑĞ¸Ğ¼Ğ¾ÑÑ‚ĞµĞ¹ Ğ¼ĞµĞ¶Ğ´Ñƒ ÑÑ‚Ğ°Ğ¿Ğ°Ğ¼Ğ¸

**Ğ¢Ğ¸Ğ¿Ñ‹ Ğ·Ğ°Ğ²Ğ¸ÑĞ¸Ğ¼Ğ¾ÑÑ‚ĞµĞ¹:**

|| Ğ¢Ğ¸Ğ¿ | ĞĞ¿Ğ¸ÑĞ°Ğ½Ğ¸Ğµ | ĞŸÑ€Ğ¸Ğ¼ĞµÑ€ |
||------|----------|---------|
|| **Ğ›Ğ¸Ğ½ĞµĞ¹Ğ½Ñ‹Ğµ** | ĞŸĞ¾ÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ÑŒĞ½Ğ¾Ğµ Ğ²Ñ‹Ğ¿Ğ¾Ğ»Ğ½ĞµĞ½Ğ¸Ğµ | `data >> validate >> train >> evaluate` |
|| **ĞŸĞ°Ñ€Ğ°Ğ»Ğ»ĞµĞ»ÑŒĞ½Ñ‹Ğµ** | ĞĞµĞ·Ğ°Ğ²Ğ¸ÑĞ¸Ğ¼Ğ¾Ğµ Ğ²Ñ‹Ğ¿Ğ¾Ğ»Ğ½ĞµĞ½Ğ¸Ğµ Ğ³Ñ€ÑƒĞ¿Ğ¿ Ğ·Ğ°Ğ´Ğ°Ñ‡ | `expand()` Ğ´Ğ»Ñ Ğ¼Ğ½Ğ¾Ğ¶ĞµÑÑ‚Ğ²ĞµĞ½Ğ½Ğ¾Ğ³Ğ¾ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ |
|| **Ğ£ÑĞ»Ğ¾Ğ²Ğ½Ñ‹Ğµ** | Ğ’Ñ‹Ğ¿Ğ¾Ğ»Ğ½ĞµĞ½Ğ¸Ğµ Ğ·Ğ°Ğ²Ğ¸ÑĞ¸Ñ‚ Ğ¾Ñ‚ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ğ° Ğ¿Ñ€ĞµĞ´Ñ‹Ğ´ÑƒÑ‰Ğ¸Ñ… Ğ·Ğ°Ğ´Ğ°Ñ‡ | `ShortCircuitOperator` Ğ´Ğ»Ñ ĞºÑÑˆĞ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ |
|| **Trigger Rules** | Ğ“Ğ¸Ğ±ĞºĞ°Ñ Ğ»Ğ¾Ğ³Ğ¸ĞºĞ° Ğ·Ğ°Ğ¿ÑƒÑĞºĞ° | `none_failed_min_one_success` |

**ĞŸÑ€Ğ¸Ğ¼ĞµÑ€Ñ‹ Ğ½Ğ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ¸ Ğ·Ğ°Ğ²Ğ¸ÑĞ¸Ğ¼Ğ¾ÑÑ‚ĞµĞ¹:**

```python
# Ğ›Ğ¸Ğ½ĞµĞ¹Ğ½Ñ‹Ğµ Ğ·Ğ°Ğ²Ğ¸ÑĞ¸Ğ¼Ğ¾ÑÑ‚Ğ¸
data_path >> cache_check >> train_result >> save_result >> summary

# Ğ£ÑĞ»Ğ¾Ğ²Ğ½Ñ‹Ğµ Ğ·Ğ°Ğ²Ğ¸ÑĞ¸Ğ¼Ğ¾ÑÑ‚Ğ¸ Ñ trigger rules
@task(trigger_rule="none_failed_min_one_success")
def generate_summary(cache_result=None, train_save_result=None):
    # Ğ’Ñ‹Ğ¿Ğ¾Ğ»Ğ½ÑĞµÑ‚ÑÑ ĞµÑĞ»Ğ¸ Ñ…Ğ¾Ñ‚Ñ Ğ±Ñ‹ Ğ¾Ğ´Ğ¸Ğ½ upstream task ÑƒÑĞ¿ĞµÑˆĞµĞ½
    pass

# ĞŸĞ°Ñ€Ğ°Ğ»Ğ»ĞµĞ»ÑŒĞ½Ñ‹Ğµ Ğ·Ğ°Ğ²Ğ¸ÑĞ¸Ğ¼Ğ¾ÑÑ‚Ğ¸
aggregated = aggregate_results(
    linear_results=linear_results,    # Ğ–Ğ´Ñ‘Ñ‚ Ğ·Ğ°Ğ²ĞµÑ€ÑˆĞµĞ½Ğ¸Ñ Ğ²ÑĞµÑ… Ğ»Ğ¸Ğ½ĞµĞ¹Ğ½Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹
    tree_results=tree_results,        # Ğ–Ğ´Ñ‘Ñ‚ Ğ·Ğ°Ğ²ĞµÑ€ÑˆĞµĞ½Ğ¸Ñ Ğ²ÑĞµÑ… Ğ´Ñ€ĞµĞ²Ğ¾Ğ²Ğ¸Ğ´Ğ½Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹
    other_results=other_results,      # Ğ–Ğ´Ñ‘Ñ‚ Ğ·Ğ°Ğ²ĞµÑ€ÑˆĞµĞ½Ğ¸Ñ Ğ²ÑĞµÑ… Ğ´Ñ€ÑƒĞ³Ğ¸Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹
)
```

### 5.4 Ğ ĞµĞ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ ĞºÑÑˆĞ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ Ğ¸ Ğ¿Ğ°Ñ€Ğ°Ğ»Ğ»ĞµĞ»ÑŒĞ½Ğ¾Ğ³Ğ¾ Ğ²Ñ‹Ğ¿Ğ¾Ğ»Ğ½ĞµĞ½Ğ¸Ñ

#### Ğ¡Ğ¸ÑÑ‚ĞµĞ¼Ğ° ĞºÑÑˆĞ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ Ğ½Ğ° Ğ±Ğ°Ğ·Ğµ MinIO

**ĞœĞ¾Ğ´ÑƒĞ»ÑŒ `airflow/plugins/minio_cache.py`:**

```python
class MinIOCache:
    """
    ĞšĞ»Ğ°ÑÑ Ğ´Ğ»Ñ ĞºÑÑˆĞ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ Ğ°Ñ€Ñ‚ĞµÑ„Ğ°ĞºÑ‚Ğ¾Ğ² Ğ² MinIO.

    ĞŸĞ¾Ğ·Ğ²Ğ¾Ğ»ÑĞµÑ‚:
    - ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑÑ‚ÑŒ ÑÑƒÑ‰ĞµÑÑ‚Ğ²Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ñ„Ğ°Ğ¹Ğ»Ğ¾Ğ² Ğ¿Ğ¾ Ñ…ÑÑˆ-ĞºĞ»ÑÑ‡Ğ°Ğ¼
    - Ğ’Ñ‹Ñ‡Ğ¸ÑĞ»ÑÑ‚ÑŒ Ñ…ÑÑˆĞ¸ Ğ´Ğ»Ñ Ğ¿Ñ€Ğ¾Ğ²ĞµÑ€ĞºĞ¸ Ğ¸Ğ·Ğ¼ĞµĞ½ĞµĞ½Ğ¸Ğ¹ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…
    - Ğ—Ğ°Ğ³Ñ€ÑƒĞ¶Ğ°Ñ‚ÑŒ/ÑĞºĞ°Ñ‡Ğ¸Ğ²Ğ°Ñ‚ÑŒ Ğ°Ñ€Ñ‚ĞµÑ„Ğ°ĞºÑ‚Ñ‹
    """

    def get_cache_key(self, prefix: str, params: dict, data_hash: str = None) -> str:
        """
        Ğ“ĞµĞ½ĞµÑ€Ğ¸Ñ€ÑƒĞµÑ‚ ĞºĞ»ÑÑ‡ ĞºÑÑˆĞ° Ğ½Ğ° Ğ¾ÑĞ½Ğ¾Ğ²Ğµ Ğ¿Ğ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ğ¾Ğ² Ğ¸ Ñ…ÑÑˆĞ° Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ….

        Ğ¤Ğ¾Ñ€Ğ¼Ğ°Ñ‚: prefix_params_hash_data_hash
        ĞŸÑ€Ğ¸Ğ¼ĞµÑ€: "models/random_forest_a1b2c3d4_e5f6g7h8"
        """
        params_hash = self.compute_params_hash(params)
        if data_hash:
            return f"{prefix}_{params_hash}_{data_hash}"
        return f"{prefix}_{params_hash}"
```

**Ğ˜Ğ½Ñ‚ĞµĞ³Ñ€Ğ°Ñ†Ğ¸Ñ Ñ Airflow:**

```python
# ĞŸÑ€Ğ¾Ğ²ĞµÑ€ĞºĞ° ĞºÑÑˆĞ°
cache_check = ShortCircuitOperator(
    task_id="check_cache",
    python_callable=check_cache_exists,
    op_kwargs={"data_path": data_path},
    provide_context=True,
)

# Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ğ¸Ğµ Ğ² ĞºÑÑˆ Ğ¿Ğ¾ÑĞ»Ğµ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ
save_result = save_to_cache(train_result)
```

#### ĞŸĞ°Ñ€Ğ°Ğ»Ğ»ĞµĞ»ÑŒĞ½Ğ¾Ğµ Ğ²Ñ‹Ğ¿Ğ¾Ğ»Ğ½ĞµĞ½Ğ¸Ğµ

**ĞĞ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ¸ Ğ¿Ğ°Ñ€Ğ°Ğ»Ğ»ĞµĞ»Ğ¸Ğ·Ğ¼Ğ° Ğ² Docker Compose:**

```yaml
environment:
  AIRFLOW__CORE__PARALLELISM: 16          # ĞœĞ°ĞºÑ. Ğ·Ğ°Ğ´Ğ°Ñ‡ Ğ²Ğ¾ Ğ²ÑÑ‘Ğ¼ Airflow
  AIRFLOW__CORE__DAG_CONCURRENCY: 8       # ĞœĞ°ĞºÑ. Ğ·Ğ°Ğ´Ğ°Ñ‡ Ğ½Ğ° Ğ¾Ğ´Ğ¸Ğ½ DAG
  AIRFLOW__CELERY__WORKER_CONCURRENCY: 4  # ĞœĞ°ĞºÑ. Ğ·Ğ°Ğ´Ğ°Ñ‡ Ğ½Ğ° Ğ²Ğ¾Ñ€ĞºĞµÑ€
```

**Ğ ĞµĞ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ Ñ‡ĞµÑ€ĞµĞ· expand() operator:**

```python
@dag(max_active_tasks=8)  # ĞĞ³Ñ€Ğ°Ğ½Ğ¸Ñ‡ĞµĞ½Ğ¸Ğµ Ğ½Ğ° ÑƒÑ€Ğ¾Ğ²Ğ½Ğµ DAG
def boston_housing_experiments_dag():

    # ĞŸĞ°Ñ€Ğ°Ğ»Ğ»ĞµĞ»ÑŒĞ½Ğ¾Ğµ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ğµ 19 Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹
    linear_results = train_single_model.expand(
        model_config=LINEAR_MODELS,      # 7 ĞºĞ¾Ğ½Ñ„Ğ¸Ğ³ÑƒÑ€Ğ°Ñ†Ğ¸Ğ¹
        data_info=[data_info] * 7,
    )

    tree_results = train_single_model.expand(
        model_config=TREE_MODELS,        # 9 ĞºĞ¾Ğ½Ñ„Ğ¸Ğ³ÑƒÑ€Ğ°Ñ†Ğ¸Ğ¹  
        data_info=[data_info] * 9,
    )

    other_results = train_single_model.expand(
        model_config=OTHER_MODELS,       # 3 ĞºĞ¾Ğ½Ñ„Ğ¸Ğ³ÑƒÑ€Ğ°Ñ†Ğ¸Ğ¸
        data_info=[data_info] * 3,
    )
```

**ĞœĞ¾Ğ½Ğ¸Ñ‚Ğ¾Ñ€Ğ¸Ğ½Ğ³ Ğ¿Ğ°Ñ€Ğ°Ğ»Ğ»ĞµĞ»ÑŒĞ½Ğ¾Ğ³Ğ¾ Ğ²Ñ‹Ğ¿Ğ¾Ğ»Ğ½ĞµĞ½Ğ¸Ñ:**

- **Airflow UI:** Ğ“Ñ€Ğ°Ñ„ Ğ·Ğ°Ğ²Ğ¸ÑĞ¸Ğ¼Ğ¾ÑÑ‚ĞµĞ¹ Ñ Ñ€ĞµĞ°Ğ»ÑŒĞ½Ñ‹Ğ¼ Ğ²Ñ€ĞµĞ¼ĞµĞ½ĞµĞ¼ Ğ²Ñ‹Ğ¿Ğ¾Ğ»Ğ½ĞµĞ½Ğ¸Ñ
- **Ğ›Ğ¾Ğ³Ğ¸:** Ğ¡Ñ‚Ñ€ÑƒĞºÑ‚ÑƒÑ€Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ğ¾Ğµ Ğ»Ğ¾Ğ³Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ñ‡ĞµÑ€ĞµĞ· `loguru`
- **ĞœĞµÑ‚Ñ€Ğ¸ĞºĞ¸:** Ğ’Ñ€ĞµĞ¼Ñ Ğ²Ñ‹Ğ¿Ğ¾Ğ»Ğ½ĞµĞ½Ğ¸Ñ ĞºĞ°Ğ¶Ğ´Ğ¾Ğ¹ Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ¸ Ğ² MLflow

---

## 6. ĞĞ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ° Ğ¸Ğ½ÑÑ‚Ñ€ÑƒĞ¼ĞµĞ½Ñ‚Ğ° ĞºĞ¾Ğ½Ñ„Ğ¸Ğ³ÑƒÑ€Ğ°Ñ†Ğ¸Ğ¹

### 6.1 ĞĞ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ° Ğ²Ñ‹Ğ±Ñ€Ğ°Ğ½Ğ½Ğ¾Ğ³Ğ¾ Ğ¸Ğ½ÑÑ‚Ñ€ÑƒĞ¼ĞµĞ½Ñ‚Ğ° Ğ´Ğ»Ñ ÑƒĞ¿Ñ€Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ñ ĞºĞ¾Ğ½Ñ„Ğ¸Ğ³ÑƒÑ€Ğ°Ñ†Ğ¸ÑĞ¼Ğ¸

**Ğ’Ñ‹Ğ±Ñ€Ğ°Ğ½Ğ½Ñ‹Ğ¹ Ğ¿Ğ¾Ğ´Ñ…Ğ¾Ğ´:** ĞœĞ¾Ğ´ÑƒĞ»ÑŒĞ½Ğ°Ñ ÑĞ¸ÑÑ‚ĞµĞ¼Ğ° ĞºĞ¾Ğ½Ñ„Ğ¸Ğ³ÑƒÑ€Ğ°Ñ†Ğ¸Ğ¹ Ğ½Ğ° Ğ¾ÑĞ½Ğ¾Ğ²Ğµ Ğ¿ĞµÑ€ĞµĞ¼ĞµĞ½Ğ½Ñ‹Ñ… Ğ¾ĞºÑ€ÑƒĞ¶ĞµĞ½Ğ¸Ñ Ğ¸ Python Ğ¼Ğ¾Ğ´ÑƒĞ»ĞµĞ¹.

**ĞÑ€Ñ…Ğ¸Ñ‚ĞµĞºÑ‚ÑƒÑ€Ğ° ÑĞ¸ÑÑ‚ĞµĞ¼Ñ‹ ĞºĞ¾Ğ½Ñ„Ğ¸Ğ³ÑƒÑ€Ğ°Ñ†Ğ¸Ğ¹:**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Ğ¡Ğ¸ÑÑ‚ĞµĞ¼Ğ° ĞºĞ¾Ğ½Ñ„Ğ¸Ğ³ÑƒÑ€Ğ°Ñ†Ğ¸Ğ¹                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚    .env     â”‚â”€â”€â”€â–¶â”‚ os.environ  â”‚â”€â”€â”€â–¶â”‚  Python Ğ¼Ğ¾Ğ´ÑƒĞ»Ğ¸      â”‚  â”‚
â”‚  â”‚ (Ğ»Ğ¾ĞºĞ°Ğ»ÑŒĞ½Ğ¾)  â”‚    â”‚ (runtime)   â”‚    â”‚ config/*.py         â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚        â”‚                   â”‚                        â”‚           â”‚
â”‚        â–¼                   â–¼                        â–¼           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚docker-composeâ”‚    â”‚  Airflow    â”‚    â”‚   ML Scripts       â”‚  â”‚
â”‚  â”‚    .yml     â”‚    â”‚   DAGs      â”‚    â”‚  (experiments)     â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**ĞÑĞ½Ğ¾Ğ²Ğ½Ñ‹Ğµ Ğ¼Ğ¾Ğ´ÑƒĞ»Ğ¸ ĞºĞ¾Ğ½Ñ„Ğ¸Ğ³ÑƒÑ€Ğ°Ñ†Ğ¸Ğ¸:**

|| ĞœĞ¾Ğ´ÑƒĞ»ÑŒ | ĞĞ°Ğ·Ğ½Ğ°Ñ‡ĞµĞ½Ğ¸Ğµ | Ğ¡Ğ¾Ğ´ĞµÑ€Ğ¶Ğ°Ğ½Ğ¸Ğµ |
||--------|------------|------------|
|| `src/config.py` | Ğ‘Ğ°Ğ·Ğ¾Ğ²Ñ‹Ğµ Ğ¿ÑƒÑ‚Ğ¸ Ğ¿Ñ€Ğ¾ĞµĞºÑ‚Ğ° | Ğ”Ğ¸Ñ€ĞµĞºÑ‚Ğ¾Ñ€Ğ¸Ğ¸ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…, Ğ¿ÑƒÑ‚ÑŒ Ğº Ğ¿Ñ€Ğ¾ĞµĞºÑ‚Ñƒ, Ğ½Ğ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ¸ Ğ»Ğ¾Ğ³Ğ³ĞµÑ€Ğ° |
|| `src/config/mlflow_config.py` | MLflow Ğ¸ MinIO | URI Ñ‚Ñ€ĞµĞºĞ¸Ğ½Ğ³Ğ°, ÑĞ½Ğ´Ğ¿Ğ¾Ğ¸Ğ½Ñ‚Ñ‹ S3, ĞºĞ»ÑÑ‡Ğ¸ Ğ´Ğ¾ÑÑ‚ÑƒĞ¿Ğ° |
|| `.env` | Ğ¡ĞµĞºÑ€ĞµÑ‚Ñ‹ Ğ¸ Ğ¿ĞµÑ€ĞµĞ¼ĞµĞ½Ğ½Ñ‹Ğµ Ğ¾ĞºÑ€ÑƒĞ¶ĞµĞ½Ğ¸Ñ | ĞŸĞ°Ñ€Ğ¾Ğ»Ğ¸, ĞºĞ»ÑÑ‡Ğ¸ API, Ğ½Ğ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ¸ Ğ‘Ğ” |
|| `docker-compose.yml` | Ğ˜Ğ½Ñ„Ñ€Ğ°ÑÑ‚Ñ€ÑƒĞºÑ‚ÑƒÑ€Ğ½Ñ‹Ğµ Ğ½Ğ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ¸ | ĞŸĞ¾Ñ€Ñ‚Ñ‹, volumes, Ğ¿ĞµÑ€ĞµĞ¼ĞµĞ½Ğ½Ñ‹Ğµ Ğ´Ğ»Ñ ĞºĞ¾Ğ½Ñ‚ĞµĞ¹Ğ½ĞµÑ€Ğ¾Ğ² |

### 6.2 Ğ¡Ğ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ğµ ĞºĞ¾Ğ½Ñ„Ğ¸Ğ³ÑƒÑ€Ğ°Ñ†Ğ¸Ğ¹ Ğ´Ğ»Ñ Ñ€Ğ°Ğ·Ğ½Ñ‹Ñ… Ğ°Ğ»Ğ³Ğ¾Ñ€Ğ¸Ñ‚Ğ¼Ğ¾Ğ²

**Ğ¦ĞµĞ½Ñ‚Ñ€Ğ°Ğ»Ğ¸Ğ·Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ğµ ĞºĞ¾Ğ½Ñ„Ğ¸Ğ³ÑƒÑ€Ğ°Ñ†Ğ¸Ğ¸ Ğ°Ğ»Ğ³Ğ¾Ñ€Ğ¸Ñ‚Ğ¼Ğ¾Ğ² Ğ² DAG:**

```python
# Ğ›Ğ¸Ğ½ĞµĞ¹Ğ½Ñ‹Ğµ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ (7 ĞºĞ¾Ğ½Ñ„Ğ¸Ğ³ÑƒÑ€Ğ°Ñ†Ğ¸Ğ¹)
LINEAR_MODELS = [
    {
        "name": "linear_regression",
        "params": {},
        "description": "Baseline Ğ»Ğ¸Ğ½ĞµĞ¹Ğ½Ğ°Ñ Ñ€ĞµĞ³Ñ€ĞµÑÑĞ¸Ñ",
    },
    {"name": "ridge", "params": {"alpha": 0.1}, "description": "Ridge Î±=0.1"},
    {"name": "ridge", "params": {"alpha": 1.0}, "description": "Ridge Î±=1.0"},
    {"name": "ridge", "params": {"alpha": 10.0}, "description": "Ridge Î±=10.0"},
    {"name": "lasso", "params": {"alpha": 0.1}, "description": "Lasso Î±=0.1"},
    {
        "name": "elastic_net",
        "params": {"alpha": 0.5, "l1_ratio": 0.5},
        "description": "ElasticNet",
    },
    {"name": "huber", "params": {"epsilon": 1.35}, "description": "Huber Regressor"},
]

# Ğ”Ñ€ĞµĞ²Ğ¾Ğ²Ğ¸Ğ´Ğ½Ñ‹Ğµ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ (9 ĞºĞ¾Ğ½Ñ„Ğ¸Ğ³ÑƒÑ€Ğ°Ñ†Ğ¸Ğ¹)
TREE_MODELS = [
    {
        "name": "decision_tree",
        "params": {"max_depth": 5},
        "description": "Decision Tree d=5",
    },
    {
        "name": "random_forest",
        "params": {"n_estimators": 100, "max_depth": 10},
        "description": "RF n=100",
    },
    {
        "name": "gradient_boosting",
        "params": {"n_estimators": 100, "learning_rate": 0.1},
        "description": "GBM lr=0.1",
    },
    # ... ĞµÑ‰Ñ‘ 6 ĞºĞ¾Ğ½Ñ„Ğ¸Ğ³ÑƒÑ€Ğ°Ñ†Ğ¸Ğ¹
]
```

**Ğ¤Ğ°Ğ±Ñ€Ğ¸ĞºĞ° Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ Ñ Ğ²Ğ°Ğ»Ğ¸Ğ´Ğ°Ñ†Ğ¸ĞµĞ¹:**

```python
def create_model(model_name: str, params: dict):
    """Ğ¡Ğ¾Ğ·Ğ´Ğ°Ñ‘Ñ‚ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ Ğ¿Ğ¾ Ğ¸Ğ¼ĞµĞ½Ğ¸ Ğ¸ Ğ¿Ğ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ğ°Ğ¼ Ñ Ğ²Ğ°Ğ»Ğ¸Ğ´Ğ°Ñ†Ğ¸ĞµĞ¹."""
    from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
    from sklearn.linear_model import LinearRegression, Ridge, Lasso

    models = {
        "linear_regression": LinearRegression,
        "ridge": Ridge,
        "lasso": Lasso,
        "random_forest": RandomForestRegressor,
        "gradient_boosting": GradientBoostingRegressor,
        # ... Ğ¾ÑÑ‚Ğ°Ğ»ÑŒĞ½Ñ‹Ğµ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸
    }

    model_class = models.get(model_name)
    if model_class is None:
        raise ValueError(f"ĞĞµĞ¸Ğ·Ğ²ĞµÑÑ‚Ğ½Ğ°Ñ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ: {model_name}")

    # Ğ’Ğ°Ğ»Ğ¸Ğ´Ğ°Ñ†Ğ¸Ñ Ğ¿Ğ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ğ¾Ğ² Ğ¿ĞµÑ€ĞµĞ´ ÑĞ¾Ğ·Ğ´Ğ°Ğ½Ğ¸ĞµĞ¼
    try:
        return model_class(**params)
    except TypeError as e:
        raise ValueError(f"ĞĞµĞºĞ¾Ñ€Ñ€ĞµĞºÑ‚Ğ½Ñ‹Ğµ Ğ¿Ğ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ñ‹ Ğ´Ğ»Ñ {model_name}: {e}")
```

### 6.3 ĞĞ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ° Ğ²Ğ°Ğ»Ğ¸Ğ´Ğ°Ñ†Ğ¸Ğ¸ ĞºĞ¾Ğ½Ñ„Ğ¸Ğ³ÑƒÑ€Ğ°Ñ†Ğ¸Ğ¹

**Ğ’Ğ°Ğ»Ğ¸Ğ´Ğ°Ñ†Ğ¸Ñ Ğ½Ğ° ÑƒÑ€Ğ¾Ğ²Ğ½Ğµ Airflow tasks:**

```python
@task
def validate_data(data_path: str) -> dict:
    """Ğ’Ğ°Ğ»Ğ¸Ğ´Ğ°Ñ†Ğ¸Ñ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ¸ Ğ¿Ğ¾Ğ´Ğ³Ğ¾Ñ‚Ğ¾Ğ²ĞºĞ° train/test split."""
    import pandas as pd
    from loguru import logger

    logger.info(f"ğŸ” Ğ’Ğ°Ğ»Ğ¸Ğ´Ğ°Ñ†Ğ¸Ñ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…: {data_path}")

    df = pd.read_csv(data_path, sep=r"\s+", header=None)

    # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ĞºĞ¸ ÑÑ…ĞµĞ¼Ñ‹ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…
    expected_columns = 14  # 13 Ğ¿Ñ€Ğ¸Ğ·Ğ½Ğ°ĞºĞ¾Ğ² + 1 Ñ†ĞµĞ»ĞµĞ²Ğ°Ñ Ğ¿ĞµÑ€ĞµĞ¼ĞµĞ½Ğ½Ğ°Ñ
    assert len(df.columns) == expected_columns, (
        f"ĞĞ¶Ğ¸Ğ´Ğ°Ğ»Ğ¾ÑÑŒ {expected_columns} ĞºĞ¾Ğ»Ğ¾Ğ½Ğ¾Ğº, Ğ¿Ğ¾Ğ»ÑƒÑ‡ĞµĞ½Ğ¾ {len(df.columns)}"
    )

    # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ĞºĞ° Ğ¿Ñ€Ğ¾Ğ¿ÑƒÑ‰ĞµĞ½Ğ½Ñ‹Ñ… Ğ·Ğ½Ğ°Ñ‡ĞµĞ½Ğ¸Ğ¹
    missing_values = df.isnull().sum().sum()
    assert missing_values == 0, f"ĞĞ±Ğ½Ğ°Ñ€ÑƒĞ¶ĞµĞ½Ğ¾ {missing_values} Ğ¿Ñ€Ğ¾Ğ¿ÑƒÑ‰ĞµĞ½Ğ½Ñ‹Ñ… Ğ·Ğ½Ğ°Ñ‡ĞµĞ½Ğ¸Ğ¹"

    # Ğ’Ğ°Ğ»Ğ¸Ğ´Ğ°Ñ†Ğ¸Ñ Ğ´Ğ¸Ğ°Ğ¿Ğ°Ğ·Ğ¾Ğ½Ğ¾Ğ²
    target = df.iloc[:, -1]  # ĞŸĞ¾ÑĞ»ĞµĞ´Ğ½ÑÑ ĞºĞ¾Ğ»Ğ¾Ğ½ĞºĞ° - Ñ†ĞµĞ»ĞµĞ²Ğ°Ñ
    assert target.min() > 0, "Ğ¦ĞµĞ»ĞµĞ²Ğ°Ñ Ğ¿ĞµÑ€ĞµĞ¼ĞµĞ½Ğ½Ğ°Ñ Ğ´Ğ¾Ğ»Ğ¶Ğ½Ğ° Ğ±Ñ‹Ñ‚ÑŒ Ğ¿Ğ¾Ğ»Ğ¾Ğ¶Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾Ğ¹"
    assert target.max() < 100, "Ğ¦ĞµĞ»ĞµĞ²Ğ°Ñ Ğ¿ĞµÑ€ĞµĞ¼ĞµĞ½Ğ½Ğ°Ñ Ğ¿Ñ€ĞµĞ²Ñ‹ÑˆĞ°ĞµÑ‚ Ñ€Ğ°Ğ·ÑƒĞ¼Ğ½Ñ‹Ğ¹ Ğ¼Ğ°ĞºÑĞ¸Ğ¼ÑƒĞ¼"

    logger.success(f"âœ… Ğ’Ğ°Ğ»Ğ¸Ğ´Ğ°Ñ†Ğ¸Ñ Ğ¿Ñ€Ğ¾Ğ¹Ğ´ĞµĞ½Ğ°: {len(df)} Ğ·Ğ°Ğ¿Ğ¸ÑĞµĞ¹")

    return {
        "n_samples": len(df),
        "n_features": len(df.columns) - 1,
        "target_mean": float(target.mean()),
        "target_std": float(target.std()),
    }
```

**Ğ’Ğ°Ğ»Ğ¸Ğ´Ğ°Ñ†Ğ¸Ñ Ğ¿ĞµÑ€ĞµĞ¼ĞµĞ½Ğ½Ñ‹Ñ… Ğ¾ĞºÑ€ÑƒĞ¶ĞµĞ½Ğ¸Ñ:**

```python
# src/config/mlflow_config.py
def setup_mlflow_env():
    """ĞĞ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ° Ğ¿ĞµÑ€ĞµĞ¼ĞµĞ½Ğ½Ñ‹Ñ… Ğ¾ĞºÑ€ÑƒĞ¶ĞµĞ½Ğ¸Ñ Ğ´Ğ»Ñ MLflow + S3 Ñ Ğ²Ğ°Ğ»Ğ¸Ğ´Ğ°Ñ†Ğ¸ĞµĞ¹."""

    # Ğ’Ğ°Ğ»Ğ¸Ğ´Ğ°Ñ†Ğ¸Ñ Ğ¾Ğ±ÑĞ·Ğ°Ñ‚ĞµĞ»ÑŒĞ½Ñ‹Ñ… Ğ¿ĞµÑ€ĞµĞ¼ĞµĞ½Ğ½Ñ‹Ñ…
    required_vars = [
        "MLFLOW_TRACKING_URI",
        "AWS_ACCESS_KEY_ID",
        "AWS_SECRET_ACCESS_KEY"
    ]

    missing_vars = []
    for var in required_vars:
        if not os.getenv(var):
            missing_vars.append(var)

    if missing_vars:
        raise EnvironmentError(
            f"ĞÑ‚ÑÑƒÑ‚ÑÑ‚Ğ²ÑƒÑÑ‚ Ğ¾Ğ±ÑĞ·Ğ°Ñ‚ĞµĞ»ÑŒĞ½Ñ‹Ğµ Ğ¿ĞµÑ€ĞµĞ¼ĞµĞ½Ğ½Ñ‹Ğµ Ğ¾ĞºÑ€ÑƒĞ¶ĞµĞ½Ğ¸Ñ: {missing_vars}"
        )

    # Ğ’Ğ°Ğ»Ğ¸Ğ´Ğ°Ñ†Ğ¸Ñ Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ‚Ğ¾Ğ²
    mlflow_uri = os.getenv("MLFLOW_TRACKING_URI")
    if not mlflow_uri.startswith(("http://", "https://")):
        raise ValueError(f"MLFLOW_TRACKING_URI Ğ´Ğ¾Ğ»Ğ¶ĞµĞ½ Ğ½Ğ°Ñ‡Ğ¸Ğ½Ğ°Ñ‚ÑŒÑÑ Ñ http:// Ğ¸Ğ»Ğ¸ https://")

    os.environ["MLFLOW_S3_ENDPOINT_URL"] = MLFLOW_S3_ENDPOINT_URL
    os.environ["AWS_ACCESS_KEY_ID"] = AWS_ACCESS_KEY_ID
    os.environ["AWS_SECRET_ACCESS_KEY"] = AWS_SECRET_ACCESS_KEY
```

### 6.4 Ğ¡Ğ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ğµ ÑĞ¸ÑÑ‚ĞµĞ¼Ñ‹ ĞºĞ¾Ğ¼Ğ¿Ğ¾Ğ·Ğ¸Ñ†Ğ¸Ğ¸ ĞºĞ¾Ğ½Ñ„Ğ¸Ğ³ÑƒÑ€Ğ°Ñ†Ğ¸Ğ¹

**ĞĞ°ÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ¸ Ğ¿ĞµÑ€ĞµĞ¾Ğ¿Ñ€ĞµĞ´ĞµĞ»ĞµĞ½Ğ¸Ğµ ĞºĞ¾Ğ½Ñ„Ğ¸Ğ³ÑƒÑ€Ğ°Ñ†Ğ¸Ğ¹:**

```python
# Ğ‘Ğ°Ğ·Ğ¾Ğ²Ñ‹Ğµ Ğ½Ğ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ¸ Ğ´Ğ»Ñ Ğ²ÑĞµÑ… ÑĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚Ğ¾Ğ²
BASE_EXPERIMENT_CONFIG = {
    "test_size": 0.2,
    "random_state": 42,
    "n_jobs": -1,
    "verbose": False,
}

# Ğ¡Ğ¿ĞµÑ†Ğ¸Ñ„Ğ¸Ñ‡Ğ½Ñ‹Ğµ Ğ½Ğ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ¸ Ğ´Ğ»Ñ ÑĞµĞ¼ĞµĞ¹ÑÑ‚Ğ² Ğ°Ğ»Ğ³Ğ¾Ñ€Ğ¸Ñ‚Ğ¼Ğ¾Ğ²
TREE_MODEL_DEFAULTS = {
    **BASE_EXPERIMENT_CONFIG,
    "max_features": "sqrt",
    "bootstrap": True,
}

ENSEMBLE_MODEL_DEFAULTS = {
    **TREE_MODEL_DEFAULTS,
    "n_estimators": 100,
    "warm_start": False,
}

# ĞšĞ¾Ğ¼Ğ¿Ğ¾Ğ·Ğ¸Ñ†Ğ¸Ñ Ñ„Ğ¸Ğ½Ğ°Ğ»ÑŒĞ½Ñ‹Ñ… ĞºĞ¾Ğ½Ñ„Ğ¸Ğ³ÑƒÑ€Ğ°Ñ†Ğ¸Ğ¹
def compose_model_config(base_config: dict, model_specific: dict) -> dict:
    """ĞšĞ¾Ğ¼Ğ¿Ğ¾Ğ·Ğ¸Ñ†Ğ¸Ñ ĞºĞ¾Ğ½Ñ„Ğ¸Ğ³ÑƒÑ€Ğ°Ñ†Ğ¸Ğ¹ Ñ Ğ¿Ñ€Ğ¸Ğ¾Ñ€Ğ¸Ñ‚ĞµÑ‚Ğ¾Ğ¼ ÑĞ¿ĞµÑ†Ğ¸Ñ„Ğ¸Ñ‡Ğ½Ñ‹Ñ… Ğ¿Ğ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ğ¾Ğ²."""

    # Ğ“Ğ»ÑƒĞ±Ğ¾ĞºĞ¾Ğµ ÑĞ»Ğ¸ÑĞ½Ğ¸Ğµ ĞºĞ¾Ğ½Ñ„Ğ¸Ğ³ÑƒÑ€Ğ°Ñ†Ğ¸Ğ¹
    result = base_config.copy()
    result.update(model_specific)

    # Ğ›Ğ¾Ğ³Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ¿Ñ€Ğ¸Ğ¼ĞµĞ½Ñ‘Ğ½Ğ½Ñ‹Ñ… Ğ½Ğ°ÑÑ‚Ñ€Ğ¾ĞµĞº
    logger.info(f"Ğ¤Ğ¸Ğ½Ğ°Ğ»ÑŒĞ½Ğ°Ñ ĞºĞ¾Ğ½Ñ„Ğ¸Ğ³ÑƒÑ€Ğ°Ñ†Ğ¸Ñ: {result}")

    return result

# Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ
random_forest_config = compose_model_config(
    ENSEMBLE_MODEL_DEFAULTS,
    {"max_depth": 10, "min_samples_split": 5}
)
```

**ĞŸĞµÑ€ĞµĞ¼ĞµĞ½Ğ½Ñ‹Ğµ Ğ¾ĞºÑ€ÑƒĞ¶ĞµĞ½Ğ¸Ñ Ñ Ğ¸ĞµÑ€Ğ°Ñ€Ñ…Ğ¸ĞµĞ¹:**

```bash
# .env - Ğ±Ğ°Ğ·Ğ¾Ğ²Ñ‹Ğµ Ğ½Ğ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ¸
MLFLOW_TRACKING_URI=http://localhost:5000
MLFLOW_EXPERIMENT_NAME=boston-housing

# ĞŸĞµÑ€ĞµĞ¾Ğ¿Ñ€ĞµĞ´ĞµĞ»ĞµĞ½Ğ¸Ğµ Ğ´Ğ»Ñ Ñ€Ğ°Ğ·Ğ½Ñ‹Ñ… Ğ¾ĞºÑ€ÑƒĞ¶ĞµĞ½Ğ¸Ğ¹  
# .env.development
MLFLOW_TRACKING_URI=http://localhost:5000
DEBUG=true

# .env.production  
MLFLOW_TRACKING_URI=https://mlflow.production.com
DEBUG=false
BATCH_SIZE=128
```

**ĞšĞ¾Ğ½Ñ„Ğ¸Ğ³ÑƒÑ€Ğ°Ñ†Ğ¸Ğ¾Ğ½Ğ½Ñ‹Ğµ ĞºĞ»Ğ°ÑÑÑ‹ Ñ Ğ²Ğ°Ğ»Ğ¸Ğ´Ğ°Ñ†Ğ¸ĞµĞ¹:**

```python
from pathlib import Path
from typing import Optional
import os

class ProjectConfig:
    """Ğ¦ĞµĞ½Ñ‚Ñ€Ğ°Ğ»ÑŒĞ½Ğ°Ñ ĞºĞ¾Ğ½Ñ„Ğ¸Ğ³ÑƒÑ€Ğ°Ñ†Ğ¸Ñ Ğ¿Ñ€Ğ¾ĞµĞºÑ‚Ğ° Ñ Ğ²Ğ°Ğ»Ğ¸Ğ´Ğ°Ñ†Ğ¸ĞµĞ¹."""

    def __init__(self):
        self.proj_root = Path(__file__).resolve().parents[2]
        self.data_dir = self.proj_root / "data"
        self.models_dir = self.data_dir / "models"

        # Ğ’Ğ°Ğ»Ğ¸Ğ´Ğ°Ñ†Ğ¸Ñ Ğ¿ÑƒÑ‚ĞµĞ¹
        if not self.data_dir.exists():
            self.data_dir.mkdir(parents=True)

    @property
    def mlflow_tracking_uri(self) -> str:
        uri = os.getenv("MLFLOW_TRACKING_URI", "http://localhost:5000")
        if not uri.startswith(("http://", "https://")):
            raise ValueError(f"ĞĞµĞºĞ¾Ñ€Ñ€ĞµĞºÑ‚Ğ½Ñ‹Ğ¹ MLFLOW_TRACKING_URI: {uri}")
        return uri

    @property
    def experiment_name(self) -> str:
        return os.getenv("MLFLOW_EXPERIMENT_NAME", "boston-housing")

    def validate(self) -> bool:
        """Ğ’Ğ°Ğ»Ğ¸Ğ´Ğ°Ñ†Ğ¸Ñ Ğ²ÑĞµĞ¹ ĞºĞ¾Ğ½Ñ„Ğ¸Ğ³ÑƒÑ€Ğ°Ñ†Ğ¸Ğ¸."""
        try:
            _ = self.mlflow_tracking_uri
            _ = self.experiment_name
            assert self.data_dir.exists()
            return True
        except (ValueError, AssertionError) as e:
            logger.error(f"ĞÑˆĞ¸Ğ±ĞºĞ° Ğ²Ğ°Ğ»Ğ¸Ğ´Ğ°Ñ†Ğ¸Ğ¸ ĞºĞ¾Ğ½Ñ„Ğ¸Ğ³ÑƒÑ€Ğ°Ñ†Ğ¸Ğ¸: {e}")
            return False

# Ğ“Ğ»Ğ¾Ğ±Ğ°Ğ»ÑŒĞ½Ñ‹Ğ¹ ÑĞºĞ·ĞµĞ¼Ğ¿Ğ»ÑÑ€
config = ProjectConfig()
```

---

## 7. Ğ˜Ğ½Ñ‚ĞµĞ³Ñ€Ğ°Ñ†Ğ¸Ñ Ğ¸ Ñ‚ĞµÑÑ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ ÑĞ¸ÑÑ‚ĞµĞ¼

### 7.1 Ğ˜Ğ½Ñ‚ĞµĞ³Ñ€Ğ°Ñ†Ğ¸Ñ Ğ²Ñ‹Ğ±Ñ€Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ¸Ğ½ÑÑ‚Ñ€ÑƒĞ¼ĞµĞ½Ñ‚Ğ¾Ğ²

**ĞÑ€Ñ…Ğ¸Ñ‚ĞµĞºÑ‚ÑƒÑ€Ğ° Ğ¸Ğ½Ñ‚ĞµĞ³Ñ€Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ğ¾Ğ¹ ÑĞ¸ÑÑ‚ĞµĞ¼Ñ‹:**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     Ğ˜Ğ½Ñ‚ĞµĞ³Ñ€Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ğ°Ñ ML ĞŸĞ»Ğ°Ñ‚Ñ„Ğ¾Ñ€Ğ¼Ğ°                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚   Apache Airflow â”‚    â”‚      MLflow      â”‚    â”‚      MinIO       â”‚   â”‚
â”‚  â”‚  (ĞÑ€ĞºĞµÑÑ‚Ñ€Ğ°Ñ†Ğ¸Ñ)   â”‚â—€â”€â”€â–¶â”‚   (Ğ¢Ñ€ĞµĞºĞ¸Ğ½Ğ³)      â”‚â—€â”€â”€â–¶â”‚   (Ğ¥Ñ€Ğ°Ğ½Ğ¸Ğ»Ğ¸Ñ‰Ğµ)    â”‚   â”‚
â”‚  â”‚                  â”‚    â”‚                  â”‚    â”‚                  â”‚   â”‚
â”‚  â”‚ â€¢ 3 DAG          â”‚    â”‚ â€¢ Ğ­ĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚Ñ‹   â”‚    â”‚ â€¢ ĞÑ€Ñ‚ĞµÑ„Ğ°ĞºÑ‚Ñ‹      â”‚   â”‚
â”‚  â”‚ â€¢ ĞŸĞ°Ñ€Ğ°Ğ»Ğ»ĞµĞ»Ğ¸Ğ·Ğ¼    â”‚    â”‚ â€¢ ĞœĞµÑ‚Ñ€Ğ¸ĞºĞ¸        â”‚    â”‚ â€¢ ĞšÑÑˆĞ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ    â”‚   â”‚
â”‚  â”‚ â€¢ ĞšÑÑˆĞ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ    â”‚    â”‚ â€¢ ĞœĞ¾Ğ´ĞµĞ»Ğ¸         â”‚    â”‚ â€¢ S3 API         â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚           â”‚                        â”‚                        â”‚           â”‚
â”‚           â–¼                        â–¼                        â–¼           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚                        ĞĞ±Ñ‰Ğ°Ñ Ğ¸Ğ½Ñ‚ĞµĞ³Ñ€Ğ°Ñ†Ğ¸Ñ                             â”‚ â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤ â”‚
â”‚  â”‚ â€¢ Docker Compose Ğ¾Ñ€ĞºĞµÑÑ‚Ñ€Ğ°Ñ†Ğ¸Ñ Ğ²ÑĞµÑ… ÑĞµÑ€Ğ²Ğ¸ÑĞ¾Ğ²                          â”‚ â”‚
â”‚  â”‚ â€¢ ĞĞ±Ñ‰Ğ¸Ğµ Ğ¿ĞµÑ€ĞµĞ¼ĞµĞ½Ğ½Ñ‹Ğµ Ğ¾ĞºÑ€ÑƒĞ¶ĞµĞ½Ğ¸Ñ (.env)                                 â”‚ â”‚
â”‚  â”‚ â€¢ Ğ•Ğ´Ğ¸Ğ½Ğ°Ñ Ğ°ÑƒÑ‚ĞµĞ½Ñ‚Ğ¸Ñ„Ğ¸ĞºĞ°Ñ†Ğ¸Ñ (Nginx + Basic Auth)                       â”‚ â”‚
â”‚  â”‚ â€¢ ĞœĞ¾Ğ½Ğ¸Ñ‚Ğ¾Ñ€Ğ¸Ğ½Ğ³ Ñ‡ĞµÑ€ĞµĞ· ÑÑ‚Ñ€ÑƒĞºÑ‚ÑƒÑ€Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ğµ Ğ»Ğ¾Ğ³Ğ¸ (loguru)                  â”‚ â”‚
â”‚  â”‚ â€¢ ĞĞ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ğµ ÑƒĞ²ĞµĞ´Ğ¾Ğ¼Ğ»ĞµĞ½Ğ¸Ñ Ğ² Airflow UI + MLflow UI              â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**ĞšĞ»ÑÑ‡ĞµĞ²Ñ‹Ğµ Ñ‚Ğ¾Ñ‡ĞºĞ¸ Ğ¸Ğ½Ñ‚ĞµĞ³Ñ€Ğ°Ñ†Ğ¸Ğ¸:**

### **1. Airflow â†’ MLflow Ğ¸Ğ½Ñ‚ĞµĞ³Ñ€Ğ°Ñ†Ğ¸Ñ**

```python
# Ğ’ Airflow DAG
def generate_report(aggregated: dict) -> dict:
    """ĞĞ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¾Ğµ Ğ»Ğ¾Ğ³Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ğ¾Ğ² Ğ² MLflow Ğ¸Ğ· Airflow."""

    import mlflow

    mlflow_uri = os.environ.get("MLFLOW_TRACKING_URI", "http://mlflow:5000")
    mlflow.set_tracking_uri(mlflow_uri)
    mlflow.set_experiment("boston_housing_experiments")

    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")

    with mlflow.start_run(run_name=f"experiments_summary_{timestamp}"):
        # Ğ›Ğ¾Ğ³Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ°Ğ³Ñ€ĞµĞ³Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ¼ĞµÑ‚Ñ€Ğ¸Ğº
        mlflow.log_metric("total_experiments", aggregated["total_experiments"])
        mlflow.log_metric("best_r2", aggregated["summary"]["best_r2"])
        mlflow.log_metric("mean_r2", aggregated["summary"]["mean_r2"])

        # Ğ›Ğ¾Ğ³Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ¿Ğ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ğ¾Ğ² Ğ»ÑƒÑ‡ÑˆĞµĞ¹ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸
        mlflow.log_param("best_model", aggregated["best_model"]["run_id"])

        # Ğ›Ğ¾Ğ³Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ°Ñ€Ñ‚ĞµÑ„Ğ°ĞºÑ‚Ğ¾Ğ²
        mlflow.log_artifact(report_path, "reports")
        mlflow.log_artifact(aggregated["results_path"], "results")

        # Ğ¢ĞµĞ³Ğ¸ Ğ´Ğ»Ñ Ğ¸Ğ´ĞµĞ½Ñ‚Ğ¸Ñ„Ğ¸ĞºĞ°Ñ†Ğ¸Ğ¸ Ğ¸ÑÑ‚Ğ¾Ñ‡Ğ½Ğ¸ĞºĞ°
        mlflow.set_tag("source", "airflow")
        mlflow.set_tag("dag", "boston_housing_experiments")
```

### **2. Airflow â†’ MinIO Ğ¸Ğ½Ñ‚ĞµĞ³Ñ€Ğ°Ñ†Ğ¸Ñ**

```python
# ĞšÑÑˆĞ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ°Ñ€Ñ‚ĞµÑ„Ğ°ĞºÑ‚Ğ¾Ğ² Ğ² MinIO Ğ¸Ğ· Airflow
class MinIOCache:
    def __init__(self):
        # Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµĞ¼ Ñ‚Ğµ Ğ¶Ğµ Ğ¿ĞµÑ€ĞµĞ¼ĞµĞ½Ğ½Ñ‹Ğµ Ğ¾ĞºÑ€ÑƒĞ¶ĞµĞ½Ğ¸Ñ Ñ‡Ñ‚Ğ¾ Ğ¸ Ğ² Airflow
        self.endpoint_url = os.environ.get("MLFLOW_S3_ENDPOINT_URL", "http://minio:9000")
        self.access_key = os.environ.get("AWS_ACCESS_KEY_ID", "minioadmin")
        self.secret_key = os.environ.get("AWS_SECRET_ACCESS_KEY", "minioadmin")

        self.client = boto3.client(
            "s3",
            endpoint_url=self.endpoint_url,
            aws_access_key_id=self.access_key,
            aws_secret_access_key=self.secret_key,
        )

# Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ² Airflow task
@task
def save_to_cache(train_result: dict) -> dict:
    """Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ğ¸Ğµ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ Ğ² MinIO Ñ Ğ°Ğ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¾Ğ¹ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸ĞµĞ¹ ĞºĞ»ÑÑ‡ĞµĞ¹."""

    from minio_cache import save_model_to_cache

    model_uri = save_model_to_cache(
        model_path=train_result["model_path"],
        model_name="random_forest_cached",
        params=train_result["params"],
        data_path=train_result["data_path"],
        metrics=train_result["metrics"],
        bucket_name="airflow-cache",
    )

    return {"status": "saved", "cache_uri": model_uri}
```

### **3. MLflow â†’ MinIO Ğ¸Ğ½Ñ‚ĞµĞ³Ñ€Ğ°Ñ†Ğ¸Ñ**

```python
# MLflow Ğ°Ğ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¸ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµÑ‚ MinIO Ğ´Ğ»Ñ Ğ°Ñ€Ñ‚ĞµÑ„Ğ°ĞºÑ‚Ğ¾Ğ²
# ĞĞ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ° Ğ² Ğ¿ĞµÑ€ĞµĞ¼ĞµĞ½Ğ½Ñ‹Ñ… Ğ¾ĞºÑ€ÑƒĞ¶ĞµĞ½Ğ¸Ñ:

MLFLOW_S3_ENDPOINT_URL=http://minio:9000
AWS_ACCESS_KEY_ID=minioadmin  
AWS_SECRET_ACCESS_KEY=minioadmin

# Ğ’ÑĞµ Ğ°Ñ€Ñ‚ĞµÑ„Ğ°ĞºÑ‚Ñ‹ MLflow Ğ°Ğ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¸ ÑĞ¾Ñ…Ñ€Ğ°Ğ½ÑÑÑ‚ÑÑ Ğ² MinIO
mlflow.sklearn.log_model(model, "model")  # â†’ s3://mlflow-artifacts/...
mlflow.log_artifact("report.html")        # â†’ s3://mlflow-artifacts/...
```

### 7.2 Ğ¡Ğ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ğµ ÑĞ¸ÑÑ‚ĞµĞ¼Ñ‹ Ğ¼Ğ¾Ğ½Ğ¸Ñ‚Ğ¾Ñ€Ğ¸Ğ½Ğ³Ğ° Ğ²Ñ‹Ğ¿Ğ¾Ğ»Ğ½ĞµĞ½Ğ¸Ñ

**ĞœĞ½Ğ¾Ğ³Ğ¾ÑƒÑ€Ğ¾Ğ²Ğ½ĞµĞ²Ğ°Ñ ÑĞ¸ÑÑ‚ĞµĞ¼Ğ° Ğ¼Ğ¾Ğ½Ğ¸Ñ‚Ğ¾Ñ€Ğ¸Ğ½Ğ³Ğ°:**

### **Ğ£Ñ€Ğ¾Ğ²ĞµĞ½ÑŒ 1: Ğ¡Ñ‚Ñ€ÑƒĞºÑ‚ÑƒÑ€Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ğµ Ğ»Ğ¾Ğ³Ğ¸ (loguru)**

```python
from loguru import logger

# ĞšĞ¾Ğ½Ñ„Ğ¸Ğ³ÑƒÑ€Ğ°Ñ†Ğ¸Ñ Ğ»Ğ¾Ğ³Ğ³ĞµÑ€Ğ° Ğ² src/config.py
logger.remove(0)  # Ğ£Ğ´Ğ°Ğ»ÑĞµĞ¼ ÑÑ‚Ğ°Ğ½Ğ´Ğ°Ñ€Ñ‚Ğ½Ñ‹Ğ¹ Ñ…ÑĞ½Ğ´Ğ»ĞµÑ€
logger.add(
    sys.stderr,
    format="<green>{time:YYYY-MM-DD HH:mm:ss}</green> | "
           "<level>{level: <8}</level> | "
           "<cyan>{name}</cyan>:<cyan>{function}</cyan>:<cyan>{line}</cyan> - "
           "<level>{message}</level>",
    level="INFO"
)

# Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ² ML Ğ¿Ğ°Ğ¹Ğ¿Ğ»Ğ°Ğ¹Ğ½Ğ°Ñ…
@task
def train_single_model(model_config: dict, data_info: dict) -> dict:
    """ĞĞ±ÑƒÑ‡ĞµĞ½Ğ¸Ğµ Ñ Ğ¿Ğ¾Ğ´Ñ€Ğ¾Ğ±Ğ½Ñ‹Ğ¼ Ğ»Ğ¾Ğ³Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸ĞµĞ¼."""

    model_name = model_config["name"]
    params = model_config["params"]

    logger.info(f"ğŸš€ ĞĞ°Ñ‡Ğ°Ğ»Ğ¾ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ: {model_name}")
    logger.debug(f"   ĞŸĞ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ñ‹: {params}")
    logger.debug(f"   Ğ Ğ°Ğ·Ğ¼ĞµÑ€ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…: train={data_info['n_train']}, test={data_info['n_test']}")

    start_time = time.time()

    try:
        # ĞĞ±ÑƒÑ‡ĞµĞ½Ğ¸Ğµ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸
        model = create_model(model_name, params)
        model.fit(X_train, y_train)

        train_time = time.time() - start_time
        logger.info(f"âœ… ĞĞ±ÑƒÑ‡ĞµĞ½Ğ¸Ğµ Ğ·Ğ°Ğ²ĞµÑ€ÑˆĞµĞ½Ğ¾ Ğ·Ğ° {train_time:.2f}Ñ")

        # Ğ’Ñ‹Ñ‡Ğ¸ÑĞ»ĞµĞ½Ğ¸Ğµ Ğ¼ĞµÑ‚Ñ€Ğ¸Ğº
        y_pred = model.predict(X_test)
        metrics = {
            "r2_score": float(r2_score(y_test, y_pred)),
            "rmse": float(np.sqrt(mean_squared_error(y_test, y_pred))),
        }

        logger.success(f"ğŸ“Š ĞœĞµÑ‚Ñ€Ğ¸ĞºĞ¸: RÂ²={metrics['r2_score']:.4f}, RMSE={metrics['rmse']:.4f}")

        return {
            "run_id": f"{model_name}_{params_str}",
            "metrics": metrics,
            "train_time": train_time,
        }

    except Exception as e:
        logger.error(f"âŒ ĞÑˆĞ¸Ğ±ĞºĞ° Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ {model_name}: {e}")
        raise
```

### **Ğ£Ñ€Ğ¾Ğ²ĞµĞ½ÑŒ 2: ĞœĞ¾Ğ½Ğ¸Ñ‚Ğ¾Ñ€Ğ¸Ğ½Ğ³ Airflow**

```python
# ĞĞ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ¸ Ğ¼Ğ¾Ğ½Ğ¸Ñ‚Ğ¾Ñ€Ğ¸Ğ½Ğ³Ğ° Ğ² default_args DAG
default_args = {
    "owner": "boston_housing",
    "depends_on_past": False,
    "email_on_failure": False,    # ĞÑ‚ĞºĞ»ÑÑ‡Ğ°ĞµĞ¼ email, Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµĞ¼ UI
    "email_on_retry": False,
    "retries": 1,
    "retry_delay": timedelta(minutes=2),
    "on_failure_callback": log_failure_callback,
    "on_success_callback": log_success_callback,
}

def log_failure_callback(context):
    """Callback Ğ¿Ñ€Ğ¸ Ğ½ĞµÑƒĞ´Ğ°Ñ‡Ğ½Ğ¾Ğ¼ Ğ²Ñ‹Ğ¿Ğ¾Ğ»Ğ½ĞµĞ½Ğ¸Ğ¸ Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ¸."""
    task_instance = context.get('task_instance')
    dag_run = context.get('dag_run')

    logger.error(f"ğŸ”¥ Task failed: {task_instance.dag_id}.{task_instance.task_id}")
    logger.error(f"   DAG run: {dag_run.run_id}")
    logger.error(f"   Execution date: {context.get('execution_date')}")

    # ĞœĞ¾Ğ¶Ğ½Ğ¾ Ğ´Ğ¾Ğ±Ğ°Ğ²Ğ¸Ñ‚ÑŒ Ğ¾Ñ‚Ğ¿Ñ€Ğ°Ğ²ĞºÑƒ Ğ² Ğ²Ğ½ĞµÑˆĞ½Ğ¸Ğµ ÑĞ¸ÑÑ‚ĞµĞ¼Ñ‹ Ğ¼Ğ¾Ğ½Ğ¸Ñ‚Ğ¾Ñ€Ğ¸Ğ½Ğ³Ğ°
    # send_alert_to_slack(task_instance, dag_run)

def log_success_callback(context):
    """Callback Ğ¿Ñ€Ğ¸ ÑƒÑĞ¿ĞµÑˆĞ½Ğ¾Ğ¼ Ğ²Ñ‹Ğ¿Ğ¾Ğ»Ğ½ĞµĞ½Ğ¸Ğ¸ Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ¸."""
    task_instance = context.get('task_instance')
    duration = task_instance.end_date - task_instance.start_date

    logger.success(f"âœ… Task completed: {task_instance.dag_id}.{task_instance.task_id}")
    logger.info(f"   Duration: {duration.total_seconds():.2f}s")
```

### **Ğ£Ñ€Ğ¾Ğ²ĞµĞ½ÑŒ 3: ĞœĞ¾Ğ½Ğ¸Ñ‚Ğ¾Ñ€Ğ¸Ğ½Ğ³ Ñ‡ĞµÑ€ĞµĞ· MLflow UI**

```python
# ĞĞ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¾Ğµ Ğ»Ğ¾Ğ³Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ ÑĞ¸ÑÑ‚ĞµĞ¼Ğ½Ñ‹Ñ… Ğ¼ĞµÑ‚Ñ€Ğ¸Ğº
@mlflow_run(experiment_name="boston-housing")
def train_with_monitoring(model_name: str, params: dict):
    """ĞĞ±ÑƒÑ‡ĞµĞ½Ğ¸Ğµ Ñ Ğ¼Ğ¾Ğ½Ğ¸Ñ‚Ğ¾Ñ€Ğ¸Ğ½Ğ³Ğ¾Ğ¼ Ğ¿Ñ€Ğ¾Ğ¸Ğ·Ğ²Ğ¾Ğ´Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ÑÑ‚Ğ¸."""

    import psutil
    import time

    # ĞœĞ¾Ğ½Ğ¸Ñ‚Ğ¾Ñ€Ğ¸Ğ½Ğ³ Ñ€ĞµÑÑƒÑ€ÑĞ¾Ğ²
    process = psutil.Process()
    start_memory = process.memory_info().rss / 1024 / 1024  # MB
    start_cpu_percent = process.cpu_percent()

    # Ğ›Ğ¾Ğ³Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ ÑĞ¸ÑÑ‚ĞµĞ¼Ğ½Ğ¾Ğ¹ Ğ¸Ğ½Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ†Ğ¸Ğ¸
    mlflow.log_param("system_memory_gb", psutil.virtual_memory().total / 1024**3)
    mlflow.log_param("system_cpu_count", psutil.cpu_count())
    mlflow.log_param("start_memory_mb", start_memory)

    start_time = time.time()

    # ĞĞ±ÑƒÑ‡ĞµĞ½Ğ¸Ğµ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸
    model = train_model(model_name, params)

    # ĞœĞ¾Ğ½Ğ¸Ñ‚Ğ¾Ñ€Ğ¸Ğ½Ğ³ Ğ¿Ğ¾ÑĞ»Ğµ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ
    end_time = time.time()
    end_memory = process.memory_info().rss / 1024 / 1024  # MB
    memory_delta = end_memory - start_memory

    # Ğ›Ğ¾Ğ³Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ¼ĞµÑ‚Ñ€Ğ¸Ğº Ğ¿Ñ€Ğ¾Ğ¸Ğ·Ğ²Ğ¾Ğ´Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ÑÑ‚Ğ¸
    mlflow.log_metric("train_time_seconds", end_time - start_time)
    mlflow.log_metric("memory_usage_mb", end_memory)
    mlflow.log_metric("memory_delta_mb", memory_delta)
    mlflow.log_metric("cpu_percent", process.cpu_percent())

    return model
```

### 7.3 ĞĞ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ° ÑƒĞ²ĞµĞ´Ğ¾Ğ¼Ğ»ĞµĞ½Ğ¸Ğ¹ Ğ¾ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ğ°Ñ…

**Ğ¡Ğ¸ÑÑ‚ĞµĞ¼Ğ° ÑƒĞ²ĞµĞ´Ğ¾Ğ¼Ğ»ĞµĞ½Ğ¸Ğ¹ Ñ‡ĞµÑ€ĞµĞ· Ğ¸Ğ½Ñ‚ĞµÑ€Ñ„ĞµĞ¹ÑÑ‹:**

### **1. Airflow UI Dashboard**

```python
# ĞšĞ°ÑÑ‚Ğ¾Ğ¼Ğ½Ñ‹Ğµ Ğ¾Ğ¿ĞµÑ€Ğ°Ñ‚Ğ¾Ñ€Ñ‹ Ğ´Ğ»Ñ ÑĞ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ñ rich-ÑƒĞ²ĞµĞ´Ğ¾Ğ¼Ğ»ĞµĞ½Ğ¸Ğ¹
from airflow.operators.bash import BashOperator
from airflow.operators.python import PythonOperator

@task
def send_completion_notification(results: dict) -> dict:
    """Ğ¡Ğ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ğµ ÑƒĞ²ĞµĞ´Ğ¾Ğ¼Ğ»ĞµĞ½Ğ¸Ñ Ğ¾ Ğ·Ğ°Ğ²ĞµÑ€ÑˆĞµĞ½Ğ¸Ğ¸ ÑĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚Ğ°."""

    total_experiments = results.get("total_experiments", 0)
    best_r2 = results.get("summary", {}).get("best_r2", 0)
    best_model = results.get("best_model", {}).get("run_id", "unknown")

    # Ğ¡Ğ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ğµ Ğ¿Ğ¾Ğ´Ñ€Ğ¾Ğ±Ğ½Ğ¾Ğ³Ğ¾ ÑÑ‚Ğ°Ñ‚ÑƒÑĞ° Ğ´Ğ»Ñ Airflow UI
    notification = {
        "status": "SUCCESS" if best_r2 > 0.8 else "WARNING",
        "summary": f"Ğ—Ğ°Ğ²ĞµÑ€ÑˆĞµĞ½Ğ¾ {total_experiments} ÑĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚Ğ¾Ğ²",
        "best_result": f"Ğ›ÑƒÑ‡ÑˆĞ°Ñ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ: {best_model} (RÂ²={best_r2:.4f})",
        "timestamp": datetime.now().isoformat(),
    }

    # Ğ›Ğ¾Ğ³Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ´Ğ»Ñ Ğ¾Ñ‚Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ñ Ğ² Airflow UI
    logger.info("=" * 60)
    logger.info("ğŸ‰ Ğ­ĞšĞ¡ĞŸĞ•Ğ Ğ˜ĞœĞ•ĞĞ¢Ğ« Ğ—ĞĞ’Ğ•Ğ Ğ¨Ğ•ĞĞ«")
    logger.info("=" * 60)
    logger.info(f"ğŸ“Š Ğ’ÑĞµĞ³Ğ¾ ÑĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚Ğ¾Ğ²: {total_experiments}")
    logger.info(f"ğŸ† Ğ›ÑƒÑ‡ÑˆĞ¸Ğ¹ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚: RÂ² = {best_r2:.4f}")
    logger.info(f"ğŸ¤– Ğ›ÑƒÑ‡ÑˆĞ°Ñ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ: {best_model}")
    logger.info("=" * 60)

    return notification
```

### **2. MLflow UI Ğ¸Ğ½Ñ‚ĞµĞ³Ñ€Ğ°Ñ†Ğ¸Ñ**

```python
# ĞĞ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¾Ğµ ÑĞ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ğµ ÑĞ²Ğ¾Ğ´Ğ½Ñ‹Ñ… run'Ğ¾Ğ² Ğ² MLflow
@task
def create_mlflow_summary(aggregated_results: dict) -> dict:
    """Ğ¡Ğ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ğµ ÑĞ²Ğ¾Ğ´Ğ½Ğ¾Ğ³Ğ¾ run'Ğ° Ğ² MLflow Ñ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ğ°Ğ¼Ğ¸ Ğ²ÑĞµÑ… ÑĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚Ğ¾Ğ²."""

    import mlflow

    mlflow.set_experiment("boston_housing_summary")

    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")

    with mlflow.start_run(run_name=f"batch_summary_{timestamp}"):

        # Ğ›Ğ¾Ğ³Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ°Ğ³Ñ€ĞµĞ³Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ¼ĞµÑ‚Ñ€Ğ¸Ğº
        summary = aggregated_results["summary"]
        mlflow.log_metric("experiments_count", aggregated_results["total_experiments"])
        mlflow.log_metric("best_r2_score", summary["best_r2"])
        mlflow.log_metric("mean_r2_score", summary["mean_r2"])
        mlflow.log_metric("std_r2_score", summary["std_r2"])
        mlflow.log_metric("worst_r2_score", summary["worst_r2"])

        # Ğ¡Ğ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ğµ Ğ²Ğ¸Ğ·ÑƒĞ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ğ¾Ğ²
        results_df = pd.read_csv(aggregated_results["results_path"])

        # Ğ“Ñ€Ğ°Ñ„Ğ¸Ğº ÑÑ€Ğ°Ğ²Ğ½ĞµĞ½Ğ¸Ñ Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹
        fig, ax = plt.subplots(figsize=(12, 8))
        results_df.plot(x='run_id', y='r2_score', kind='bar', ax=ax)
        ax.set_title('Ğ¡Ñ€Ğ°Ğ²Ğ½ĞµĞ½Ğ¸Ğµ RÂ² Score Ğ¿Ğ¾ Ğ¼Ğ¾Ğ´ĞµĞ»ÑĞ¼')
        ax.set_xlabel('ĞœĞ¾Ğ´ĞµĞ»ÑŒ')
        ax.set_ylabel('RÂ² Score')
        plt.xticks(rotation=45, ha='right')
        plt.tight_layout()

        plot_path = "/tmp/models_comparison.png"
        plt.savefig(plot_path, dpi=300, bbox_inches='tight')
        mlflow.log_artifact(plot_path, "plots")

        # Ğ¢ĞµĞ³Ğ¸ Ğ´Ğ»Ñ Ğ½Ğ°Ğ²Ğ¸Ğ³Ğ°Ñ†Ğ¸Ğ¸
        mlflow.set_tag("experiment_type", "batch_comparison")
        mlflow.set_tag("source", "airflow_batch")
        mlflow.set_tag("algorithms_count", len(results_df))

        logger.success("âœ… Ğ¡Ğ²Ğ¾Ğ´Ğ½Ñ‹Ğ¹ Ğ¾Ñ‚Ñ‡Ñ‘Ñ‚ ÑĞ¾Ğ·Ğ´Ğ°Ğ½ Ğ² MLflow")

        return {
            "mlflow_run_id": mlflow.active_run().info.run_id,
            "summary_created": True
        }
```

### **3. Ğ˜Ğ½Ñ‚ĞµĞ³Ñ€Ğ°Ñ†Ğ¸Ñ Ñ Ğ²Ğ½ĞµÑˆĞ½Ğ¸Ğ¼Ğ¸ ÑĞ¸ÑÑ‚ĞµĞ¼Ğ°Ğ¼Ğ¸**

```python
# ĞĞ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ° webhook'Ğ¾Ğ² Ğ´Ğ»Ñ Ğ²Ğ½ĞµÑˆĞ½Ğ¸Ñ… ÑƒĞ²ĞµĞ´Ğ¾Ğ¼Ğ»ĞµĞ½Ğ¸Ğ¹
@task
def send_webhook_notification(results: dict) -> dict:
    """ĞÑ‚Ğ¿Ñ€Ğ°Ğ²ĞºĞ° webhook ÑƒĞ²ĞµĞ´Ğ¾Ğ¼Ğ»ĞµĞ½Ğ¸Ñ Ğ²Ğ¾ Ğ²Ğ½ĞµÑˆĞ½Ğ¸Ğµ ÑĞ¸ÑÑ‚ĞµĞ¼Ñ‹."""

    import requests

    webhook_url = os.environ.get("WEBHOOK_URL")
    if not webhook_url:
        logger.warning("WEBHOOK_URL Ğ½Ğµ Ğ½Ğ°ÑÑ‚Ñ€Ğ¾ĞµĞ½, Ğ¿Ñ€Ğ¾Ğ¿ÑƒÑĞºĞ°ĞµĞ¼ Ğ²Ğ½ĞµÑˆĞ½Ğ¸Ğµ ÑƒĞ²ĞµĞ´Ğ¾Ğ¼Ğ»ĞµĞ½Ğ¸Ñ")
        return {"status": "skipped"}

    payload = {
        "text": f"ğŸ¤– ML Pipeline Ğ·Ğ°Ğ²ĞµÑ€ÑˆÑ‘Ğ½",
        "attachments": [{
            "color": "good" if results["summary"]["best_r2"] > 0.8 else "warning",
            "fields": [
                {
                    "title": "Ğ­ĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚Ğ¾Ğ²",
                    "value": str(results["total_experiments"]),
                    "short": True
                },
                {
                    "title": "Ğ›ÑƒÑ‡ÑˆĞ¸Ğ¹ RÂ²",
                    "value": f"{results['summary']['best_r2']:.4f}",
                    "short": True
                },
                {
                    "title": "Ğ›ÑƒÑ‡ÑˆĞ°Ñ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ",
                    "value": results["best_model"]["run_id"],
                    "short": False
                }
            ]
        }]
    }

    try:
        response = requests.post(webhook_url, json=payload, timeout=10)
        response.raise_for_status()
        logger.success("âœ… Webhook ÑƒĞ²ĞµĞ´Ğ¾Ğ¼Ğ»ĞµĞ½Ğ¸Ğµ Ğ¾Ñ‚Ğ¿Ñ€Ğ°Ğ²Ğ»ĞµĞ½Ğ¾")
        return {"status": "sent", "response_code": response.status_code}
    except requests.RequestException as e:
        logger.warning(f"âš ï¸ ĞÑˆĞ¸Ğ±ĞºĞ° Ğ¾Ñ‚Ğ¿Ñ€Ğ°Ğ²ĞºĞ¸ webhook: {e}")
        return {"status": "error", "error": str(e)}
```

### 7.4 Ğ¢ĞµÑÑ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ²Ğ¾ÑĞ¿Ñ€Ğ¾Ğ¸Ğ·Ğ²Ğ¾Ğ´Ğ¸Ğ¼Ğ¾ÑÑ‚Ğ¸

**Ğ¡Ğ¸ÑÑ‚ĞµĞ¼Ğ° Ğ¾Ğ±ĞµÑĞ¿ĞµÑ‡ĞµĞ½Ğ¸Ñ Ğ²Ğ¾ÑĞ¿Ñ€Ğ¾Ğ¸Ğ·Ğ²Ğ¾Ğ´Ğ¸Ğ¼Ğ¾ÑÑ‚Ğ¸ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ğ¾Ğ²:**

### **1. Ğ”ĞµÑ‚ĞµÑ€Ğ¼Ğ¸Ğ½Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ğ¾ÑÑ‚ÑŒ Ñ‡ĞµÑ€ĞµĞ· Ñ„Ğ¸ĞºÑĞ°Ñ†Ğ¸Ñ seed'Ğ¾Ğ²**

```python
# Ğ“Ğ»Ğ¾Ğ±Ğ°Ğ»ÑŒĞ½Ğ°Ñ Ğ½Ğ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ° random seed Ğ²Ğ¾ Ğ²ÑĞµÑ… ÑĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚Ğ°Ñ…
def set_reproducible_environment(random_state: int = 42):
    """ĞĞ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ° Ğ¾ĞºÑ€ÑƒĞ¶ĞµĞ½Ğ¸Ñ Ğ´Ğ»Ñ Ğ²Ğ¾ÑĞ¿Ñ€Ğ¾Ğ¸Ğ·Ğ²Ğ¾Ğ´Ğ¸Ğ¼Ñ‹Ñ… Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ğ¾Ğ²."""

    import random
    import numpy as np
    import os

    # Python random
    random.seed(random_state)

    # NumPy random  
    np.random.seed(random_state)

    # Scikit-learn Ğ¿Ğ¾ ÑƒĞ¼Ğ¾Ğ»Ñ‡Ğ°Ğ½Ğ¸Ñ
    os.environ['PYTHONHASHSEED'] = str(random_state)

    logger.info(f"ğŸ”’ Ğ£ÑÑ‚Ğ°Ğ½Ğ¾Ğ²Ğ»ĞµĞ½ random_state={random_state} Ğ´Ğ»Ñ Ğ²Ğ¾ÑĞ¿Ñ€Ğ¾Ğ¸Ğ·Ğ²Ğ¾Ğ´Ğ¸Ğ¼Ğ¾ÑÑ‚Ğ¸")

# ĞŸÑ€Ğ¸Ğ¼ĞµĞ½ĞµĞ½Ğ¸Ğµ Ğ²Ğ¾ Ğ²ÑĞµÑ… Ğ¼Ğ¾Ğ´ĞµĞ»ÑÑ…
BASE_EXPERIMENT_CONFIG = {
    "random_state": 42,
    "test_size": 0.2,
}

# Ğ’ÑĞµ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ Ğ½Ğ°ÑĞ»ĞµĞ´ÑƒÑÑ‚ Ğ´ĞµÑ‚ĞµÑ€Ğ¼Ğ¸Ğ½Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ğ¾ÑÑ‚ÑŒ
def create_model(model_name: str, params: dict):
    """Ğ¡Ğ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ğµ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ Ñ Ğ¿Ñ€Ğ¸Ğ½ÑƒĞ´Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾Ğ¹ ÑƒÑÑ‚Ğ°Ğ½Ğ¾Ğ²ĞºĞ¾Ğ¹ random_state."""

    # ĞŸÑ€Ğ¸Ğ½ÑƒĞ´Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ Ğ´Ğ¾Ğ±Ğ°Ğ²Ğ»ÑĞµĞ¼ random_state ĞµÑĞ»Ğ¸ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ ĞµĞ³Ğ¾ Ğ¿Ğ¾Ğ´Ğ´ĞµÑ€Ğ¶Ğ¸Ğ²Ğ°ĞµÑ‚
    if hasattr(model_class, '_check_n_features') and 'random_state' not in params:
        params['random_state'] = BASE_EXPERIMENT_CONFIG['random_state']

    return model_class(**params)
```

### **2. ĞšÑÑˆĞ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ´Ğ»Ñ Ğ¿Ñ€Ğ¾Ğ²ĞµÑ€ĞºĞ¸ Ğ¸Ğ´ĞµĞ½Ñ‚Ğ¸Ñ‡Ğ½Ğ¾ÑÑ‚Ğ¸**

```python
class ReproducibilityTester:
    """ĞšĞ»Ğ°ÑÑ Ğ´Ğ»Ñ Ñ‚ĞµÑÑ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ Ğ²Ğ¾ÑĞ¿Ñ€Ğ¾Ğ¸Ğ·Ğ²Ğ¾Ğ´Ğ¸Ğ¼Ğ¾ÑÑ‚Ğ¸ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ğ¾Ğ²."""

    def __init__(self, cache: MinIOCache):
        self.cache = cache

    def test_model_reproducibility(
        self,
        model_name: str,
        params: dict,
        data_path: str,
        tolerance: float = 1e-6
    ) -> dict:
        """
        Ğ¢ĞµÑÑ‚Ğ¸Ñ€ÑƒĞµÑ‚ Ğ²Ğ¾ÑĞ¿Ñ€Ğ¾Ğ¸Ğ·Ğ²Ğ¾Ğ´Ğ¸Ğ¼Ğ¾ÑÑ‚ÑŒ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ Ğ¿ÑƒÑ‚Ñ‘Ğ¼ Ğ´Ğ²Ğ¾Ğ¹Ğ½Ğ¾Ğ³Ğ¾ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ.

        Returns:
            dict Ñ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ğ°Ğ¼Ğ¸ Ñ‚ĞµÑÑ‚Ğ° Ğ²Ğ¾ÑĞ¿Ñ€Ğ¾Ğ¸Ğ·Ğ²Ğ¾Ğ´Ğ¸Ğ¼Ğ¾ÑÑ‚Ğ¸
        """
        logger.info(f"ğŸ§ª Ğ¢ĞµÑÑ‚ Ğ²Ğ¾ÑĞ¿Ñ€Ğ¾Ğ¸Ğ·Ğ²Ğ¾Ğ´Ğ¸Ğ¼Ğ¾ÑÑ‚Ğ¸: {model_name}")

        results = []

        # ĞĞ±ÑƒÑ‡Ğ°ĞµĞ¼ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ Ğ´Ğ²Ğ°Ğ¶Ğ´Ñ‹ Ñ Ğ¾Ğ´Ğ¸Ğ½Ğ°ĞºĞ¾Ğ²Ñ‹Ğ¼Ğ¸ Ğ¿Ğ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ğ°Ğ¼Ğ¸
        for run_num in [1, 2]:
            logger.info(f"   Ğ—Ğ°Ğ¿ÑƒÑĞº #{run_num}")

            # ĞĞ±ÑƒÑ‡ĞµĞ½Ğ¸Ğµ
            model = create_model(model_name, params)
            X_train, X_test, y_train, y_test = load_and_split_data(data_path)

            set_reproducible_environment(params.get('random_state', 42))
            model.fit(X_train, y_train)
            y_pred = model.predict(X_test)

            metrics = {
                "r2_score": r2_score(y_test, y_pred),
                "rmse": np.sqrt(mean_squared_error(y_test, y_pred)),
                "predictions_hash": hashlib.md5(y_pred.tobytes()).hexdigest()
            }

            results.append(metrics)

        # Ğ¡Ñ€Ğ°Ğ²Ğ½ĞµĞ½Ğ¸Ğµ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ğ¾Ğ²
        r2_diff = abs(results[0]["r2_score"] - results[1]["r2_score"])
        rmse_diff = abs(results[0]["rmse"] - results[1]["rmse"])
        predictions_identical = results[0]["predictions_hash"] == results[1]["predictions_hash"]

        is_reproducible = (
            r2_diff < tolerance and
            rmse_diff < tolerance and
            predictions_identical
        )

        test_result = {
            "model_name": model_name,
            "is_reproducible": is_reproducible,
            "r2_difference": r2_diff,
            "rmse_difference": rmse_diff,
            "predictions_identical": predictions_identical,
            "tolerance": tolerance,
            "run1_results": results[0],
            "run2_results": results[1],
        }

        if is_reproducible:
            logger.success(f"âœ… ĞœĞ¾Ğ´ĞµĞ»ÑŒ {model_name} Ğ²Ğ¾ÑĞ¿Ñ€Ğ¾Ğ¸Ğ·Ğ²Ğ¾Ğ´Ğ¸Ğ¼Ğ°")
        else:
            logger.warning(f"âš ï¸ ĞœĞ¾Ğ´ĞµĞ»ÑŒ {model_name} ĞĞ• Ğ²Ğ¾ÑĞ¿Ñ€Ğ¾Ğ¸Ğ·Ğ²Ğ¾Ğ´Ğ¸Ğ¼Ğ°")
            logger.warning(f"   RÂ² Ñ€Ğ°Ğ·Ğ½Ğ¾ÑÑ‚ÑŒ: {r2_diff}")
            logger.warning(f"   RMSE Ñ€Ğ°Ğ·Ğ½Ğ¾ÑÑ‚ÑŒ: {rmse_diff}")

        return test_result

# Ğ˜Ğ½Ñ‚ĞµĞ³Ñ€Ğ°Ñ†Ğ¸Ñ Ğ² Airflow DAG
@task
def test_reproducibility() -> dict:
    """Task Ğ´Ğ»Ñ Ñ‚ĞµÑÑ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ Ğ²Ğ¾ÑĞ¿Ñ€Ğ¾Ğ¸Ğ·Ğ²Ğ¾Ğ´Ğ¸Ğ¼Ğ¾ÑÑ‚Ğ¸ ĞºĞ»ÑÑ‡ĞµĞ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹."""

    cache = MinIOCache(bucket_name="reproducibility-tests")
    tester = ReproducibilityTester(cache)

    # Ğ¢ĞµÑÑ‚Ğ¸Ñ€ÑƒĞµĞ¼ Ñ‚Ğ¾Ğ¿-3 Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸
    test_models = [
        {"name": "random_forest", "params": {"n_estimators": 100, "random_state": 42}},
        {"name": "gradient_boosting", "params": {"n_estimators": 100, "random_state": 42}},
        {"name": "ridge", "params": {"alpha": 1.0, "random_state": 42}},
    ]

    test_results = []
    for model_config in test_models:
        result = tester.test_model_reproducibility(
            model_config["name"],
            model_config["params"],
            "/opt/airflow/data/raw/housing.csv"
        )
        test_results.append(result)

    # Ğ¡Ğ²Ğ¾Ğ´Ğ½Ğ°Ñ ÑÑ‚Ğ°Ñ‚Ğ¸ÑÑ‚Ğ¸ĞºĞ°
    reproducible_count = sum(1 for r in test_results if r["is_reproducible"])
    total_count = len(test_results)

    summary = {
        "total_tests": total_count,
        "reproducible_count": reproducible_count,
        "reproducibility_rate": reproducible_count / total_count,
        "test_results": test_results,
    }

    logger.info(f"ğŸ§ª Ğ¢ĞµÑÑ‚Ñ‹ Ğ²Ğ¾ÑĞ¿Ñ€Ğ¾Ğ¸Ğ·Ğ²Ğ¾Ğ´Ğ¸Ğ¼Ğ¾ÑÑ‚Ğ¸: {reproducible_count}/{total_count}")

    return summary
```

### **3. Ğ’ĞµÑ€ÑĞ¸Ğ¾Ğ½Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ñ‡ĞµÑ€ĞµĞ· DVC**

```python
@task
def validate_data_version() -> dict:
    """ĞŸÑ€Ğ¾Ğ²ĞµÑ€ĞºĞ° Ğ²ĞµÑ€ÑĞ¸Ğ¸ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ´Ğ»Ñ Ğ¾Ğ±ĞµÑĞ¿ĞµÑ‡ĞµĞ½Ğ¸Ñ Ğ²Ğ¾ÑĞ¿Ñ€Ğ¾Ğ¸Ğ·Ğ²Ğ¾Ğ´Ğ¸Ğ¼Ğ¾ÑÑ‚Ğ¸."""

    import subprocess

    try:
        # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼ ÑÑ‚Ğ°Ñ‚ÑƒÑ DVC
        result = subprocess.run(
            ["dvc", "status"],
            cwd="/opt/airflow",
            capture_output=True,
            text=True,
            timeout=30
        )

        if result.returncode == 0:
            if not result.stdout.strip():
                logger.success("âœ… DVC: Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ Ğ°ĞºÑ‚ÑƒĞ°Ğ»ÑŒĞ½Ñ‹")
                data_status = "up_to_date"
            else:
                logger.warning("âš ï¸ DVC: Ğ¾Ğ±Ğ½Ğ°Ñ€ÑƒĞ¶ĞµĞ½Ñ‹ Ğ¸Ğ·Ğ¼ĞµĞ½ĞµĞ½Ğ¸Ñ Ğ² Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…")
                logger.info(f"DVC ÑÑ‚Ğ°Ñ‚ÑƒÑ:\n{result.stdout}")
                data_status = "modified"
        else:
            logger.error(f"âŒ DVC Ğ¾ÑˆĞ¸Ğ±ĞºĞ°: {result.stderr}")
            data_status = "error"

        # ĞŸĞ¾Ğ»ÑƒÑ‡Ğ°ĞµĞ¼ Ñ…ÑÑˆ Ñ‚ĞµĞºÑƒÑ‰Ğ¸Ñ… Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…
        data_path = "/opt/airflow/data/raw/housing.csv"
        with open(data_path, "rb") as f:
            data_hash = hashlib.md5(f.read()).hexdigest()

        return {
            "data_status": data_status,
            "data_hash": data_hash,
            "dvc_output": result.stdout,
        }

    except subprocess.TimeoutExpired:
        logger.error("âŒ DVC ĞºĞ¾Ğ¼Ğ°Ğ½Ğ´Ğ° Ğ¿Ñ€ĞµĞ²Ñ‹ÑĞ¸Ğ»Ğ° Ñ‚Ğ°Ğ¹Ğ¼Ğ°ÑƒÑ‚")
        return {"data_status": "timeout"}
    except FileNotFoundError:
        logger.warning("âš ï¸ DVC Ğ½Ğµ ÑƒÑÑ‚Ğ°Ğ½Ğ¾Ğ²Ğ»ĞµĞ½")
        return {"data_status": "dvc_not_found"}
```

---

## ğŸ“š Ğ”Ğ¾ĞºÑƒĞ¼ĞµĞ½Ñ‚Ğ°Ñ†Ğ¸Ñ Ğ¿Ñ€Ğ¾ĞµĞºÑ‚Ğ°

ĞŸĞ¾Ğ´Ñ€Ğ¾Ğ±Ğ½Ñ‹Ğµ Ñ€ÑƒĞºĞ¾Ğ²Ğ¾Ğ´ÑÑ‚Ğ²Ğ° Ğ½Ğ°Ñ…Ğ¾Ğ´ÑÑ‚ÑÑ Ğ² Ğ´Ğ¸Ñ€ĞµĞºÑ‚Ğ¾Ñ€Ğ¸Ğ¸ `docs/guides/`:

| Ğ¤Ğ°Ğ¹Ğ» | ĞĞ¿Ğ¸ÑĞ°Ğ½Ğ¸Ğµ |
|------|----------|
| [`MLFLOW+DVC+MINIO.md`](../docs/guides/MLFLOW+DVC+MINIO.md) | ĞŸĞ¾Ğ»Ğ½Ğ¾Ğµ Ñ€ÑƒĞºĞ¾Ğ²Ğ¾Ğ´ÑÑ‚Ğ²Ğ¾ Ğ¿Ğ¾ MLflow + DVC + MinIO |
| [`MINIO+DVC.md`](../docs/guides/MINIO+DVC.md) | ĞĞ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ° MinIO Ğ¸ DVC |
| [`PRE-COMMIT.md`](../docs/guides/PRE-COMMIT.md) | ĞĞ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ° pre-commit Ñ…ÑƒĞºĞ¾Ğ² |

---

## ğŸ“ Ğ—Ğ°ĞºĞ»ÑÑ‡ĞµĞ½Ğ¸Ğµ

Ğ’ Ñ€Ğ°Ğ¼ĞºĞ°Ñ… Ğ»Ğ°Ğ±Ğ¾Ñ€Ğ°Ñ‚Ğ¾Ñ€Ğ½Ğ¾Ğ¹ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ñ‹ Ğ²Ñ‹Ğ¿Ğ¾Ğ»Ğ½ĞµĞ½Ñ‹ Ğ²ÑĞµ Ğ¿Ğ¾ÑÑ‚Ğ°Ğ²Ğ»ĞµĞ½Ğ½Ñ‹Ğµ Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ¸:

### ĞĞ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ° Ğ²Ñ‹Ğ±Ñ€Ğ°Ğ½Ğ½Ğ¾Ğ³Ğ¾ Ğ¸Ğ½ÑÑ‚Ñ€ÑƒĞ¼ĞµĞ½Ñ‚Ğ° Ñ‚Ñ€ĞµĞºĞ¸Ğ½Ğ³Ğ°

1. **Ğ£ÑÑ‚Ğ°Ğ½Ğ¾Ğ²ĞºĞ° Ğ¸ Ğ½Ğ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ° MLflow**: Ğ£ÑÑ‚Ğ°Ğ½Ğ¾Ğ²Ğ»ĞµĞ½ MLflow 2.18.0+, Ñ€Ğ°Ğ·Ğ²Ñ‘Ñ€Ğ½ÑƒÑ‚Ğ¾ Ğ¾Ğ±Ğ»Ğ°Ñ‡Ğ½Ğ¾Ğµ Ñ…Ñ€Ğ°Ğ½Ğ¸Ğ»Ğ¸Ñ‰Ğµ MinIO, ÑĞ¾Ğ·Ğ´Ğ°Ğ½ Ğ¿Ñ€Ğ¾ĞµĞºÑ‚ Ğ¸ ÑĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚Ñ‹, Ğ½Ğ°ÑÑ‚Ñ€Ğ¾ĞµĞ½Ğ° Ğ´Ğ²ÑƒÑ…ÑƒÑ€Ğ¾Ğ²Ğ½ĞµĞ²Ğ°Ñ Ğ°ÑƒÑ‚ĞµĞ½Ñ‚Ğ¸Ñ„Ğ¸ĞºĞ°Ñ†Ğ¸Ñ (Nginx Basic Auth + MLflow Auth + MinIO Access Keys)

2. **ĞŸÑ€Ğ¾Ğ²ĞµĞ´ĞµĞ½Ğ¸Ğµ ÑĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚Ğ¾Ğ²**: ĞŸÑ€Ğ¾Ğ²ĞµĞ´ĞµĞ½Ğ¾ 16 ÑĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚Ğ¾Ğ² Ñ Ñ€Ğ°Ğ·Ğ»Ğ¸Ñ‡Ğ½Ñ‹Ğ¼Ğ¸ Ğ°Ğ»Ğ³Ğ¾Ñ€Ğ¸Ñ‚Ğ¼Ğ°Ğ¼Ğ¸ (Random Forest, Gradient Boosting, Ridge, Lasso, ElasticNet, SVR, KNN, Decision Tree, AdaBoost, Bagging, Extra Trees, Huber Regressor), Ğ½Ğ°ÑÑ‚Ñ€Ğ¾ĞµĞ½Ğ¾ Ğ»Ğ¾Ğ³Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ¼ĞµÑ‚Ñ€Ğ¸Ğº, Ğ¿Ğ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ğ¾Ğ² Ğ¸ Ğ°Ñ€Ñ‚ĞµÑ„Ğ°ĞºÑ‚Ğ¾Ğ², ÑĞ¾Ğ·Ğ´Ğ°Ğ½Ğ° ÑĞ¸ÑÑ‚ĞµĞ¼Ğ° ÑÑ€Ğ°Ğ²Ğ½ĞµĞ½Ğ¸Ñ ÑĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚Ğ¾Ğ², Ğ½Ğ°ÑÑ‚Ñ€Ğ¾ĞµĞ½Ğ° Ñ„Ğ¸Ğ»ÑŒÑ‚Ñ€Ğ°Ñ†Ğ¸Ñ Ğ¸ Ğ¿Ğ¾Ğ¸ÑĞº

3. **Ğ˜Ğ½Ñ‚ĞµĞ³Ñ€Ğ°Ñ†Ğ¸Ñ Ñ ĞºĞ¾Ğ´Ğ¾Ğ¼**: Ğ˜Ğ½Ñ‚ĞµĞ³Ñ€Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½ MLflow Ğ² Python ĞºĞ¾Ğ´, ÑĞ¾Ğ·Ğ´Ğ°Ğ½Ñ‹ Ğ´ĞµĞºĞ¾Ñ€Ğ°Ñ‚Ğ¾Ñ€Ñ‹ Ğ´Ğ»Ñ Ğ°Ğ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¾Ğ³Ğ¾ Ğ»Ğ¾Ğ³Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ (`@mlflow_run`, `@log_params_decorator`, `@log_metrics_decorator`), Ğ½Ğ°ÑÑ‚Ñ€Ğ¾ĞµĞ½Ñ‹ ĞºĞ¾Ğ½Ñ‚ĞµĞºÑÑ‚Ğ½Ñ‹Ğµ Ğ¼ĞµĞ½ĞµĞ´Ğ¶ĞµÑ€Ñ‹ (`MLflowExperimentTracker`), ÑĞ¾Ğ·Ğ´Ğ°Ğ½Ñ‹ ÑƒÑ‚Ğ¸Ğ»Ğ¸Ñ‚Ñ‹ Ğ´Ğ»Ñ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ñ‹ Ñ ÑĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚Ğ°Ğ¼Ğ¸

### ĞĞ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ° Ğ²Ñ‹Ğ±Ñ€Ğ°Ğ½Ğ½Ğ¾Ğ³Ğ¾ Ğ¸Ğ½ÑÑ‚Ñ€ÑƒĞ¼ĞµĞ½Ñ‚Ğ° Ğ¾Ñ€ĞºĞµÑÑ‚Ñ€Ğ°Ñ†Ğ¸Ğ¸

4. **Ğ£ÑÑ‚Ğ°Ğ½Ğ¾Ğ²ĞºĞ° Ğ¸ Ğ½Ğ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ° Apache Airflow**: Ğ Ğ°Ğ·Ğ²ĞµÑ€Ğ½ÑƒÑ‚ Airflow 2.8.0+ Ñ‡ĞµÑ€ĞµĞ· Docker Compose Ñ CeleryExecutor, PostgreSQL, Redis, Ğ¸Ğ½Ñ‚ĞµĞ³Ñ€Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½ Ñ MLflow Ğ¸ MinIO

5. **Ğ¡Ğ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ğµ workflow Ğ´Ğ»Ñ ML Ğ¿Ğ°Ğ¹Ğ¿Ğ»Ğ°Ğ¹Ğ½Ğ°**: Ğ ĞµĞ°Ğ»Ğ¸Ğ·Ğ¾Ğ²Ğ°Ğ½Ğ¾ 3 DAG:
   - `boston_housing_simple`: Ğ¿Ñ€Ğ¾ÑÑ‚Ğ¾Ğ¹ Ğ¿Ğ¾ÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ÑŒĞ½Ñ‹Ğ¹ Ğ¿Ğ°Ğ¹Ğ¿Ğ»Ğ°Ğ¹Ğ½
   - `boston_housing_experiments`: Ğ¿Ğ°Ñ€Ğ°Ğ»Ğ»ĞµĞ»ÑŒĞ½Ğ¾Ğµ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ğµ 19 Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ Ñ Ğ°Ğ³Ñ€ĞµĞ³Ğ°Ñ†Ğ¸ĞµĞ¹
   - `boston_housing_cached`: Ğ¿Ğ°Ğ¹Ğ¿Ğ»Ğ°Ğ¹Ğ½ Ñ Ğ¸Ğ½Ñ‚ĞµĞ»Ğ»ĞµĞºÑ‚ÑƒĞ°Ğ»ÑŒĞ½Ñ‹Ğ¼ ĞºÑÑˆĞ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸ĞµĞ¼ Ğ² MinIO

6. **ĞĞ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ° Ğ·Ğ°Ğ²Ğ¸ÑĞ¸Ğ¼Ğ¾ÑÑ‚ĞµĞ¹ Ğ¼ĞµĞ¶Ğ´Ñƒ ÑÑ‚Ğ°Ğ¿Ğ°Ğ¼Ğ¸**: Ğ ĞµĞ°Ğ»Ğ¸Ğ·Ğ¾Ğ²Ğ°Ğ½Ñ‹ Ğ»Ğ¸Ğ½ĞµĞ¹Ğ½Ñ‹Ğµ, Ğ¿Ğ°Ñ€Ğ°Ğ»Ğ»ĞµĞ»ÑŒĞ½Ñ‹Ğµ Ğ¸ ÑƒÑĞ»Ğ¾Ğ²Ğ½Ñ‹Ğµ Ğ·Ğ°Ğ²Ğ¸ÑĞ¸Ğ¼Ğ¾ÑÑ‚Ğ¸, trigger rules Ğ´Ğ»Ñ Ğ³Ğ¸Ğ±ĞºĞ¾Ğ¹ Ğ»Ğ¾Ğ³Ğ¸ĞºĞ¸ Ğ·Ğ°Ğ¿ÑƒÑĞºĞ°

7. **Ğ ĞµĞ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ ĞºÑÑˆĞ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ Ğ¸ Ğ¿Ğ°Ñ€Ğ°Ğ»Ğ»ĞµĞ»ÑŒĞ½Ğ¾Ğ³Ğ¾ Ğ²Ñ‹Ğ¿Ğ¾Ğ»Ğ½ĞµĞ½Ğ¸Ñ**: Ğ¡Ğ¾Ğ·Ğ´Ğ°Ğ½Ğ° ÑĞ¸ÑÑ‚ĞµĞ¼Ğ° ĞºÑÑˆĞ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ Ğ½Ğ° Ğ±Ğ°Ğ·Ğµ MinIO Ñ Ğ¿Ñ€Ğ¾Ğ²ĞµÑ€ĞºĞ¾Ğ¹ Ñ…ÑÑˆĞµĞ¹ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ¸ Ğ¿Ğ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ğ¾Ğ², Ğ½Ğ°ÑÑ‚Ñ€Ğ¾ĞµĞ½ Ğ¿Ğ°Ñ€Ğ°Ğ»Ğ»ĞµĞ»Ğ¸Ğ·Ğ¼ Ñ‡ĞµÑ€ĞµĞ· expand() operator (Ğ´Ğ¾ 8 Ğ·Ğ°Ğ´Ğ°Ñ‡ Ğ¾Ğ´Ğ½Ğ¾Ğ²Ñ€ĞµĞ¼ĞµĞ½Ğ½Ğ¾)

### ĞĞ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ° Ğ²Ñ‹Ğ±Ñ€Ğ°Ğ½Ğ½Ğ¾Ğ³Ğ¾ Ğ¸Ğ½ÑÑ‚Ñ€ÑƒĞ¼ĞµĞ½Ñ‚Ğ° ĞºĞ¾Ğ½Ñ„Ğ¸Ğ³ÑƒÑ€Ğ°Ñ†Ğ¸Ğ¹

8. **ĞĞ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ° Ğ¸Ğ½ÑÑ‚Ñ€ÑƒĞ¼ĞµĞ½Ñ‚Ğ° ÑƒĞ¿Ñ€Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ñ ĞºĞ¾Ğ½Ñ„Ğ¸Ğ³ÑƒÑ€Ğ°Ñ†Ğ¸ÑĞ¼Ğ¸**: Ğ ĞµĞ°Ğ»Ğ¸Ğ·Ğ¾Ğ²Ğ°Ğ½Ğ° Ğ¼Ğ¾Ğ´ÑƒĞ»ÑŒĞ½Ğ°Ñ ÑĞ¸ÑÑ‚ĞµĞ¼Ğ° ĞºĞ¾Ğ½Ñ„Ğ¸Ğ³ÑƒÑ€Ğ°Ñ†Ğ¸Ğ¹ Ğ½Ğ° Ğ¾ÑĞ½Ğ¾Ğ²Ğµ Ğ¿ĞµÑ€ĞµĞ¼ĞµĞ½Ğ½Ñ‹Ñ… Ğ¾ĞºÑ€ÑƒĞ¶ĞµĞ½Ğ¸Ñ (.env), Python Ğ¼Ğ¾Ğ´ÑƒĞ»ĞµĞ¹ (config.py, mlflow_config.py) Ğ¸ Docker Compose

9. **Ğ¡Ğ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ğµ ĞºĞ¾Ğ½Ñ„Ğ¸Ğ³ÑƒÑ€Ğ°Ñ†Ğ¸Ğ¹ Ğ´Ğ»Ñ Ñ€Ğ°Ğ·Ğ½Ñ‹Ñ… Ğ°Ğ»Ğ³Ğ¾Ñ€Ğ¸Ñ‚Ğ¼Ğ¾Ğ²**: Ğ¡Ğ¾Ğ·Ğ´Ğ°Ğ½Ñ‹ Ñ†ĞµĞ½Ñ‚Ñ€Ğ°Ğ»Ğ¸Ğ·Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ğµ ĞºĞ¾Ğ½Ñ„Ğ¸Ğ³ÑƒÑ€Ğ°Ñ†Ğ¸Ğ¸ Ğ´Ğ»Ñ 19 Ğ°Ğ»Ğ³Ğ¾Ñ€Ğ¸Ñ‚Ğ¼Ğ¾Ğ² (7 Ğ»Ğ¸Ğ½ĞµĞ¹Ğ½Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹, 9 Ğ´Ñ€ĞµĞ²Ğ¾Ğ²Ğ¸Ğ´Ğ½Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹, 3 Ğ´Ñ€ÑƒĞ³Ğ¸Ñ… Ğ°Ğ»Ğ³Ğ¾Ñ€Ğ¸Ñ‚Ğ¼Ğ°) Ñ Ñ„Ğ°Ğ±Ñ€Ğ¸ĞºĞ¾Ğ¹ Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹

10. **ĞĞ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ° Ğ²Ğ°Ğ»Ğ¸Ğ´Ğ°Ñ†Ğ¸Ğ¸ ĞºĞ¾Ğ½Ñ„Ğ¸Ğ³ÑƒÑ€Ğ°Ñ†Ğ¸Ğ¹**: Ğ ĞµĞ°Ğ»Ğ¸Ğ·Ğ¾Ğ²Ğ°Ğ½Ğ° Ğ²Ğ°Ğ»Ğ¸Ğ´Ğ°Ñ†Ğ¸Ñ Ğ½Ğ° ÑƒÑ€Ğ¾Ğ²Ğ½Ğµ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…, Ğ¿Ğ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ğ¾Ğ² Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹, Ğ¿ĞµÑ€ĞµĞ¼ĞµĞ½Ğ½Ñ‹Ñ… Ğ¾ĞºÑ€ÑƒĞ¶ĞµĞ½Ğ¸Ñ Ñ Ğ¿Ğ¾Ğ´Ñ€Ğ¾Ğ±Ğ½Ñ‹Ğ¼ Ğ»Ğ¾Ğ³Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸ĞµĞ¼ Ğ¾ÑˆĞ¸Ğ±Ğ¾Ğº

11. **Ğ¡Ğ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ğµ ÑĞ¸ÑÑ‚ĞµĞ¼Ñ‹ ĞºĞ¾Ğ¼Ğ¿Ğ¾Ğ·Ğ¸Ñ†Ğ¸Ğ¸ ĞºĞ¾Ğ½Ñ„Ğ¸Ğ³ÑƒÑ€Ğ°Ñ†Ğ¸Ğ¹**: ĞĞ°ÑÑ‚Ñ€Ğ¾ĞµĞ½Ğ¾ Ğ½Ğ°ÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ¸ Ğ¿ĞµÑ€ĞµĞ¾Ğ¿Ñ€ĞµĞ´ĞµĞ»ĞµĞ½Ğ¸Ğµ ĞºĞ¾Ğ½Ñ„Ğ¸Ğ³ÑƒÑ€Ğ°Ñ†Ğ¸Ğ¹, Ğ¸ĞµÑ€Ğ°Ñ€Ñ…Ğ¸Ñ Ğ¿ĞµÑ€ĞµĞ¼ĞµĞ½Ğ½Ñ‹Ñ… Ğ¾ĞºÑ€ÑƒĞ¶ĞµĞ½Ğ¸Ñ, ĞºĞ¾Ğ½Ñ„Ğ¸Ğ³ÑƒÑ€Ğ°Ñ†Ğ¸Ğ¾Ğ½Ğ½Ñ‹Ğµ ĞºĞ»Ğ°ÑÑÑ‹ Ñ Ğ²Ğ°Ğ»Ğ¸Ğ´Ğ°Ñ†Ğ¸ĞµĞ¹

### Ğ˜Ğ½Ñ‚ĞµĞ³Ñ€Ğ°Ñ†Ğ¸Ñ Ğ¸ Ñ‚ĞµÑÑ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ

12. **Ğ˜Ğ½Ñ‚ĞµĞ³Ñ€Ğ°Ñ†Ğ¸Ñ Ğ²Ñ‹Ğ±Ñ€Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ¸Ğ½ÑÑ‚Ñ€ÑƒĞ¼ĞµĞ½Ñ‚Ğ¾Ğ²**: ĞŸĞ¾Ğ»Ğ½Ğ°Ñ Ğ¸Ğ½Ñ‚ĞµĞ³Ñ€Ğ°Ñ†Ğ¸Ñ Airflow + MLflow + MinIO Ñ‡ĞµÑ€ĞµĞ· ĞµĞ´Ğ¸Ğ½Ñ‹Ğµ Ğ¿ĞµÑ€ĞµĞ¼ĞµĞ½Ğ½Ñ‹Ğµ Ğ¾ĞºÑ€ÑƒĞ¶ĞµĞ½Ğ¸Ñ, Docker Compose Ğ¾Ñ€ĞºĞµÑÑ‚Ñ€Ğ°Ñ†Ğ¸Ñ, Ğ¾Ğ±Ñ‰ÑƒÑ Ğ°ÑƒÑ‚ĞµĞ½Ñ‚Ğ¸Ñ„Ğ¸ĞºĞ°Ñ†Ğ¸Ñ

13. **Ğ¡Ğ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ğµ ÑĞ¸ÑÑ‚ĞµĞ¼Ñ‹ Ğ¼Ğ¾Ğ½Ğ¸Ñ‚Ğ¾Ñ€Ğ¸Ğ½Ğ³Ğ° Ğ²Ñ‹Ğ¿Ğ¾Ğ»Ğ½ĞµĞ½Ğ¸Ñ**: Ğ ĞµĞ°Ğ»Ğ¸Ğ·Ğ¾Ğ²Ğ°Ğ½ Ğ¼Ğ½Ğ¾Ğ³Ğ¾ÑƒÑ€Ğ¾Ğ²Ğ½ĞµĞ²Ñ‹Ğ¹ Ğ¼Ğ¾Ğ½Ğ¸Ñ‚Ğ¾Ñ€Ğ¸Ğ½Ğ³: ÑÑ‚Ñ€ÑƒĞºÑ‚ÑƒÑ€Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ğµ Ğ»Ğ¾Ğ³Ğ¸ (loguru), Ğ¼Ğ¾Ğ½Ğ¸Ñ‚Ğ¾Ñ€Ğ¸Ğ½Ğ³ Airflow Ñ callbacks, Ğ¼Ğ¾Ğ½Ğ¸Ñ‚Ğ¾Ñ€Ğ¸Ğ½Ğ³ Ğ¿Ñ€Ğ¾Ğ¸Ğ·Ğ²Ğ¾Ğ´Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ÑÑ‚Ğ¸ Ğ² MLflow

14. **ĞĞ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ° ÑƒĞ²ĞµĞ´Ğ¾Ğ¼Ğ»ĞµĞ½Ğ¸Ğ¹ Ğ¾ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ğ°Ñ…**: Ğ¡Ğ¸ÑÑ‚ĞµĞ¼Ğ° ÑƒĞ²ĞµĞ´Ğ¾Ğ¼Ğ»ĞµĞ½Ğ¸Ğ¹ Ñ‡ĞµÑ€ĞµĞ· Airflow UI, MLflow UI Ñ Ğ°Ğ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ğ¼ ÑĞ¾Ğ·Ğ´Ğ°Ğ½Ğ¸ĞµĞ¼ ÑĞ²Ğ¾Ğ´Ğ½Ñ‹Ñ… Ğ¾Ñ‚Ñ‡Ñ‘Ñ‚Ğ¾Ğ², Ğ¸Ğ½Ñ‚ĞµĞ³Ñ€Ğ°Ñ†Ğ¸Ñ Ñ Ğ²Ğ½ĞµÑˆĞ½Ğ¸Ğ¼Ğ¸ ÑĞ¸ÑÑ‚ĞµĞ¼Ğ°Ğ¼Ğ¸ Ñ‡ĞµÑ€ĞµĞ· webhook'Ğ¸

15. **Ğ¢ĞµÑÑ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ²Ğ¾ÑĞ¿Ñ€Ğ¾Ğ¸Ğ·Ğ²Ğ¾Ğ´Ğ¸Ğ¼Ğ¾ÑÑ‚Ğ¸**: Ğ¡Ğ¸ÑÑ‚ĞµĞ¼Ğ° Ğ¾Ğ±ĞµÑĞ¿ĞµÑ‡ĞµĞ½Ğ¸Ñ Ğ´ĞµÑ‚ĞµÑ€Ğ¼Ğ¸Ğ½Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ğ¾ÑÑ‚Ğ¸ Ñ‡ĞµÑ€ĞµĞ· Ñ„Ğ¸ĞºÑĞ°Ñ†Ğ¸Ñ random seeds, ĞºÑÑˆĞ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ´Ğ»Ñ Ğ¿Ñ€Ğ¾Ğ²ĞµÑ€ĞºĞ¸ Ğ¸Ğ´ĞµĞ½Ñ‚Ğ¸Ñ‡Ğ½Ğ¾ÑÑ‚Ğ¸ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ğ¾Ğ², Ğ²ĞµÑ€ÑĞ¸Ğ¾Ğ½Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ñ‡ĞµÑ€ĞµĞ· DVC

### ĞÑ‚Ñ‡Ñ‘Ñ‚ Ğ¾ Ğ¿Ñ€Ğ¾Ğ´ĞµĞ»Ğ°Ğ½Ğ½Ğ¾Ğ¹ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğµ

16. **Ğ¡Ğ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ğµ Ğ¾Ñ‚Ñ‡Ñ‘Ñ‚Ğ°**: Ğ¡Ğ¾Ğ·Ğ´Ğ°Ğ½ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğ¹ Ğ¿Ğ¾Ğ´Ñ€Ğ¾Ğ±Ğ½Ñ‹Ğ¹ Ğ¾Ñ‚Ñ‡Ñ‘Ñ‚ Ğ² Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ‚Ğµ Markdown Ñ Ğ¾Ğ¿Ğ¸ÑĞ°Ğ½Ğ¸ĞµĞ¼ Ğ²ÑĞµÑ… ĞºĞ¾Ğ¼Ğ¿Ğ¾Ğ½ĞµĞ½Ñ‚Ğ¾Ğ² ÑĞ¸ÑÑ‚ĞµĞ¼Ñ‹, Ğ´Ğ¾Ğ±Ğ°Ğ²Ğ»ĞµĞ½Ñ‹ ÑÑ…ĞµĞ¼Ñ‹ Ğ°Ñ€Ñ…Ğ¸Ñ‚ĞµĞºÑ‚ÑƒÑ€Ñ‹ Ğ¸ Ğ¿Ñ€Ğ¸Ğ¼ĞµÑ€Ñ‹ ĞºĞ¾Ğ´Ğ°, Ğ¾Ñ‚Ñ‡Ñ‘Ñ‚ ÑĞ¾Ñ…Ñ€Ğ°Ğ½Ñ‘Ğ½ Ğ² Git Ñ€ĞµĞ¿Ğ¾Ğ·Ğ¸Ñ‚Ğ¾Ñ€Ğ¸Ğ¸

**Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµĞ¼Ñ‹Ğ¹ ÑÑ‚ĞµĞº Ñ‚ĞµÑ…Ğ½Ğ¾Ğ»Ğ¾Ğ³Ğ¸Ğ¹:**

|| ĞšĞ°Ñ‚ĞµĞ³Ğ¾Ñ€Ğ¸Ñ | Ğ¢ĞµÑ…Ğ½Ğ¾Ğ»Ğ¾Ğ³Ğ¸Ñ | Ğ’ĞµÑ€ÑĞ¸Ñ | ĞĞ°Ğ·Ğ½Ğ°Ñ‡ĞµĞ½Ğ¸Ğµ |
||-----------|------------|--------|------------|
|| **Ğ¯Ğ·Ñ‹Ğº Ğ¸ Ğ¿Ğ°ĞºĞµÑ‚Ñ‹** | Python + uv | 3.13 | ĞÑĞ½Ğ¾Ğ²Ğ½Ğ¾Ğ¹ ÑĞ·Ñ‹Ğº Ñ€Ğ°Ğ·Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ¸, Ğ¿Ğ°ĞºĞµÑ‚Ğ½Ñ‹Ğ¹ Ğ¼ĞµĞ½ĞµĞ´Ğ¶ĞµÑ€ |
|| **ĞÑ€ĞºĞµÑÑ‚Ñ€Ğ°Ñ†Ğ¸Ñ** | Apache Airflow | 2.8.0+ | ĞÑ€ĞºĞµÑÑ‚Ñ€Ğ°Ñ†Ğ¸Ñ ML Ğ¿Ğ°Ğ¹Ğ¿Ğ»Ğ°Ğ¹Ğ½Ğ¾Ğ², Ğ¿Ğ»Ğ°Ğ½Ğ¸Ñ€Ğ¾Ğ²Ñ‰Ğ¸Ğº Ğ·Ğ°Ğ´Ğ°Ñ‡ |
|| **Ğ¢Ñ€ĞµĞºĞ¸Ğ½Ğ³** | MLflow | 2.18.0+ | Ğ¢Ñ€ĞµĞºĞ¸Ğ½Ğ³ ÑĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚Ğ¾Ğ², Model Registry |
|| **Ğ¥Ñ€Ğ°Ğ½Ğ¸Ğ»Ğ¸Ñ‰Ğµ** | MinIO | latest | S3-ÑĞ¾Ğ²Ğ¼ĞµÑÑ‚Ğ¸Ğ¼Ğ¾Ğµ Ñ…Ñ€Ğ°Ğ½Ğ¸Ğ»Ğ¸Ñ‰Ğµ Ğ°Ñ€Ñ‚ĞµÑ„Ğ°ĞºÑ‚Ğ¾Ğ² Ğ¸ ĞºÑÑˆĞ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ |
|| **ĞšĞ¾Ğ½Ñ„Ğ¸Ğ³ÑƒÑ€Ğ°Ñ†Ğ¸Ğ¸** | python-dotenv + Ğ¼Ğ¾Ğ´ÑƒĞ»Ğ¸ | â€” | Ğ£Ğ¿Ñ€Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ğµ ĞºĞ¾Ğ½Ñ„Ğ¸Ğ³ÑƒÑ€Ğ°Ñ†Ğ¸ÑĞ¼Ğ¸ Ñ‡ĞµÑ€ĞµĞ· .env Ğ¸ Python |
|| **Ğ’ĞµÑ€ÑĞ¸Ğ¾Ğ½Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…** | DVC | 3.64.2+ | Ğ’ĞµÑ€ÑĞ¸Ğ¾Ğ½Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ¸ Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ |
|| **Ğ‘Ğ°Ğ·Ğ° Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…** | PostgreSQL | 13 | ĞœĞµÑ‚Ğ°Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ Airflow |
|| **Ğ‘Ñ€Ğ¾ĞºĞµÑ€ ÑĞ¾Ğ¾Ğ±Ñ‰ĞµĞ½Ğ¸Ğ¹** | Redis | 7 | Celery broker Ğ´Ğ»Ñ Airflow |
|| **ĞšĞ¾Ğ½Ñ‚ĞµĞ¹Ğ½ĞµÑ€Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ** | Docker + Docker Compose | â€” | Ğ Ğ°Ğ·Ğ²ĞµÑ€Ñ‚Ñ‹Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ¸Ğ½Ñ„Ñ€Ğ°ÑÑ‚Ñ€ÑƒĞºÑ‚ÑƒÑ€Ñ‹ |
|| **ĞĞ±Ñ€Ğ°Ñ‚Ğ½Ñ‹Ğ¹ Ğ¿Ñ€Ğ¾ĞºÑĞ¸** | Nginx | alpine | ĞÑƒÑ‚ĞµĞ½Ñ‚Ğ¸Ñ„Ğ¸ĞºĞ°Ñ†Ğ¸Ñ Ğ¸ Ğ¼Ğ°Ñ€ÑˆÑ€ÑƒÑ‚Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ |
|| **ML Ğ±Ğ¸Ğ±Ğ»Ğ¸Ğ¾Ñ‚ĞµĞºĞ°** | scikit-learn | 1.3+ | ĞĞ»Ğ³Ğ¾Ñ€Ğ¸Ñ‚Ğ¼Ñ‹ Ğ¼Ğ°ÑˆĞ¸Ğ½Ğ½Ğ¾Ğ³Ğ¾ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ |
|| **Ğ›Ğ¾Ğ³Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ** | loguru | â€” | Ğ¡Ñ‚Ñ€ÑƒĞºÑ‚ÑƒÑ€Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ğ¾Ğµ Ğ»Ğ¾Ğ³Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ |
|| **ĞšĞ°Ñ‡ĞµÑÑ‚Ğ²Ğ¾ ĞºĞ¾Ğ´Ğ°** | Ruff + pre-commit | â€” | Ğ›Ğ¸Ğ½Ñ‚Ğ¸Ğ½Ğ³ Ğ¸ Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ ĞºĞ¾Ğ´Ğ° |

---
