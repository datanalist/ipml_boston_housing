# ğŸ“Š ĞÑ‚Ñ‡Ñ‘Ñ‚: Ğ¢Ñ€ĞµĞºĞ¸Ğ½Ğ³ ML-ÑĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚Ğ¾Ğ²

**ĞŸÑ€Ğ¾ĞµĞºÑ‚:** Boston Housing Price Prediction  
**Ğ”Ğ°Ñ‚Ğ°:** 23 Ğ´ĞµĞºĞ°Ğ±Ñ€Ñ 2025 (Ğ¾Ğ±Ğ½Ğ¾Ğ²Ğ»ĞµĞ½Ğ¾)  
**ĞĞ²Ñ‚Ğ¾Ñ€:** ĞœĞ°ĞºĞ°Ñ€Ğ¾Ğ² ĞœĞ¸Ñ…Ğ°Ğ¸Ğ» Ğ’Ğ»Ğ°Ğ´Ğ¸Ğ¼Ğ¸Ñ€Ğ¾Ğ²Ğ¸Ñ‡ (ÑÑ‚ÑƒĞ´ĞµĞ½Ñ‡ĞµÑĞºĞ¸Ğ¹ Ğ¿Ñ€Ğ¾ĞµĞºÑ‚ Ğ¿Ğ¾ IPML)  

---

## ğŸ“‹ Ğ¡Ğ¾Ğ´ĞµÑ€Ğ¶Ğ°Ğ½Ğ¸Ğµ

1. [ĞĞ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ° Ğ²Ñ‹Ğ±Ñ€Ğ°Ğ½Ğ½Ğ¾Ğ³Ğ¾ Ğ¸Ğ½ÑÑ‚Ñ€ÑƒĞ¼ĞµĞ½Ñ‚Ğ° Ñ‚Ñ€ĞµĞºĞ¸Ğ½Ğ³Ğ°](#1-Ğ½Ğ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ°-Ğ²Ñ‹Ğ±Ñ€Ğ°Ğ½Ğ½Ğ¾Ğ³Ğ¾-Ğ¸Ğ½ÑÑ‚Ñ€ÑƒĞ¼ĞµĞ½Ñ‚Ğ°)
2. [ĞŸÑ€Ğ¾Ğ²ĞµĞ´ĞµĞ½Ğ¸Ğµ ÑĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚Ğ¾Ğ²](#2-Ğ¿Ñ€Ğ¾Ğ²ĞµĞ´ĞµĞ½Ğ¸Ğµ-ÑĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚Ğ¾Ğ²)
3. [Ğ˜Ğ½Ñ‚ĞµĞ³Ñ€Ğ°Ñ†Ğ¸Ñ Ñ ĞºĞ¾Ğ´Ğ¾Ğ¼](#3-Ğ¸Ğ½Ñ‚ĞµĞ³Ñ€Ğ°Ñ†Ğ¸Ñ-Ñ-ĞºĞ¾Ğ´Ğ¾Ğ¼)
4. [Ğ˜Ğ½ÑÑ‚Ñ€ÑƒĞºÑ†Ğ¸Ğ¸ Ğ¿Ğ¾ Ğ·Ğ°Ğ¿ÑƒÑĞºÑƒ](#4-Ğ¸Ğ½ÑÑ‚Ñ€ÑƒĞºÑ†Ğ¸Ğ¸-Ğ¿Ğ¾-Ğ·Ğ°Ğ¿ÑƒÑĞºÑƒ)
5. [ĞĞ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ° Ğ¸Ğ½ÑÑ‚Ñ€ÑƒĞ¼ĞµĞ½Ñ‚Ğ° Ğ¾Ñ€ĞºĞµÑÑ‚Ñ€Ğ°Ñ†Ğ¸Ğ¸](#5-Ğ½Ğ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ°-Ğ¸Ğ½ÑÑ‚Ñ€ÑƒĞ¼ĞµĞ½Ñ‚Ğ°-Ğ¾Ñ€ĞºĞµÑÑ‚Ñ€Ğ°Ñ†Ğ¸Ğ¸)
6. [ĞĞ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ° Ğ¸Ğ½ÑÑ‚Ñ€ÑƒĞ¼ĞµĞ½Ñ‚Ğ° ĞºĞ¾Ğ½Ñ„Ğ¸Ğ³ÑƒÑ€Ğ°Ñ†Ğ¸Ğ¹](#6-Ğ½Ğ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ°-Ğ¸Ğ½ÑÑ‚Ñ€ÑƒĞ¼ĞµĞ½Ñ‚Ğ°-ĞºĞ¾Ğ½Ñ„Ğ¸Ğ³ÑƒÑ€Ğ°Ñ†Ğ¸Ğ¹)
7. [Ğ˜Ğ½Ñ‚ĞµĞ³Ñ€Ğ°Ñ†Ğ¸Ñ Ğ¸ Ñ‚ĞµÑÑ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ ÑĞ¸ÑÑ‚ĞµĞ¼](#7-Ğ¸Ğ½Ñ‚ĞµĞ³Ñ€Ğ°Ñ†Ğ¸Ñ-Ğ¸-Ñ‚ĞµÑÑ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ-ÑĞ¸ÑÑ‚ĞµĞ¼)

---

## 1. ĞĞ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ° Ğ²Ñ‹Ğ±Ñ€Ğ°Ğ½Ğ½Ğ¾Ğ³Ğ¾ Ğ¸Ğ½ÑÑ‚Ñ€ÑƒĞ¼ĞµĞ½Ñ‚Ğ° Ñ‚Ñ€ĞµĞºĞ¸Ğ½Ğ³Ğ°

### 1.1 Ğ£ÑÑ‚Ğ°Ğ½Ğ¾Ğ²ĞºĞ° Ğ¸ Ğ½Ğ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ° Ğ²Ñ‹Ğ±Ñ€Ğ°Ğ½Ğ½Ğ¾Ğ³Ğ¾ Ğ¸Ğ½ÑÑ‚Ñ€ÑƒĞ¼ĞµĞ½Ñ‚Ğ° (MLflow)

**Ğ’Ñ‹Ğ±Ñ€Ğ°Ğ½Ğ½Ñ‹Ğ¹ ÑÑ‚ĞµĞº Ñ‚ĞµÑ…Ğ½Ğ¾Ğ»Ğ¾Ğ³Ğ¸Ğ¹:**

| Ğ˜Ğ½ÑÑ‚Ñ€ÑƒĞ¼ĞµĞ½Ñ‚ | Ğ’ĞµÑ€ÑĞ¸Ñ | ĞĞ°Ğ·Ğ½Ğ°Ñ‡ĞµĞ½Ğ¸Ğµ |
|------------|--------|------------|
| **MLflow** | 3.7.0+ | Ğ¢Ñ€ĞµĞºĞ¸Ğ½Ğ³ ÑĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚Ğ¾Ğ², Model Registry |
| **MinIO** | latest | S3-ÑĞ¾Ğ²Ğ¼ĞµÑÑ‚Ğ¸Ğ¼Ğ¾Ğµ Ñ…Ñ€Ğ°Ğ½Ğ¸Ğ»Ğ¸Ñ‰Ğµ Ğ°Ñ€Ñ‚ĞµÑ„Ğ°ĞºÑ‚Ğ¾Ğ² |
| **DVC** | 3.64.2+ | Ğ’ĞµÑ€ÑĞ¸Ğ¾Ğ½Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… |
| **Apache Airflow** | 2.8.1 | ĞÑ€ĞºĞµÑÑ‚Ñ€Ğ°Ñ†Ğ¸Ñ ML Ğ¿Ğ°Ğ¹Ğ¿Ğ»Ğ°Ğ¹Ğ½Ğ¾Ğ² |
| **PostgreSQL** | 15 | Ğ‘Ğ°Ğ·Ğ° Ğ¼ĞµÑ‚Ğ°Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Airflow |
| **Redis** | 7-alpine | Ğ‘Ñ€Ğ¾ĞºĞµÑ€ ÑĞ¾Ğ¾Ğ±Ñ‰ĞµĞ½Ğ¸Ğ¹ Celery |
| **Nginx** | alpine | Reverse proxy Ñ Basic Auth |
| **Docker** | â€” | ĞšĞ¾Ğ½Ñ‚ĞµĞ¹Ğ½ĞµÑ€Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ Ğ¸Ğ½Ñ„Ñ€Ğ°ÑÑ‚Ñ€ÑƒĞºÑ‚ÑƒÑ€Ñ‹ |

**Ğ£ÑÑ‚Ğ°Ğ½Ğ¾Ğ²ĞºĞ° Ğ·Ğ°Ğ²Ğ¸ÑĞ¸Ğ¼Ğ¾ÑÑ‚ĞµĞ¹:**

```bash
# Ğ§ĞµÑ€ĞµĞ· uv (Ğ¿Ğ°ĞºĞµÑ‚Ğ½Ñ‹Ğ¹ Ğ¼ĞµĞ½ĞµĞ´Ğ¶ĞµÑ€)
uv add "mlflow[auth]>=3.7.0" "boto3>=1.41.5" "dvc[s3]>=3.64.2"

# ĞĞ±Ğ½Ğ¾Ğ²Ğ»ĞµĞ½Ğ¸Ğµ pyproject.toml
```

**Ğ¤Ğ°Ğ¹Ğ» `pyproject.toml`:**

```toml
[project]
name = "ipml-boston-housing"
version = "0.1.0"
description = "Add your description here"
readme = "README.md"
requires-python = ">=3.13"
dependencies = [
    "cookiecutter-data-science>=2.3.0",
    "dvc[s3]>=3.64.2",
    "dvc-gdrive>=3.0.1",
    "pre-commit>=4.5.0",
    "ruff>=0.14.6",
    "numpy>=2.3.5",
    "pandas>=2.3.3",
    "dvclive>=3.49.0",
    "loguru>=0.7.3",
    "scikit-learn>=1.7.2",
    "click>=8.3.1",
    "dvc-s3>=3.2.2",
    "mlflow[auth]>=3.7.0",
    "boto3>=1.41.5",
]

[dependency-groups]
dev = [
    "detect-secrets>=1.5.0",
]
```

### 1.2 ĞĞ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ° Ğ±Ğ°Ğ·Ñ‹ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…/Ğ¾Ğ±Ğ»Ğ°Ñ‡Ğ½Ğ¾Ğ³Ğ¾ Ñ…Ñ€Ğ°Ğ½Ğ¸Ğ»Ğ¸Ñ‰Ğ° (MinIO)

**ĞÑ€Ñ…Ğ¸Ñ‚ĞµĞºÑ‚ÑƒÑ€Ğ° Ñ€ĞµÑˆĞµĞ½Ğ¸Ñ:**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        ML Experiment Lifecycle                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  ĞšĞ¾Ğ´/Ğ¡ĞºÑ€Ğ¸Ğ¿Ñ‚Ñ‹ â”‚â”€â”€â”€â–¶â”‚   MLflow     â”‚â”€â”€â”€â–¶â”‚      MinIO           â”‚   â”‚
â”‚  â”‚  Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ    â”‚    â”‚   Tracking   â”‚    â”‚  (Artifact Store)    â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚   Server     â”‚    â”‚                      â”‚   â”‚
â”‚                      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚   â”‚
â”‚                             â”‚            â”‚  â”‚ mlflow-artifactsâ”‚  â”‚   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚            â”‚  â”‚  â””â”€ models/     â”‚  â”‚   â”‚
â”‚  â”‚     DVC      â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚  â”‚  â””â”€ metrics/    â”‚  â”‚   â”‚
â”‚  â”‚  (Ğ’ĞµÑ€ÑĞ¸Ğ¸     â”‚           â”‚            â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚   â”‚
â”‚  â”‚   Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…)    â”‚           â”‚            â”‚                      â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚            â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚   â”‚
â”‚        â”‚                    â”‚            â”‚  â”‚boston-housing- â”‚  â”‚   â”‚
â”‚        â–¼                    â”‚            â”‚  â”‚     data       â”‚  â”‚   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚            â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚   â”‚
â”‚  â”‚     Git      â”‚â—€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚  â”‚  (.dvc Ñ„Ğ°Ğ¹Ğ»Ñ‹)â”‚                                                   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                                   â”‚
â”‚                                                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Docker-ĞºĞ¾Ğ½Ñ„Ğ¸Ğ³ÑƒÑ€Ğ°Ñ†Ğ¸Ñ MinIO (`docker/Dockerfile.minio`):**

```dockerfile
FROM minio/minio:latest

LABEL maintainer="Boston Housing ML Project"
LABEL description="MinIO storage Ğ´Ğ»Ñ Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ğ¸Ñ ML Ğ°Ñ€Ñ‚ĞµÑ„Ğ°ĞºÑ‚Ğ¾Ğ²"

ENV MINIO_ROOT_USER=minioadmin0
ENV MINIO_ROOT_PASSWORD=minioadmin1230
ENV MINIO_CONSOLE_ADDRESS=":9001"

EXPOSE 9000 9001
VOLUME ["/data"]

HEALTHCHECK --interval=30s --timeout=20s --start-period=10s --retries=3 \
    CMD curl -f http://localhost:9000/minio/health/live || exit 1

CMD ["server", "/data", "--console-address", ":9001"]
```

**Ğ‘Ğ°ĞºĞµÑ‚Ñ‹ Ğ² MinIO:**

| Ğ‘Ğ°ĞºĞµÑ‚ | ĞĞ°Ğ·Ğ½Ğ°Ñ‡ĞµĞ½Ğ¸Ğµ |
|-------|------------|
| `boston-housing-data` | Ğ”Ğ°Ğ½Ğ½Ñ‹Ğµ Ğ¸ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ (DVC) |
| `mlflow-artifacts` | ĞÑ€Ñ‚ĞµÑ„Ğ°ĞºÑ‚Ñ‹ MLflow (Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸, Ğ¼ĞµÑ‚Ñ€Ğ¸ĞºĞ¸, Ğ³Ñ€Ğ°Ñ„Ğ¸ĞºĞ¸) |

**Ğ¡ĞºÑ€Ğ¸Ğ½ÑˆĞ¾Ñ‚ MinIO Object Browser:**

![UI MinIO](figures/6.png)

*Ğ Ğ¸Ñ. 1: Ğ’ĞµĞ±-ĞºĞ¾Ğ½ÑĞ¾Ğ»ÑŒ MinIO Ñ Ğ±Ğ°ĞºĞµÑ‚Ğ°Ğ¼Ğ¸ Ğ´Ğ»Ñ Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ğ¸Ñ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… DVC Ğ¸ Ğ°Ñ€Ñ‚ĞµÑ„Ğ°ĞºÑ‚Ğ¾Ğ² MLflow*

### 1.3 Ğ¡Ğ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ğµ Ğ¿Ñ€Ğ¾ĞµĞºÑ‚Ğ° Ğ¸ ÑĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚Ğ¾Ğ²

**Ğ—Ğ°Ğ¿ÑƒÑĞº Ğ¸Ğ½Ñ„Ñ€Ğ°ÑÑ‚Ñ€ÑƒĞºÑ‚ÑƒÑ€Ñ‹:**

```bash
# Ğ—Ğ°Ğ¿ÑƒÑĞº MinIO Ğ¸ MLflow
docker-compose up -d minio mlflow nginx

# Ğ¡Ğ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ğµ Ğ±Ğ°ĞºĞµÑ‚Ğ¾Ğ²
mc alias set local http://localhost:9000 minioadmin0 minioadmin1230
mc mb local/boston-housing-data
mc mb local/mlflow-artifacts
```

**Ğ¡Ğ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ğµ ÑĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚Ğ° Ğ² MLflow:**

```python
import mlflow

mlflow.set_tracking_uri("http://localhost:5000")
mlflow.set_experiment("boston-housing")
```

### 1.4 ĞĞ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ° Ğ°ÑƒÑ‚ĞµĞ½Ñ‚Ğ¸Ñ„Ğ¸ĞºĞ°Ñ†Ğ¸Ğ¸ Ğ¸ Ğ´Ğ¾ÑÑ‚ÑƒĞ¿Ğ°

Ğ ĞµĞ°Ğ»Ğ¸Ğ·Ğ¾Ğ²Ğ°Ğ½Ğ° **Ğ´Ğ²ÑƒÑ…ÑƒÑ€Ğ¾Ğ²Ğ½ĞµĞ²Ğ°Ñ Ğ°ÑƒÑ‚ĞµĞ½Ñ‚Ğ¸Ñ„Ğ¸ĞºĞ°Ñ†Ğ¸Ñ**:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    ĞÑ€Ñ…Ğ¸Ñ‚ĞµĞºÑ‚ÑƒÑ€Ğ° Ğ°ÑƒÑ‚ĞµĞ½Ñ‚Ğ¸Ñ„Ğ¸ĞºĞ°Ñ†Ğ¸Ğ¸                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                                    â”‚
â”‚  â”‚   Ğ‘Ñ€Ğ°ÑƒĞ·ĞµÑ€    â”‚â”€â”€â”€â”€â”€â”                                              â”‚
â”‚  â”‚   (UI)       â”‚     â”‚                                              â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚                                              â”‚
â”‚                       â–¼                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                     â”‚
â”‚  â”‚ Python SDK   â”‚   â”‚     Nginx (Ğ¿Ğ¾Ñ€Ñ‚ 5000)    â”‚                     â”‚
â”‚  â”‚ (mlflow.*)   â”‚â”€â”€â–¶â”‚   Basic Auth (htpasswd)  â”‚                     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                     â”‚
â”‚        â”‚                        â”‚                                    â”‚
â”‚        â”‚                        â–¼                                    â”‚
â”‚        â”‚            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                     â”‚
â”‚        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚  MLflow Server (Ğ²Ğ½ÑƒÑ‚Ñ€.)  â”‚                     â”‚
â”‚                     â”‚   Basic Auth (built-in)  â”‚                     â”‚
â”‚                     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                     â”‚
â”‚                                 â”‚                                    â”‚
â”‚                                 â–¼                                    â”‚
â”‚                     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                     â”‚
â”‚                     â”‚    MinIO (S3 Ğ°Ñ€Ñ‚ĞµÑ„Ğ°ĞºÑ‚Ñ‹)  â”‚                     â”‚
â”‚                     â”‚    Access Key + Secret   â”‚                     â”‚
â”‚                     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                     â”‚
â”‚                                                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Ğ£Ñ€Ğ¾Ğ²Ğ½Ğ¸ Ğ·Ğ°Ñ‰Ğ¸Ñ‚Ñ‹:**

| Ğ£Ñ€Ğ¾Ğ²ĞµĞ½ÑŒ | ĞšĞ¾Ğ¼Ğ¿Ğ¾Ğ½ĞµĞ½Ñ‚ | ĞœĞµÑ‚Ğ¾Ğ´ Ğ·Ğ°Ñ‰Ğ¸Ñ‚Ñ‹ |
|---------|-----------|--------------|
| 1 | MinIO (S3) | Access Key + Secret Key |
| 2 | Nginx (UI/Ğ±Ñ€Ğ°ÑƒĞ·ĞµÑ€) | Basic Auth (htpasswd) |
| 3 | MLflow (API/SDK) | Basic Auth (Ğ²ÑÑ‚Ñ€Ğ¾ĞµĞ½Ğ½Ñ‹Ğ¹) |

**ĞšĞ¾Ğ½Ñ„Ğ¸Ğ³ÑƒÑ€Ğ°Ñ†Ğ¸Ñ `.env`:**

```bash
# MinIO
MINIO_ROOT_USER=minioadmin0
MINIO_ROOT_PASSWORD=minioadmin1230

# MLflow Admin
MLFLOW_ADMIN_USERNAME=admin
MLFLOW_ADMIN_PASSWORD=secure_password_123

# MLflow Tracking (Ğ´Ğ»Ñ Python SDK)
MLFLOW_TRACKING_URI=http://localhost:5000
MLFLOW_TRACKING_USERNAME=admin
MLFLOW_TRACKING_PASSWORD=secure_password_123

# S3/MinIO Ğ´Ğ»Ñ Ğ°Ñ€Ñ‚ĞµÑ„Ğ°ĞºÑ‚Ğ¾Ğ²
MLFLOW_S3_ENDPOINT_URL=http://localhost:9000
AWS_ACCESS_KEY_ID=minioadmin0
AWS_SECRET_ACCESS_KEY=minioadmin1230
```

**Ğ”Ğ¾ÑÑ‚ÑƒĞ¿ Ğº ÑĞµÑ€Ğ²Ğ¸ÑĞ°Ğ¼:**

| Ğ¡ĞµÑ€Ğ²Ğ¸Ñ | URL | Ğ›Ğ¾Ğ³Ğ¸Ğ½/ĞŸĞ°Ñ€Ğ¾Ğ»ÑŒ | ĞĞ¿Ğ¸ÑĞ°Ğ½Ğ¸Ğµ |
|--------|-----|--------------|----------|
| **Airflow UI** | http://localhost:8080 | admin / admin | Ğ£Ğ¿Ñ€Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ğµ DAGs Ğ¸ Ğ¼Ğ¾Ğ½Ğ¸Ñ‚Ğ¾Ñ€Ğ¸Ğ½Ğ³ |
| **MLflow UI** | http://localhost:5000 | admin / secure_password_123 | Ğ’ĞµĞ±-Ğ¸Ğ½Ñ‚ĞµÑ€Ñ„ĞµĞ¹Ñ MLflow |
| **MinIO Console** | http://localhost:9001 | minioadmin0 / minioadmin1230 | Ğ£Ğ¿Ñ€Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ğµ Ñ…Ñ€Ğ°Ğ½Ğ¸Ğ»Ğ¸Ñ‰ĞµĞ¼ |
| **MinIO S3 API** | http://localhost:9000 | â€” | S3 API Ğ´Ğ»Ñ Ğ°Ñ€Ñ‚ĞµÑ„Ğ°ĞºÑ‚Ğ¾Ğ² |

---

## 2. ĞŸÑ€Ğ¾Ğ²ĞµĞ´ĞµĞ½Ğ¸Ğµ ÑĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚Ğ¾Ğ²

### 2.1 ĞŸÑ€Ğ¾Ğ²ĞµĞ´ĞµĞ½Ğ¸Ğµ 19 ÑĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚Ğ¾Ğ² Ñ Ñ€Ğ°Ğ·Ğ½Ñ‹Ğ¼Ğ¸ Ğ°Ğ»Ğ³Ğ¾Ñ€Ğ¸Ñ‚Ğ¼Ğ°Ğ¼Ğ¸

Ğ ĞµĞ°Ğ»Ğ¸Ğ·Ğ¾Ğ²Ğ°Ğ½ ĞºĞ¾Ğ¼Ğ¿Ğ»ĞµĞºÑĞ½Ñ‹Ğ¹ Ğ½Ğ°Ğ±Ğ¾Ñ€ ÑĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚Ğ¾Ğ² Ñ‡ĞµÑ€ĞµĞ· Airflow DAG `boston_housing_experiments` Ñ Ğ¿Ğ°Ñ€Ğ°Ğ»Ğ»ĞµĞ»ÑŒĞ½Ñ‹Ğ¼ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸ĞµĞ¼ 19 Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ Ğ¼Ğ°ÑˆĞ¸Ğ½Ğ½Ğ¾Ğ³Ğ¾ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ:

**Ğ›Ğ¸Ğ½ĞµĞ¹Ğ½Ñ‹Ğµ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ (7 ÑĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚Ğ¾Ğ²):**
| # | ĞĞ»Ğ³Ğ¾Ñ€Ğ¸Ñ‚Ğ¼ | ĞŸĞ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ñ‹ | ĞĞ¿Ğ¸ÑĞ°Ğ½Ğ¸Ğµ |
|---|----------|-----------|----------|
| 1 | Linear Regression | â€” | Baseline Ğ»Ğ¸Ğ½ĞµĞ¹Ğ½Ğ°Ñ Ñ€ĞµĞ³Ñ€ĞµÑÑĞ¸Ñ |
| 2 | Ridge | alpha=0.1 | Ridge Î±=0.1 |
| 3 | Ridge | alpha=1.0 | Ridge Î±=1.0 |
| 4 | Ridge | alpha=10.0 | Ridge Î±=10.0 |
| 5 | Lasso | alpha=0.1 | Lasso Î±=0.1 |
| 6 | ElasticNet | alpha=0.5, l1_ratio=0.5 | ElasticNet |
| 7 | Huber Regressor | epsilon=1.35 | Huber Regressor |

**Ğ”Ñ€ĞµĞ²Ğ¾Ğ²Ğ¸Ğ´Ğ½Ñ‹Ğµ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ Ğ¸ Ğ°Ğ½ÑĞ°Ğ¼Ğ±Ğ»Ğ¸ (9 ÑĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚Ğ¾Ğ²):**
| # | ĞĞ»Ğ³Ğ¾Ñ€Ğ¸Ñ‚Ğ¼ | ĞŸĞ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ñ‹ | ĞĞ¿Ğ¸ÑĞ°Ğ½Ğ¸Ğµ |
|---|----------|-----------|----------|
| 8 | Decision Tree | max_depth=5 | Decision Tree d=5 |
| 9 | Decision Tree | max_depth=10 | Decision Tree d=10 |
| 10 | Random Forest | n_estimators=100, max_depth=10 | RF n=100 |
| 11 | Random Forest | n_estimators=200, max_depth=15 | RF n=200 |
| 12 | Extra Trees | n_estimators=100, max_depth=10 | ExtraTrees |
| 13 | Gradient Boosting | n_estimators=100, learning_rate=0.1 | GBM lr=0.1 |
| 14 | Gradient Boosting | n_estimators=200, learning_rate=0.05 | GBM lr=0.05 |
| 15 | AdaBoost | n_estimators=50, learning_rate=1.0 | AdaBoost |
| 16 | Bagging | n_estimators=20 | Bagging |

**Ğ”Ñ€ÑƒĞ³Ğ¸Ğµ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ (3 ÑĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚Ğ°):**
| # | ĞĞ»Ğ³Ğ¾Ñ€Ğ¸Ñ‚Ğ¼ | ĞŸĞ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ñ‹ | ĞĞ¿Ğ¸ÑĞ°Ğ½Ğ¸Ğµ |
|---|----------|-----------|----------|
| 17 | SVR | kernel=rbf, C=1.0 | SVR RBF |
| 18 | KNN | n_neighbors=5, weights=uniform | KNN k=5 |
| 19 | KNN | n_neighbors=10, weights=distance | KNN k=10 |

**Ğ¡ĞºÑ€Ğ¸Ğ½ÑˆĞ¾Ñ‚ Ğ¿Ñ€Ğ¾Ğ²ĞµĞ´ĞµĞ½Ğ½Ñ‹Ñ… ÑĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚Ğ¾Ğ²:**

![UI MLFlow Ñ ÑĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚Ğ°Ğ¼Ğ¸](figures/5.png)

*Ğ Ğ¸Ñ. 2: MLflow UI Ñ Ğ¿Ñ€Ğ¾Ğ²ĞµĞ´ĞµĞ½Ğ½Ñ‹Ğ¼Ğ¸ Ğ¸ Ğ·Ğ°Ğ¿ÑƒÑ‰ĞµĞ½Ğ½Ñ‹Ğ¼Ğ¸ ÑĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚Ğ°Ğ¼Ğ¸*

### 2.2 ĞĞ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ° Ğ»Ğ¾Ğ³Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ Ğ¼ĞµÑ‚Ñ€Ğ¸Ğº, Ğ¿Ğ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ğ¾Ğ² Ğ¸ Ğ°Ñ€Ñ‚ĞµÑ„Ğ°ĞºÑ‚Ğ¾Ğ²

**Ğ›Ğ¾Ğ³Ğ¸Ñ€ÑƒĞµĞ¼Ñ‹Ğµ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ:**

| Ğ¢Ğ¸Ğ¿ | ĞŸÑ€Ğ¸Ğ¼ĞµÑ€Ñ‹ |
|-----|---------|
| **ĞŸĞ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ñ‹** | `n_estimators`, `max_depth`, `learning_rate`, `test_size` |
| **ĞœĞµÑ‚Ñ€Ğ¸ĞºĞ¸** | `r2_score`, `rmse`, `mae`, `mape` |
| **ĞÑ€Ñ‚ĞµÑ„Ğ°ĞºÑ‚Ñ‹** | ĞœĞ¾Ğ´ĞµĞ»Ğ¸ (`.pkl`), Ğ³Ñ€Ğ°Ñ„Ğ¸ĞºĞ¸ Ğ²Ğ°Ğ¶Ğ½Ğ¾ÑÑ‚Ğ¸ Ğ¿Ñ€Ğ¸Ğ·Ğ½Ğ°ĞºĞ¾Ğ², CSV Ñ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ğ°Ğ¼Ğ¸ |
| **Ğ¢ĞµĞ³Ğ¸** | `model_type`, `framework`, `dataset` |

**ĞŸÑ€Ğ¸Ğ¼ĞµÑ€ Ğ»Ğ¾Ğ³Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ:**

```python
import mlflow

with mlflow.start_run(run_name="rf-baseline"):
    # ĞŸĞ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ñ‹
    mlflow.log_params({
        "n_estimators": 200,
        "max_depth": 15,
        "min_samples_split": 5,
    })

    # ĞœĞµÑ‚Ñ€Ğ¸ĞºĞ¸
    mlflow.log_metrics({
        "r2_score": 0.8665,
        "rmse": 3.13,
        "mae": 2.09,
    })

    # ĞÑ€Ñ‚ĞµÑ„Ğ°ĞºÑ‚Ñ‹
    mlflow.sklearn.log_model(model, "model")
    mlflow.log_artifact("feature_importance.csv")

    # Ğ¢ĞµĞ³Ğ¸
    mlflow.set_tags({
        "model_type": "RandomForest",
        "framework": "sklearn",
    })
```


### 2.3 Ğ¡Ğ¸ÑÑ‚ĞµĞ¼Ğ° ÑÑ€Ğ°Ğ²Ğ½ĞµĞ½Ğ¸Ñ ÑĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚Ğ¾Ğ²

MLflow Ğ¿Ñ€ĞµĞ´Ğ¾ÑÑ‚Ğ°Ğ²Ğ»ÑĞµÑ‚ Ğ¼Ğ¾Ñ‰Ğ½Ñ‹Ğµ Ğ¸Ğ½ÑÑ‚Ñ€ÑƒĞ¼ĞµĞ½Ñ‚Ñ‹ Ğ´Ğ»Ñ ÑÑ€Ğ°Ğ²Ğ½ĞµĞ½Ğ¸Ñ:

**Ğ§ĞµÑ€ĞµĞ· UI:**
- Ğ¢Ğ°Ğ±Ğ»Ğ¸Ñ†Ğ° ÑĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚Ğ¾Ğ² Ñ ÑĞ¾Ñ€Ñ‚Ğ¸Ñ€Ğ¾Ğ²ĞºĞ¾Ğ¹ Ğ¿Ğ¾ Ğ¼ĞµÑ‚Ñ€Ğ¸ĞºĞ°Ğ¼
- Ğ“Ñ€Ğ°Ñ„Ğ¸ĞºĞ¸ ÑÑ€Ğ°Ğ²Ğ½ĞµĞ½Ğ¸Ñ (Parallel Coordinates, Scatter Plot)
- Ğ’Ğ¸Ğ·ÑƒĞ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ Ğ¸Ğ·Ğ¼ĞµĞ½ĞµĞ½Ğ¸Ñ Ğ¼ĞµÑ‚Ñ€Ğ¸Ğº Ğ¿Ğ¾ Ğ²Ñ€ĞµĞ¼ĞµĞ½Ğ¸

**Ğ§ĞµÑ€ĞµĞ· API:**

```python
from mlflow.tracking import MlflowClient

client = MlflowClient()

# ĞŸĞ¾Ğ»ÑƒÑ‡ĞµĞ½Ğ¸Ğµ Ñ‚Ğ¾Ğ¿-10 Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ Ğ¿Ğ¾ RÂ² Score
runs = client.search_runs(
    experiment_ids=["1"],
    order_by=["metrics.r2_score DESC"],
    max_results=10,
)

for run in runs:
    r2 = run.data.metrics.get("r2_score", 0)
    params = run.data.params
    print(f"Run {run.info.run_id[:8]}: RÂ²={r2:.4f}")
```

**Ğ§ĞµÑ€ĞµĞ· CLI:**

```bash
# Ğ¡Ğ¿Ğ¸ÑĞ¾Ğº ÑĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚Ğ¾Ğ²
mlflow experiments search

# ĞŸĞ¾Ğ¸ÑĞº Ğ·Ğ°Ğ¿ÑƒÑĞºĞ¾Ğ² Ñ Ñ„Ğ¸Ğ»ÑŒÑ‚Ñ€Ğ°Ñ†Ğ¸ĞµĞ¹
mlflow runs list --experiment-id 1

# Ğ¡Ñ€Ğ°Ğ²Ğ½ĞµĞ½Ğ¸Ğµ Ğ´Ğ²ÑƒÑ… Ğ·Ğ°Ğ¿ÑƒÑĞºĞ¾Ğ²
mlflow runs compare <run_id_1> <run_id_2>
```

### 2.4 Ğ¤Ğ¸Ğ»ÑŒÑ‚Ñ€Ğ°Ñ†Ğ¸Ñ Ğ¸ Ğ¿Ğ¾Ğ¸ÑĞº ÑĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚Ğ¾Ğ²

**Ğ’Ğ¾Ğ·Ğ¼Ğ¾Ğ¶Ğ½Ğ¾ÑÑ‚Ğ¸ Ñ„Ğ¸Ğ»ÑŒÑ‚Ñ€Ğ°Ñ†Ğ¸Ğ¸ Ğ² MLflow:**

```python
# ĞŸĞ¾Ğ¸ÑĞº Ğ¿Ğ¾ Ğ¼ĞµÑ‚Ñ€Ğ¸ĞºĞ°Ğ¼
runs = client.search_runs(
    experiment_ids=["1"],
    filter_string="metrics.r2_score > 0.85",
)

# ĞŸĞ¾Ğ¸ÑĞº Ğ¿Ğ¾ Ğ¿Ğ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ğ°Ğ¼
runs = client.search_runs(
    experiment_ids=["1"],
    filter_string="params.n_estimators = '200'",
)

# ĞŸĞ¾Ğ¸ÑĞº Ğ¿Ğ¾ Ñ‚ĞµĞ³Ğ°Ğ¼
runs = client.search_runs(
    experiment_ids=["1"],
    filter_string="tags.model_type = 'RandomForest'",
)

# ĞšĞ¾Ğ¼Ğ±Ğ¸Ğ½Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ğ¹ Ğ¿Ğ¾Ğ¸ÑĞº
runs = client.search_runs(
    experiment_ids=["1"],
    filter_string="""
        metrics.r2_score > 0.80
        AND params.max_depth != 'None'
        AND tags.framework = 'sklearn'
    """,
    order_by=["metrics.rmse ASC"],
)
```

**Ğ¡ĞºÑ€Ğ¸Ğ½ÑˆĞ¾Ñ‚ Ñ„Ğ¸Ğ»ÑŒÑ‚Ñ€Ğ°Ñ†Ğ¸Ğ¸ ÑĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚Ğ¾Ğ² (Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğµ Ğ½ĞµĞ´Ğ¾ÑÑ‚ÑƒĞ¿Ğ½Ğ¾):**

---

## 3. Ğ˜Ğ½Ñ‚ĞµĞ³Ñ€Ğ°Ñ†Ğ¸Ñ Ñ ĞºĞ¾Ğ´Ğ¾Ğ¼

### 3.1 Ğ˜Ğ½Ñ‚ĞµĞ³Ñ€Ğ°Ñ†Ğ¸Ñ MLflow Ğ² Python ĞºĞ¾Ğ´

**Ğ¡Ñ‚Ñ€ÑƒĞºÑ‚ÑƒÑ€Ğ° Ğ¼Ğ¾Ğ´ÑƒĞ»Ñ `src/tracking/`:**

```
src/tracking/
â”œâ”€â”€ __init__.py
â”œâ”€â”€ decorators.py      # 5 Ğ´ĞµĞºĞ¾Ñ€Ğ°Ñ‚Ğ¾Ñ€Ğ¾Ğ² Ğ´Ğ»Ñ Ğ°Ğ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¾Ğ³Ğ¾ Ğ»Ğ¾Ğ³Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ
â”œâ”€â”€ mlflow_tracker.py  # 2 ĞºĞ¾Ğ½Ñ‚ĞµĞºÑÑ‚Ğ½Ñ‹Ñ… Ğ¼ĞµĞ½ĞµĞ´Ğ¶ĞµÑ€Ğ°
â””â”€â”€ utils.py           # 9 ÑƒÑ‚Ğ¸Ğ»Ğ¸Ñ‚ Ğ´Ğ»Ñ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ñ‹ Ñ ÑĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚Ğ°Ğ¼Ğ¸
```

**ĞœĞ¾Ğ´ÑƒĞ»ÑŒ ĞºĞ¾Ğ½Ñ„Ğ¸Ğ³ÑƒÑ€Ğ°Ñ†Ğ¸Ğ¸ `src/config/mlflow_config.py`:**

```python
"""ĞšĞ¾Ğ½Ñ„Ğ¸Ğ³ÑƒÑ€Ğ°Ñ†Ğ¸Ñ MLflow Ğ´Ğ»Ñ Ğ¿Ñ€Ğ¾ĞµĞºÑ‚Ğ°."""

import os

# MLflow Tracking
MLFLOW_TRACKING_URI = os.getenv("MLFLOW_TRACKING_URI", "http://localhost:5000")
MLFLOW_EXPERIMENT_NAME = os.getenv("MLFLOW_EXPERIMENT_NAME", "boston-housing")

# MinIO/S3 Ğ´Ğ»Ñ Ğ°Ñ€Ñ‚ĞµÑ„Ğ°ĞºÑ‚Ğ¾Ğ²
MLFLOW_S3_ENDPOINT_URL = os.getenv("MLFLOW_S3_ENDPOINT_URL", "http://localhost:9000")
AWS_ACCESS_KEY_ID = os.getenv("AWS_ACCESS_KEY_ID", "minioadmin0")
AWS_SECRET_ACCESS_KEY = os.getenv("AWS_SECRET_ACCESS_KEY", "minioadmin1230")


def setup_mlflow_env():
    """ĞĞ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ° Ğ¿ĞµÑ€ĞµĞ¼ĞµĞ½Ğ½Ñ‹Ñ… Ğ¾ĞºÑ€ÑƒĞ¶ĞµĞ½Ğ¸Ñ Ğ´Ğ»Ñ MLflow + S3."""
    os.environ["MLFLOW_S3_ENDPOINT_URL"] = MLFLOW_S3_ENDPOINT_URL
    os.environ["AWS_ACCESS_KEY_ID"] = AWS_ACCESS_KEY_ID
    os.environ["AWS_SECRET_ACCESS_KEY"] = AWS_SECRET_ACCESS_KEY
```

### 3.2 Ğ”ĞµĞºĞ¾Ñ€Ğ°Ñ‚Ğ¾Ñ€Ñ‹ Ğ´Ğ»Ñ Ğ°Ğ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¾Ğ³Ğ¾ Ğ»Ğ¾Ğ³Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ

**ĞœĞ¾Ğ´ÑƒĞ»ÑŒ `src/tracking/decorators.py`:**

Ğ ĞµĞ°Ğ»Ğ¸Ğ·Ğ¾Ğ²Ğ°Ğ½Ğ¾ **5 Ğ´ĞµĞºĞ¾Ñ€Ğ°Ñ‚Ğ¾Ñ€Ğ¾Ğ²** Ğ´Ğ»Ñ Ğ°Ğ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¾Ğ³Ğ¾ Ğ»Ğ¾Ğ³Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ:

| Ğ”ĞµĞºĞ¾Ñ€Ğ°Ñ‚Ğ¾Ñ€ | ĞĞ°Ğ·Ğ½Ğ°Ñ‡ĞµĞ½Ğ¸Ğµ |
|-----------|------------|
| `@mlflow_run` | ĞĞ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¾Ğµ ÑĞ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ğµ MLflow run Ñ Ğ»Ğ¾Ğ³Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸ĞµĞ¼ Ğ²Ñ€ĞµĞ¼ĞµĞ½Ğ¸ Ğ²Ñ‹Ğ¿Ğ¾Ğ»Ğ½ĞµĞ½Ğ¸Ñ |
| `@log_params_decorator` | ĞĞ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¾Ğµ Ğ»Ğ¾Ğ³Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ kwargs Ñ„ÑƒĞ½ĞºÑ†Ğ¸Ğ¸ ĞºĞ°Ğº Ğ¿Ğ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ğ¾Ğ² |
| `@log_metrics_decorator` | Ğ˜Ğ·Ğ²Ğ»ĞµÑ‡ĞµĞ½Ğ¸Ğµ Ğ¸ Ğ»Ğ¾Ğ³Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ¼ĞµÑ‚Ñ€Ğ¸Ğº Ğ¸Ğ· Ğ²Ğ¾Ğ·Ğ²Ñ€Ğ°Ñ‰Ğ°ĞµĞ¼Ğ¾Ğ³Ğ¾ ÑĞ»Ğ¾Ğ²Ğ°Ñ€Ñ |
| `@log_artifact_decorator` | ĞĞ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¾Ğµ Ğ»Ğ¾Ğ³Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ñ„Ğ°Ğ¹Ğ»Ğ°-Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ğ° ĞºĞ°Ğº Ğ°Ñ€Ñ‚ĞµÑ„Ğ°ĞºÑ‚Ğ° |
| `@timed_execution` | Ğ˜Ğ·Ğ¼ĞµÑ€ĞµĞ½Ğ¸Ğµ Ğ¸ Ğ»Ğ¾Ğ³Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ²Ñ€ĞµĞ¼ĞµĞ½Ğ¸ Ğ²Ñ‹Ğ¿Ğ¾Ğ»Ğ½ĞµĞ½Ğ¸Ñ Ñ„ÑƒĞ½ĞºÑ†Ğ¸Ğ¸ |

```python
"""Ğ”ĞµĞºĞ¾Ñ€Ğ°Ñ‚Ğ¾Ñ€Ñ‹ Ğ´Ğ»Ñ Ğ°Ğ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¾Ğ³Ğ¾ Ğ»Ğ¾Ğ³Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ Ğ² MLflow."""

import functools
import time
from typing import Any, Callable

import mlflow
from loguru import logger


def mlflow_run(
    experiment_name: str = "boston-housing",
    run_name: str | None = None,
    tags: dict | None = None,
):
    """
    Ğ”ĞµĞºĞ¾Ñ€Ğ°Ñ‚Ğ¾Ñ€ Ğ´Ğ»Ñ Ğ°Ğ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¾Ğ³Ğ¾ ÑĞ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ñ MLflow run.

    Ğ¡Ğ¾Ğ·Ğ´Ğ°Ñ‘Ñ‚ Ğ½Ğ¾Ğ²Ñ‹Ğ¹ MLflow run Ğ¿ĞµÑ€ĞµĞ´ Ğ²Ñ‹Ğ¿Ğ¾Ğ»Ğ½ĞµĞ½Ğ¸ĞµĞ¼ Ñ„ÑƒĞ½ĞºÑ†Ğ¸Ğ¸ Ğ¸ Ğ°Ğ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¸
    Ğ»Ğ¾Ğ³Ğ¸Ñ€ÑƒĞµÑ‚ Ğ²Ñ€ĞµĞ¼Ñ Ğ²Ñ‹Ğ¿Ğ¾Ğ»Ğ½ĞµĞ½Ğ¸Ñ.

    Example:
        >>> @mlflow_run(experiment_name="my-exp", run_name="baseline")
        ... def train_model(params):
        ...     model = RandomForestRegressor(**params)
        ...     model.fit(X_train, y_train)
        ...     return model
    """
    def decorator(func: Callable) -> Callable:
        @functools.wraps(func)
        def wrapper(*args, **kwargs) -> Any:
            mlflow.set_experiment(experiment_name)

            with mlflow.start_run(run_name=run_name, tags=tags):
                start_time = time.time()
                mlflow.log_param("start_time", start_time)
                result = func(*args, **kwargs)
                duration = time.time() - start_time
                mlflow.log_metric("duration_seconds", duration)
                logger.info(f"Ğ­ĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚ Ğ·Ğ°Ğ²ĞµÑ€ÑˆÑ‘Ğ½ Ğ·Ğ° {duration:.2f}Ñ")
                return result

        return wrapper
    return decorator


def log_params_decorator(func: Callable) -> Callable:
    """
    Ğ”ĞµĞºĞ¾Ñ€Ğ°Ñ‚Ğ¾Ñ€ Ğ´Ğ»Ñ Ğ°Ğ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¾Ğ³Ğ¾ Ğ»Ğ¾Ğ³Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ Ğ¿Ğ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ğ¾Ğ² Ñ„ÑƒĞ½ĞºÑ†Ğ¸Ğ¸.
    ĞĞ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¸ Ğ»Ğ¾Ğ³Ğ¸Ñ€ÑƒĞµÑ‚ Ğ²ÑĞµ kwargs Ğ¿ĞµÑ€ĞµĞ´Ğ°Ğ½Ğ½Ñ‹Ğµ Ğ² Ñ„ÑƒĞ½ĞºÑ†Ğ¸Ñ ĞºĞ°Ğº Ğ¿Ğ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ñ‹ MLflow.
    """
    @functools.wraps(func)
    def wrapper(*args, **kwargs) -> Any:
        if kwargs and mlflow.active_run():
            mlflow.log_params(kwargs)
            logger.debug(f"Ğ—Ğ°Ğ»Ğ¾Ğ³Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ñ‹ Ğ¿Ğ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ñ‹: {list(kwargs.keys())}")
        return func(*args, **kwargs)
    return wrapper


def log_metrics_decorator(metric_keys: list[str]):
    """
    Ğ”ĞµĞºĞ¾Ñ€Ğ°Ñ‚Ğ¾Ñ€ Ğ´Ğ»Ñ Ğ°Ğ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¾Ğ³Ğ¾ Ğ»Ğ¾Ğ³Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ Ğ¼ĞµÑ‚Ñ€Ğ¸Ğº Ğ¸Ğ· Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ğ°.
    Ğ˜Ğ·Ğ²Ğ»ĞµĞºĞ°ĞµÑ‚ ÑƒĞºĞ°Ğ·Ğ°Ğ½Ğ½Ñ‹Ğµ ĞºĞ»ÑÑ‡Ğ¸ Ğ¸Ğ· Ğ²Ğ¾Ğ·Ğ²Ñ€Ğ°Ñ‰Ğ°ĞµĞ¼Ğ¾Ğ³Ğ¾ ÑĞ»Ğ¾Ğ²Ğ°Ñ€Ñ Ğ¸ Ğ»Ğ¾Ğ³Ğ¸Ñ€ÑƒĞµÑ‚ Ğ¸Ñ… ĞºĞ°Ğº Ğ¼ĞµÑ‚Ñ€Ğ¸ĞºĞ¸.
    """
    def decorator(func: Callable) -> Callable:
        @functools.wraps(func)
        def wrapper(*args, **kwargs) -> dict:
            result = func(*args, **kwargs)
            if isinstance(result, dict) and mlflow.active_run():
                metrics_to_log = {
                    k: v for k, v in result.items()
                    if k in metric_keys and isinstance(v, (int, float))
                }
                if metrics_to_log:
                    mlflow.log_metrics(metrics_to_log)
            return result
        return wrapper
    return decorator


def log_artifact_decorator(artifact_path: str | None = None):
    """
    Ğ”ĞµĞºĞ¾Ñ€Ğ°Ñ‚Ğ¾Ñ€ Ğ´Ğ»Ñ Ğ°Ğ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¾Ğ³Ğ¾ Ğ»Ğ¾Ğ³Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ Ğ°Ñ€Ñ‚ĞµÑ„Ğ°ĞºÑ‚Ğ°.
    Ğ•ÑĞ»Ğ¸ Ñ„ÑƒĞ½ĞºÑ†Ğ¸Ñ Ğ²Ğ¾Ğ·Ğ²Ñ€Ğ°Ñ‰Ğ°ĞµÑ‚ Ğ¿ÑƒÑ‚ÑŒ Ğº Ñ„Ğ°Ğ¹Ğ»Ñƒ, ÑÑ‚Ğ¾Ñ‚ Ñ„Ğ°Ğ¹Ğ» Ğ±ÑƒĞ´ĞµÑ‚ Ğ·Ğ°Ğ»Ğ¾Ğ³Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½.
    """
    from pathlib import Path

    def decorator(func: Callable) -> Callable:
        @functools.wraps(func)
        def wrapper(*args, **kwargs) -> Any:
            result = func(*args, **kwargs)
            if mlflow.active_run():
                if isinstance(result, (str, Path)) and Path(result).exists():
                    mlflow.log_artifact(str(result), artifact_path)
                    logger.debug(f"ĞÑ€Ñ‚ĞµÑ„Ğ°ĞºÑ‚ Ğ·Ğ°Ğ»Ğ¾Ğ³Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½: {result}")
            return result
        return wrapper
    return decorator


def timed_execution(func: Callable) -> Callable:
    """
    Ğ”ĞµĞºĞ¾Ñ€Ğ°Ñ‚Ğ¾Ñ€ Ğ´Ğ»Ñ Ğ¸Ğ·Ğ¼ĞµÑ€ĞµĞ½Ğ¸Ñ Ğ²Ñ€ĞµĞ¼ĞµĞ½Ğ¸ Ğ²Ñ‹Ğ¿Ğ¾Ğ»Ğ½ĞµĞ½Ğ¸Ñ Ñ„ÑƒĞ½ĞºÑ†Ğ¸Ğ¸.
    Ğ›Ğ¾Ğ³Ğ¸Ñ€ÑƒĞµÑ‚ Ğ²Ñ€ĞµĞ¼Ñ Ğ²Ñ‹Ğ¿Ğ¾Ğ»Ğ½ĞµĞ½Ğ¸Ñ ĞºĞ°Ğº Ğ¼ĞµÑ‚Ñ€Ğ¸ĞºÑƒ {function_name}_duration_seconds.
    """
    @functools.wraps(func)
    def wrapper(*args, **kwargs) -> Any:
        start_time = time.time()
        result = func(*args, **kwargs)
        duration = time.time() - start_time
        if mlflow.active_run():
            metric_name = f"{func.__name__}_duration_seconds"
            mlflow.log_metric(metric_name, duration)
        logger.debug(f"{func.__name__} Ğ²Ñ‹Ğ¿Ğ¾Ğ»Ğ½ĞµĞ½Ğ° Ğ·Ğ° {duration:.2f}Ñ")
        return result
    return wrapper
```

**ĞŸÑ€Ğ¸Ğ¼ĞµÑ€ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ Ğ´ĞµĞºĞ¾Ñ€Ğ°Ñ‚Ğ¾Ñ€Ğ¾Ğ²:**

```python
from src.tracking.decorators import mlflow_run, log_params_decorator, log_metrics_decorator

@mlflow_run(experiment_name="boston-housing", run_name="rf-experiment")
@log_params_decorator
def train_model(n_estimators=100, max_depth=10, **params):
    model = RandomForestRegressor(n_estimators=n_estimators, max_depth=max_depth)
    model.fit(X_train, y_train)
    return model

@log_metrics_decorator(["r2_score", "rmse", "mae"])
def evaluate_model(model, X_test, y_test) -> dict:
    y_pred = model.predict(X_test)
    return {
        "r2_score": r2_score(y_test, y_pred),
        "rmse": np.sqrt(mean_squared_error(y_test, y_pred)),
        "mae": mean_absolute_error(y_test, y_pred),
    }

# Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ
model = train_model(n_estimators=200, max_depth=15)
metrics = evaluate_model(model, X_test, y_test)
```

### 3.3 ĞšĞ¾Ğ½Ñ‚ĞµĞºÑÑ‚Ğ½Ñ‹Ğµ Ğ¼ĞµĞ½ĞµĞ´Ğ¶ĞµÑ€Ñ‹

**ĞœĞ¾Ğ´ÑƒĞ»ÑŒ `src/tracking/mlflow_tracker.py`:**

Ğ ĞµĞ°Ğ»Ğ¸Ğ·Ğ¾Ğ²Ğ°Ğ½Ğ¾ **2 ĞºĞ»Ğ°ÑÑĞ°** Ğ´Ğ»Ñ ÑƒĞ¿Ñ€Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ñ ÑĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚Ğ°Ğ¼Ğ¸:

| ĞšĞ»Ğ°ÑÑ | ĞĞ°Ğ·Ğ½Ğ°Ñ‡ĞµĞ½Ğ¸Ğµ |
|-------|------------|
| `MLflowExperimentTracker` | ĞÑĞ½Ğ¾Ğ²Ğ½Ğ¾Ğ¹ ĞºĞ¾Ğ½Ñ‚ĞµĞºÑÑ‚Ğ½Ñ‹Ğ¹ Ğ¼ĞµĞ½ĞµĞ´Ğ¶ĞµÑ€ Ğ´Ğ»Ñ Ñ‚Ñ€ĞµĞºĞ¸Ğ½Ğ³Ğ° ÑĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚Ğ¾Ğ² |
| `NestedRunTracker` | ĞšĞ¾Ğ½Ñ‚ĞµĞºÑÑ‚Ğ½Ñ‹Ğ¹ Ğ¼ĞµĞ½ĞµĞ´Ğ¶ĞµÑ€ Ğ´Ğ»Ñ Ğ²Ğ»Ğ¾Ğ¶ĞµĞ½Ğ½Ñ‹Ñ… runs (ĞºÑ€Ğ¾ÑÑ-Ğ²Ğ°Ğ»Ğ¸Ğ´Ğ°Ñ†Ğ¸Ñ, grid search) |

```python
"""MLflow Ñ‚Ñ€ĞµĞºĞµÑ€ Ñ Ğ¿Ğ¾Ğ´Ğ´ĞµÑ€Ğ¶ĞºĞ¾Ğ¹ ĞºĞ¾Ğ½Ñ‚ĞµĞºÑÑ‚Ğ½Ğ¾Ğ³Ğ¾ Ğ¼ĞµĞ½ĞµĞ´Ğ¶ĞµÑ€Ğ°."""

from typing import Any
from pathlib import Path

import mlflow
from mlflow.models.signature import infer_signature
from loguru import logger

from src.config.mlflow_config import (
    MLFLOW_TRACKING_URI,
    MLFLOW_EXPERIMENT_NAME,
    setup_mlflow_env,
)


class MLflowExperimentTracker:
    """
    ĞšĞ¾Ğ½Ñ‚ĞµĞºÑÑ‚Ğ½Ñ‹Ğ¹ Ğ¼ĞµĞ½ĞµĞ´Ğ¶ĞµÑ€ Ğ´Ğ»Ñ Ñ‚Ñ€ĞµĞºĞ¸Ğ½Ğ³Ğ° ML ÑĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚Ğ¾Ğ².

    ĞŸÑ€ĞµĞ´Ğ¾ÑÑ‚Ğ°Ğ²Ğ»ÑĞµÑ‚ ÑƒĞ´Ğ¾Ğ±Ğ½Ñ‹Ğ¹ Ğ¸Ğ½Ñ‚ĞµÑ€Ñ„ĞµĞ¹Ñ Ğ´Ğ»Ñ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ñ‹ Ñ MLflow: Ğ°Ğ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¸
    Ğ½Ğ°ÑÑ‚Ñ€Ğ°Ğ¸Ğ²Ğ°ĞµÑ‚ Ğ¾ĞºÑ€ÑƒĞ¶ĞµĞ½Ğ¸Ğµ, ÑƒĞ¿Ñ€Ğ°Ğ²Ğ»ÑĞµÑ‚ Ğ¶Ğ¸Ğ·Ğ½ĞµĞ½Ğ½Ñ‹Ğ¼ Ñ†Ğ¸ĞºĞ»Ğ¾Ğ¼ run Ğ¸ Ğ»Ğ¾Ğ³Ğ¸Ñ€ÑƒĞµÑ‚
    Ğ¿Ğ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ñ‹, Ğ¼ĞµÑ‚Ñ€Ğ¸ĞºĞ¸, Ğ°Ñ€Ñ‚ĞµÑ„Ğ°ĞºÑ‚Ñ‹ Ğ¸ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸.

    Attributes:
        experiment_name: ĞĞ°Ğ·Ğ²Ğ°Ğ½Ğ¸Ğµ ÑĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚Ğ° MLflow
        run: Ğ¢ĞµĞºÑƒÑ‰Ğ¸Ğ¹ Ğ°ĞºÑ‚Ğ¸Ğ²Ğ½Ñ‹Ğ¹ run (Ğ¸Ğ»Ğ¸ None)

    Example:
        >>> tracker = MLflowExperimentTracker(experiment_name="boston-housing")
        >>> with tracker.start_run(run_name="gradient-boosting-v1"):
        ...     tracker.set_tags({"model_type": "GradientBoosting"})
        ...     tracker.log_params({"n_estimators": 200, "max_depth": 10})
        ...     model = GradientBoostingRegressor(n_estimators=200, max_depth=10)
        ...     model.fit(X_train, y_train)
        ...     tracker.log_metrics({"r2_score": 0.85, "rmse": 3.2})
        ...     tracker.log_model(model, "model", input_example=X_test.head(5))
        ...     print(f"Run ID: {tracker.run_id}")
    """

    def __init__(
        self,
        experiment_name: str = MLFLOW_EXPERIMENT_NAME,
        tracking_uri: str = MLFLOW_TRACKING_URI,
    ):
        setup_mlflow_env()
        mlflow.set_tracking_uri(tracking_uri)
        mlflow.set_experiment(experiment_name)
        self.experiment_name = experiment_name
        self.run = None
        logger.info(f"MLflow Ñ‚Ñ€ĞµĞºĞµÑ€: {tracking_uri}, ÑĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚: {experiment_name}")

    def start_run(self, run_name: str | None = None, tags: dict | None = None):
        """ĞĞ°Ñ‡Ğ°Ğ»Ğ¾ Ğ½Ğ¾Ğ²Ğ¾Ğ³Ğ¾ Ğ·Ğ°Ğ¿ÑƒÑĞºĞ° ÑĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚Ğ°."""
        self.run = mlflow.start_run(run_name=run_name, tags=tags)
        logger.info(f"Ğ—Ğ°Ğ¿ÑƒÑ‰ĞµĞ½ run: {self.run.info.run_id}")
        return self

    def __enter__(self):
        if self.run is None:
            self.start_run()
        return self

    def __exit__(self, exc_type, exc_val, exc_tb):
        mlflow.end_run()
        self.run = None

    def log_params(self, params: dict[str, Any]):
        """Ğ›Ğ¾Ğ³Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ¿Ğ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ğ¾Ğ²."""
        mlflow.log_params(params)
        logger.debug(f"Ğ—Ğ°Ğ»Ğ¾Ğ³Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ñ‹ Ğ¿Ğ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ñ‹: {list(params.keys())}")

    def log_param(self, key: str, value: Any):
        """Ğ›Ğ¾Ğ³Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ¾Ğ´Ğ½Ğ¾Ğ³Ğ¾ Ğ¿Ğ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ğ°."""
        mlflow.log_param(key, value)

    def log_metrics(self, metrics: dict[str, float], step: int | None = None):
        """Ğ›Ğ¾Ğ³Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ¼ĞµÑ‚Ñ€Ğ¸Ğº."""
        mlflow.log_metrics(metrics, step=step)
        for name, value in metrics.items():
            logger.info(f"ĞœĞµÑ‚Ñ€Ğ¸ĞºĞ° {name}: {value:.4f}")

    def log_metric(self, key: str, value: float, step: int | None = None):
        """Ğ›Ğ¾Ğ³Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ¾Ğ´Ğ½Ğ¾Ğ¹ Ğ¼ĞµÑ‚Ñ€Ğ¸ĞºĞ¸."""
        mlflow.log_metric(key, value, step=step)

    def log_artifact(self, local_path: str | Path, artifact_path: str | None = None):
        """Ğ›Ğ¾Ğ³Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ°Ñ€Ñ‚ĞµÑ„Ğ°ĞºÑ‚Ğ° (Ñ„Ğ°Ğ¹Ğ»Ğ°)."""
        mlflow.log_artifact(str(local_path), artifact_path)
        logger.info(f"ĞÑ€Ñ‚ĞµÑ„Ğ°ĞºÑ‚ ÑĞ¾Ñ…Ñ€Ğ°Ğ½Ñ‘Ğ½: {local_path}")

    def log_artifacts(self, local_dir: str | Path, artifact_path: str | None = None):
        """Ğ›Ğ¾Ğ³Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ´Ğ¸Ñ€ĞµĞºÑ‚Ğ¾Ñ€Ğ¸Ğ¸ Ğ°Ñ€Ñ‚ĞµÑ„Ğ°ĞºÑ‚Ğ¾Ğ²."""
        mlflow.log_artifacts(str(local_dir), artifact_path)
        logger.info(f"Ğ”Ğ¸Ñ€ĞµĞºÑ‚Ğ¾Ñ€Ğ¸Ñ Ğ°Ñ€Ñ‚ĞµÑ„Ğ°ĞºÑ‚Ğ¾Ğ² ÑĞ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ğ°: {local_dir}")

    def log_model(self, model, artifact_path: str, input_example=None,
                  registered_model_name: str | None = None):
        """Ğ›Ğ¾Ğ³Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ sklearn Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ Ñ Ğ°Ğ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ğ¼ Ğ¾Ğ¿Ñ€ĞµĞ´ĞµĞ»ĞµĞ½Ğ¸ĞµĞ¼ ÑĞ¸Ğ³Ğ½Ğ°Ñ‚ÑƒÑ€Ñ‹."""
        signature = None
        if input_example is not None:
            predictions = model.predict(input_example)
            signature = infer_signature(input_example, predictions)
        mlflow.sklearn.log_model(
            model, artifact_path,
            signature=signature,
            input_example=input_example,
            registered_model_name=registered_model_name,
        )
        logger.info(f"ĞœĞ¾Ğ´ĞµĞ»ÑŒ ÑĞ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ğ°: {artifact_path}")

    def set_tags(self, tags: dict[str, str]):
        """Ğ£ÑÑ‚Ğ°Ğ½Ğ¾Ğ²ĞºĞ° Ñ‚ĞµĞ³Ğ¾Ğ²."""
        mlflow.set_tags(tags)

    def set_tag(self, key: str, value: str):
        """Ğ£ÑÑ‚Ğ°Ğ½Ğ¾Ğ²ĞºĞ° Ğ¾Ğ´Ğ½Ğ¾Ğ³Ğ¾ Ñ‚ĞµĞ³Ğ°."""
        mlflow.set_tag(key, value)

    def log_dict(self, dictionary: dict, artifact_file: str):
        """Ğ›Ğ¾Ğ³Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ ÑĞ»Ğ¾Ğ²Ğ°Ñ€Ñ ĞºĞ°Ğº JSON/YAML Ğ°Ñ€Ñ‚ĞµÑ„Ğ°ĞºÑ‚Ğ°."""
        mlflow.log_dict(dictionary, artifact_file)

    def log_figure(self, figure, artifact_file: str):
        """Ğ›Ğ¾Ğ³Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ matplotlib/plotly Ñ„Ğ¸Ğ³ÑƒÑ€Ñ‹."""
        mlflow.log_figure(figure, artifact_file)

    @property
    def run_id(self) -> str | None:
        """ID Ñ‚ĞµĞºÑƒÑ‰ĞµĞ³Ğ¾ Ğ·Ğ°Ğ¿ÑƒÑĞºĞ°."""
        return self.run.info.run_id if self.run else None

    @property
    def artifact_uri(self) -> str | None:
        """URI Ñ…Ñ€Ğ°Ğ½Ğ¸Ğ»Ğ¸Ñ‰Ğ° Ğ°Ñ€Ñ‚ĞµÑ„Ğ°ĞºÑ‚Ğ¾Ğ² Ñ‚ĞµĞºÑƒÑ‰ĞµĞ³Ğ¾ Ğ·Ğ°Ğ¿ÑƒÑĞºĞ°."""
        return self.run.info.artifact_uri if self.run else None

    @property
    def experiment_id(self) -> str | None:
        """ID Ñ‚ĞµĞºÑƒÑ‰ĞµĞ³Ğ¾ ÑĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚Ğ°."""
        return self.run.info.experiment_id if self.run else None


class NestedRunTracker:
    """
    ĞšĞ¾Ğ½Ñ‚ĞµĞºÑÑ‚Ğ½Ñ‹Ğ¹ Ğ¼ĞµĞ½ĞµĞ´Ğ¶ĞµÑ€ Ğ´Ğ»Ñ Ğ²Ğ»Ğ¾Ğ¶ĞµĞ½Ğ½Ñ‹Ñ… MLflow runs.

    ĞŸĞ¾Ğ·Ğ²Ğ¾Ğ»ÑĞµÑ‚ ÑĞ¾Ğ·Ğ´Ğ°Ğ²Ğ°Ñ‚ÑŒ Ğ¸ĞµÑ€Ğ°Ñ€Ñ…Ğ¸Ñ‡ĞµÑĞºÑƒÑ ÑÑ‚Ñ€ÑƒĞºÑ‚ÑƒÑ€Ñƒ ÑĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚Ğ¾Ğ²,
    Ğ½Ğ°Ğ¿Ñ€Ğ¸Ğ¼ĞµÑ€, Ğ´Ğ»Ñ ĞºÑ€Ğ¾ÑÑ-Ğ²Ğ°Ğ»Ğ¸Ğ´Ğ°Ñ†Ğ¸Ğ¸ Ğ¸Ğ»Ğ¸ grid search.

    Example:
        >>> with MLflowExperimentTracker() as parent:
        ...     parent.log_params({"model": "RandomForest"})
        ...     for fold in range(5):
        ...         with NestedRunTracker(f"fold-{fold}") as child:
        ...             child.log_metrics({"accuracy": 0.85 + fold * 0.01})
    """

    def __init__(self, run_name: str | None = None, tags: dict | None = None):
        self.run_name = run_name
        self.tags = tags
        self.run = None

    def __enter__(self):
        self.run = mlflow.start_run(run_name=self.run_name, tags=self.tags, nested=True)
        return self

    def __exit__(self, exc_type, exc_val, exc_tb):
        mlflow.end_run()
        self.run = None

    def log_params(self, params: dict[str, Any]):
        """Ğ›Ğ¾Ğ³Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ¿Ğ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ğ¾Ğ²."""
        mlflow.log_params(params)

    def log_metrics(self, metrics: dict[str, float], step: int | None = None):
        """Ğ›Ğ¾Ğ³Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ¼ĞµÑ‚Ñ€Ğ¸Ğº."""
        mlflow.log_metrics(metrics, step=step)

    def log_metric(self, key: str, value: float, step: int | None = None):
        """Ğ›Ğ¾Ğ³Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ¾Ğ´Ğ½Ğ¾Ğ¹ Ğ¼ĞµÑ‚Ñ€Ğ¸ĞºĞ¸."""
        mlflow.log_metric(key, value, step=step)

    @property
    def run_id(self) -> str | None:
        """ID Ñ‚ĞµĞºÑƒÑ‰ĞµĞ³Ğ¾ Ğ²Ğ»Ğ¾Ğ¶ĞµĞ½Ğ½Ğ¾Ğ³Ğ¾ Ğ·Ğ°Ğ¿ÑƒÑĞºĞ°."""
        return self.run.info.run_id if self.run else None
```

**ĞŸÑ€Ğ¸Ğ¼ĞµÑ€ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ ĞºĞ¾Ğ½Ñ‚ĞµĞºÑÑ‚Ğ½Ğ¾Ğ³Ğ¾ Ğ¼ĞµĞ½ĞµĞ´Ğ¶ĞµÑ€Ğ°:**

```python
from src.tracking.mlflow_tracker import MLflowExperimentTracker

tracker = MLflowExperimentTracker(experiment_name="boston-housing")

with tracker.start_run(run_name="gradient-boosting-v1"):
    tracker.set_tags({"model_type": "GradientBoosting", "framework": "sklearn"})
    tracker.log_params({"n_estimators": 200, "max_depth": 10})

    # ĞĞ±ÑƒÑ‡ĞµĞ½Ğ¸Ğµ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸
    model = GradientBoostingRegressor(n_estimators=200, max_depth=10)
    model.fit(X_train, y_train)

    # ĞÑ†ĞµĞ½ĞºĞ°
    metrics = evaluate_model(model, X_test, y_test)
    tracker.log_metrics(metrics)

    # Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ğ¸Ğµ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸
    tracker.log_model(model, "model", input_example=X_test.head(5))

    print(f"Run ID: {tracker.run_id}")
    print(f"Artifacts: {tracker.artifact_uri}")
```

### 3.4 Ğ£Ñ‚Ğ¸Ğ»Ğ¸Ñ‚Ñ‹ Ğ´Ğ»Ñ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ñ‹ Ñ ÑĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚Ğ°Ğ¼Ğ¸

**ĞœĞ¾Ğ´ÑƒĞ»ÑŒ `src/tracking/utils.py`:**

Ğ ĞµĞ°Ğ»Ğ¸Ğ·Ğ¾Ğ²Ğ°Ğ½Ğ¾ **9 ÑƒÑ‚Ğ¸Ğ»Ğ¸Ñ‚** Ğ´Ğ»Ñ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ñ‹ Ñ MLflow ÑĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚Ğ°Ğ¼Ğ¸:

| Ğ¤ÑƒĞ½ĞºÑ†Ğ¸Ñ | ĞĞ°Ğ·Ğ½Ğ°Ñ‡ĞµĞ½Ğ¸Ğµ |
|---------|------------|
| `get_best_run` | ĞŸĞ¾Ğ»ÑƒÑ‡ĞµĞ½Ğ¸Ğµ Ğ»ÑƒÑ‡ÑˆĞµĞ³Ğ¾ Ğ·Ğ°Ğ¿ÑƒÑĞºĞ° Ğ¿Ğ¾ Ğ¼ĞµÑ‚Ñ€Ğ¸ĞºĞµ |
| `load_best_model` | Ğ—Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞ° Ğ»ÑƒÑ‡ÑˆĞµĞ¹ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ Ğ¸Ğ· ÑĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚Ğ° |
| `compare_runs` | Ğ¡Ñ€Ğ°Ğ²Ğ½ĞµĞ½Ğ¸Ğµ Ğ·Ğ°Ğ¿ÑƒÑĞºĞ¾Ğ² Ğ² Ğ²Ğ¸Ğ´Ğµ DataFrame |
| `register_best_model` | Ğ ĞµĞ³Ğ¸ÑÑ‚Ñ€Ğ°Ñ†Ğ¸Ñ Ğ»ÑƒÑ‡ÑˆĞµĞ¹ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ Ğ² Model Registry |
| `delete_experiment_runs` | Ğ£Ğ´Ğ°Ğ»ĞµĞ½Ğ¸Ğµ ÑÑ‚Ğ°Ñ€Ñ‹Ñ… Ğ·Ğ°Ğ¿ÑƒÑĞºĞ¾Ğ² (Ñ dry-run Ñ€ĞµĞ¶Ğ¸Ğ¼Ğ¾Ğ¼) |
| `get_experiment_summary` | ĞŸĞ¾Ğ»ÑƒÑ‡ĞµĞ½Ğ¸Ğµ ÑĞ²Ğ¾Ğ´ĞºĞ¸ Ğ¿Ğ¾ ÑĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚Ñƒ |
| `get_run_by_name` | ĞŸĞ¾Ğ¸ÑĞº Ğ·Ğ°Ğ¿ÑƒÑĞºĞ° Ğ¿Ğ¾ Ğ¸Ğ¼ĞµĞ½Ğ¸ |
| `list_registered_models` | Ğ¡Ğ¿Ğ¸ÑĞ¾Ğº Ğ·Ğ°Ñ€ĞµĞ³Ğ¸ÑÑ‚Ñ€Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ |
| `transition_model_stage` | Ğ˜Ğ·Ğ¼ĞµĞ½ĞµĞ½Ğ¸Ğµ ÑÑ‚Ğ°Ğ´Ğ¸Ğ¸ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ Ğ² Registry |

```python
"""Ğ£Ñ‚Ğ¸Ğ»Ğ¸Ñ‚Ñ‹ Ğ´Ğ»Ñ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ñ‹ Ñ MLflow ÑĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚Ğ°Ğ¼Ğ¸."""

from typing import Any
import pandas as pd
import mlflow
from mlflow.tracking import MlflowClient
from loguru import logger


def get_best_run(
    experiment_name: str,
    metric: str = "r2_score",
    ascending: bool = False,
) -> dict[str, Any]:
    """
    ĞŸĞ¾Ğ»ÑƒÑ‡ĞµĞ½Ğ¸Ğµ Ğ»ÑƒÑ‡ÑˆĞµĞ³Ğ¾ Ğ·Ğ°Ğ¿ÑƒÑĞºĞ° Ğ¿Ğ¾ Ğ¼ĞµÑ‚Ñ€Ğ¸ĞºĞµ.

    Args:
        experiment_name: ĞĞ°Ğ·Ğ²Ğ°Ğ½Ğ¸Ğµ ÑĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚Ğ°
        metric: ĞœĞµÑ‚Ñ€Ğ¸ĞºĞ° Ğ´Ğ»Ñ ÑĞ¾Ñ€Ñ‚Ğ¸Ñ€Ğ¾Ğ²ĞºĞ¸
        ascending: True Ğ´Ğ»Ñ Ğ¼Ğ¸Ğ½Ğ¸Ğ¼Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸ (RMSE), False Ğ´Ğ»Ñ Ğ¼Ğ°ĞºÑĞ¸Ğ¼Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸ (RÂ²)

    Returns:
        Ğ¡Ğ»Ğ¾Ğ²Ğ°Ñ€ÑŒ Ñ Ğ¸Ğ½Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ†Ğ¸ĞµĞ¹ Ğ¾ Ğ»ÑƒÑ‡ÑˆĞµĞ¼ Ğ·Ğ°Ğ¿ÑƒÑĞºĞµ
    """
    client = MlflowClient()
    experiment = client.get_experiment_by_name(experiment_name)

    if experiment is None:
        logger.warning(f"Ğ­ĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚ '{experiment_name}' Ğ½Ğµ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½")
        return {}

    order = "ASC" if ascending else "DESC"
    runs = client.search_runs(
        experiment_ids=[experiment.experiment_id],
        order_by=[f"metrics.{metric} {order}"],
        max_results=1,
    )

    if not runs:
        return {}

    best_run = runs[0]
    return {
        "run_id": best_run.info.run_id,
        "metrics": best_run.data.metrics,
        "params": best_run.data.params,
        "tags": best_run.data.tags,
        "artifact_uri": best_run.info.artifact_uri,
        "start_time": best_run.info.start_time,
        "status": best_run.info.status,
    }


def load_best_model(experiment_name: str, metric: str = "r2_score"):
    """Ğ—Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞ° Ğ»ÑƒÑ‡ÑˆĞµĞ¹ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ Ğ¿Ğ¾ Ğ¼ĞµÑ‚Ñ€Ğ¸ĞºĞµ."""
    best_run = get_best_run(experiment_name, metric)
    if not best_run:
        raise ValueError(f"ĞĞµÑ‚ Ğ·Ğ°Ğ¿ÑƒÑĞºĞ¾Ğ² Ğ² ÑĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚Ğµ '{experiment_name}'")

    model_uri = f"runs:/{best_run['run_id']}/model"
    logger.info(f"Ğ—Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞ° Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ Ğ¸Ğ· {model_uri}")
    return mlflow.sklearn.load_model(model_uri)


def compare_runs(
    experiment_name: str,
    metrics: list[str] = None,
    top_n: int = 10,
) -> pd.DataFrame:
    """Ğ¡Ñ€Ğ°Ğ²Ğ½ĞµĞ½Ğ¸Ğµ Ğ·Ğ°Ğ¿ÑƒÑĞºĞ¾Ğ² ÑĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚Ğ°."""
    if metrics is None:
        metrics = ["r2_score", "rmse", "mae"]

    client = MlflowClient()
    experiment = client.get_experiment_by_name(experiment_name)

    runs = client.search_runs(
        experiment_ids=[experiment.experiment_id],
        order_by=["metrics.r2_score DESC"],
        max_results=top_n,
    )

    data = []
    for run in runs:
        row = {
            "run_id": run.info.run_id[:8],
            "run_name": run.data.tags.get("mlflow.runName", ""),
            "status": run.info.status,
        }
        row.update({f"metric_{k}": v for k, v in run.data.metrics.items() if k in metrics})
        row.update({f"param_{k}": v for k, v in run.data.params.items()})
        data.append(row)

    return pd.DataFrame(data)


def get_experiment_summary(experiment_name: str) -> dict[str, Any]:
    """ĞŸĞ¾Ğ»ÑƒÑ‡ĞµĞ½Ğ¸Ğµ ÑĞ²Ğ¾Ğ´ĞºĞ¸ Ğ¿Ğ¾ ÑĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚Ñƒ."""
    client = MlflowClient()
    experiment = client.get_experiment_by_name(experiment_name)

    if experiment is None:
        return {}

    all_runs = client.search_runs(experiment_ids=[experiment.experiment_id])
    finished_runs = [r for r in all_runs if r.info.status == "FINISHED"]

    r2_values = [r.data.metrics.get("r2_score") for r in finished_runs
                 if r.data.metrics.get("r2_score") is not None]

    return {
        "experiment_name": experiment_name,
        "total_runs": len(all_runs),
        "finished_runs": len(finished_runs),
        "best_r2": max(r2_values) if r2_values else None,
        "avg_r2": sum(r2_values) / len(r2_values) if r2_values else None,
    }


def delete_experiment_runs(
    experiment_name: str,
    keep_top_n: int = 10,
    metric: str = "r2_score",
    dry_run: bool = True,
) -> list[str]:
    """Ğ£Ğ´Ğ°Ğ»ĞµĞ½Ğ¸Ğµ ÑÑ‚Ğ°Ñ€Ñ‹Ñ… Ğ·Ğ°Ğ¿ÑƒÑĞºĞ¾Ğ², ĞºÑ€Ğ¾Ğ¼Ğµ Ñ‚Ğ¾Ğ¿-N Ğ¿Ğ¾ Ğ¼ĞµÑ‚Ñ€Ğ¸ĞºĞµ."""
    client = MlflowClient()
    experiment = client.get_experiment_by_name(experiment_name)

    all_runs = client.search_runs(
        experiment_ids=[experiment.experiment_id],
        order_by=[f"metrics.{metric} DESC"],
    )

    deleted_ids = []
    for run in all_runs[keep_top_n:]:
        if dry_run:
            logger.info(f"[DRY RUN] Ğ‘ÑƒĞ´ĞµÑ‚ ÑƒĞ´Ğ°Ğ»Ñ‘Ğ½ run: {run.info.run_id}")
        else:
            client.delete_run(run.info.run_id)
            logger.info(f"Ğ£Ğ´Ğ°Ğ»Ñ‘Ğ½ run: {run.info.run_id}")
        deleted_ids.append(run.info.run_id)

    return deleted_ids
```

**ĞŸÑ€Ğ¸Ğ¼ĞµÑ€ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ ÑƒÑ‚Ğ¸Ğ»Ğ¸Ñ‚:**

```python
from src.tracking.utils import (
    get_best_run,
    load_best_model,
    compare_runs,
    register_best_model,
)

# ĞŸĞ¾Ğ»ÑƒÑ‡ĞµĞ½Ğ¸Ğµ Ğ»ÑƒÑ‡ÑˆĞµĞ³Ğ¾ Ğ·Ğ°Ğ¿ÑƒÑĞºĞ°
best = get_best_run("boston-housing", metric="r2_score")
print(f"Ğ›ÑƒÑ‡ÑˆĞ¸Ğ¹ RÂ²: {best['metrics']['r2_score']:.4f}")

# Ğ—Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞ° Ğ»ÑƒÑ‡ÑˆĞµĞ¹ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸
model = load_best_model("boston-housing")
predictions = model.predict(X_new)

# Ğ¡Ñ€Ğ°Ğ²Ğ½ĞµĞ½Ğ¸Ğµ ÑĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚Ğ¾Ğ²
comparison = compare_runs("boston-housing", top_n=5)
print(comparison)

# Ğ ĞµĞ³Ğ¸ÑÑ‚Ñ€Ğ°Ñ†Ğ¸Ñ Ğ»ÑƒÑ‡ÑˆĞµĞ¹ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸
version = register_best_model("boston-housing", "boston-housing-rf")
print(f"Ğ—Ğ°Ñ€ĞµĞ³Ğ¸ÑÑ‚Ñ€Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ° Ğ²ĞµÑ€ÑĞ¸Ñ: {version}")
```

---

## 4. Ğ˜Ğ½ÑÑ‚Ñ€ÑƒĞºÑ†Ğ¸Ğ¸ Ğ¿Ğ¾ Ğ·Ğ°Ğ¿ÑƒÑĞºÑƒ

### 4.1 Ğ‘Ñ‹ÑÑ‚Ñ€Ñ‹Ğ¹ ÑÑ‚Ğ°Ñ€Ñ‚

```bash
# 1. ĞšĞ»Ğ¾Ğ½Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ñ€ĞµĞ¿Ğ¾Ğ·Ğ¸Ñ‚Ğ¾Ñ€Ğ¸Ñ
git clone <repo-url>
cd ipml_boston_housing

# 2. Ğ£ÑÑ‚Ğ°Ğ½Ğ¾Ğ²ĞºĞ° Ğ·Ğ°Ğ²Ğ¸ÑĞ¸Ğ¼Ğ¾ÑÑ‚ĞµĞ¹
uv sync

# 3. Ğ¡Ğ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ğµ Ñ„Ğ°Ğ¹Ğ»Ğ° .env
cat > .env << 'EOF'
# MinIO
MINIO_ROOT_USER=minioadmin0
MINIO_ROOT_PASSWORD=minioadmin1230

# MLflow
MLFLOW_ADMIN_USERNAME=admin
MLFLOW_ADMIN_PASSWORD=secure_password_123
MLFLOW_TRACKING_URI=http://localhost:5000
MLFLOW_TRACKING_USERNAME=admin
MLFLOW_TRACKING_PASSWORD=secure_password_123
MLFLOW_S3_ENDPOINT_URL=http://localhost:9000
MLFLOW_FLASK_SERVER_SECRET_KEY=mlflow-secret-key-change-me

# S3/MinIO Ğ´Ğ»Ñ Ğ°Ñ€Ñ‚ĞµÑ„Ğ°ĞºÑ‚Ğ¾Ğ²
AWS_ACCESS_KEY_ID=minioadmin0
AWS_SECRET_ACCESS_KEY=minioadmin1230

# Airflow
AIRFLOW_ADMIN_USERNAME=admin
AIRFLOW_ADMIN_PASSWORD=admin
AIRFLOW_UID=50000
EOF

# 4. Ğ—Ğ°Ğ¿ÑƒÑĞº Ğ¸Ğ½Ñ„Ñ€Ğ°ÑÑ‚Ñ€ÑƒĞºÑ‚ÑƒÑ€Ñ‹
# Ğ—Ğ°Ğ¿ÑƒÑĞº Ğ¿Ğ¾Ğ»Ğ½Ğ¾Ğ³Ğ¾ ÑÑ‚ĞµĞºĞ° (Ğ²ĞºĞ»ÑÑ‡Ğ°Ñ Airflow)
docker-compose up -d

# Ğ˜Ğ›Ğ˜ Ğ·Ğ°Ğ¿ÑƒÑĞº Ñ‚Ğ¾Ğ»ÑŒĞºĞ¾ ML Ğ¸Ğ½Ñ„Ñ€Ğ°ÑÑ‚Ñ€ÑƒĞºÑ‚ÑƒÑ€Ñ‹ (Ğ±ĞµĞ· Airflow)
# docker-compose up -d minio mlflow nginx

# 5. Ğ¡Ğ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ğµ Ğ±Ğ°ĞºĞµÑ‚Ğ¾Ğ²
mc alias set local http://localhost:9000 minioadmin0 minioadmin1230
mc mb local/boston-housing-data
mc mb local/mlflow-artifacts

# 6. Ğ—Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞ° Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…
dvc pull

# 7. Ğ—Ğ°Ğ¿ÑƒÑĞº ÑĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚Ğ¾Ğ²
# Ğ›Ğ¾ĞºĞ°Ğ»ÑŒĞ½Ğ¾
python src/modeling/train.py -n 200 -d 15

# Ğ§ĞµÑ€ĞµĞ· Airflow (Ğ¿Ğ¾Ğ»Ğ½Ñ‹Ğ¹ Ğ½Ğ°Ğ±Ğ¾Ñ€ Ğ¸Ğ· 19 ÑĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚Ğ¾Ğ²)
# Ğ’ĞĞ–ĞĞ: Ğ”Ğ¾Ğ¶Ğ´Ğ¸Ñ‚ĞµÑÑŒ Ğ¸Ğ½Ğ¸Ñ†Ğ¸Ğ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸ Airflow (2-3 Ğ¼Ğ¸Ğ½ÑƒÑ‚Ñ‹)
# ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑŒÑ‚Ğµ Ğ³Ğ¾Ñ‚Ğ¾Ğ²Ğ½Ğ¾ÑÑ‚ÑŒ: docker-compose logs airflow-init
# ĞÑ‚ĞºÑ€Ğ¾Ğ¹Ñ‚Ğµ http://localhost:8080 (admin/admin)
# Ğ—Ğ°Ğ¿ÑƒÑÑ‚Ğ¸Ñ‚Ğµ DAG: boston_housing_experiments

# 8. ĞŸÑ€Ğ¾ÑĞ¼Ğ¾Ñ‚Ñ€ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ğ¾Ğ²
# MLflow UI: http://localhost:5000 (admin / secure_password_123)
# Airflow UI: http://localhost:8080 (admin / admin)
# MinIO Console: http://localhost:9001 (minioadmin0 / minioadmin1230)
```

### 4.2 ĞŸĞ¾Ğ»ĞµĞ·Ğ½Ñ‹Ğµ ĞºĞ¾Ğ¼Ğ°Ğ½Ğ´Ñ‹

```bash
# MLflow
mlflow experiments search                # Ğ¡Ğ¿Ğ¸ÑĞ¾Ğº ÑĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚Ğ¾Ğ²
mlflow runs list --experiment-id 1       # Ğ—Ğ°Ğ¿ÑƒÑĞºĞ¸ ÑĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚Ğ°
mlflow models list                       # Ğ—Ğ°Ñ€ĞµĞ³Ğ¸ÑÑ‚Ñ€Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ğµ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸

# Airflow
# Ğ’ĞµĞ±-Ğ¸Ğ½Ñ‚ĞµÑ€Ñ„ĞµĞ¹Ñ: http://localhost:8080 (admin/admin)
docker-compose logs -f airflow-webserver   # Ğ›Ğ¾Ğ³Ğ¸ Ğ²ĞµĞ±-ÑĞµÑ€Ğ²ĞµÑ€Ğ°
docker-compose logs -f airflow-scheduler   # Ğ›Ğ¾Ğ³Ğ¸ Ğ¿Ğ»Ğ°Ğ½Ğ¸Ñ€Ğ¾Ğ²Ñ‰Ğ¸ĞºĞ°
docker-compose logs -f airflow-worker      # Ğ›Ğ¾Ğ³Ğ¸ Ğ²Ğ¾Ñ€ĞºĞµÑ€Ğ°

# Docker (Ğ¿Ğ¾Ğ»Ğ½Ğ°Ñ Ğ¸Ğ½Ñ„Ñ€Ğ°ÑÑ‚Ñ€ÑƒĞºÑ‚ÑƒÑ€Ğ°)
docker-compose ps                        # Ğ¡Ñ‚Ğ°Ñ‚ÑƒÑ Ğ²ÑĞµÑ… ĞºĞ¾Ğ½Ñ‚ĞµĞ¹Ğ½ĞµÑ€Ğ¾Ğ²
docker-compose logs -f mlflow            # Ğ›Ğ¾Ğ³Ğ¸ MLflow
docker-compose restart airflow-webserver # ĞŸĞµÑ€ĞµĞ·Ğ°Ğ¿ÑƒÑĞº Airflow UI
docker-compose down && docker-compose up -d  # ĞŸĞ¾Ğ»Ğ½Ñ‹Ğ¹ Ğ¿ĞµÑ€ĞµĞ·Ğ°Ğ¿ÑƒÑĞº

# DVC
dvc status                               # Ğ¡Ñ‚Ğ°Ñ‚ÑƒÑ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…
dvc pull                                 # Ğ—Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞ° Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…
dvc push                                 # ĞÑ‚Ğ¿Ñ€Ğ°Ğ²ĞºĞ° Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…
```

---

## 5. ĞĞ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ° Ğ¸Ğ½ÑÑ‚Ñ€ÑƒĞ¼ĞµĞ½Ñ‚Ğ° Ğ¾Ñ€ĞºĞµÑÑ‚Ñ€Ğ°Ñ†Ğ¸Ğ¸

**Ğ’Ñ‹Ğ¿Ğ¾Ğ»Ğ½ĞµĞ½Ğ½Ñ‹Ğµ Ğ·Ğ°Ğ´Ğ°Ğ½Ğ¸Ñ:**
- âœ… Ğ£ÑÑ‚Ğ°Ğ½Ğ¾Ğ²Ğ»ĞµĞ½ Ğ¸ Ğ½Ğ°ÑÑ‚Ñ€Ğ¾ĞµĞ½ Apache Airflow 2.8.1 Ñ CeleryExecutor
- âœ… Ğ¡Ğ¾Ğ·Ğ´Ğ°Ğ½ workflow Ğ´Ğ»Ñ ML Ğ¿Ğ°Ğ¹Ğ¿Ğ»Ğ°Ğ¹Ğ½Ğ° (3 DAG Ñ Ñ€Ğ°Ğ·Ğ»Ğ¸Ñ‡Ğ½Ñ‹Ğ¼Ğ¸ Ğ¿Ğ°Ñ‚Ñ‚ĞµÑ€Ğ½Ğ°Ğ¼Ğ¸)
- âœ… ĞĞ°ÑÑ‚Ñ€Ğ¾ĞµĞ½Ñ‹ Ğ·Ğ°Ğ²Ğ¸ÑĞ¸Ğ¼Ğ¾ÑÑ‚Ğ¸ Ğ¼ĞµĞ¶Ğ´Ñƒ ÑÑ‚Ğ°Ğ¿Ğ°Ğ¼Ğ¸ (Ğ»Ğ¸Ğ½ĞµĞ¹Ğ½Ñ‹Ğµ, Ğ¿Ğ°Ñ€Ğ°Ğ»Ğ»ĞµĞ»ÑŒĞ½Ñ‹Ğµ, ÑƒÑĞ»Ğ¾Ğ²Ğ½Ñ‹Ğµ)
- âœ… Ğ ĞµĞ°Ğ»Ğ¸Ğ·Ğ¾Ğ²Ğ°Ğ½Ğ¾ ĞºÑÑˆĞ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ² MinIO Ğ¸ Ğ¿Ğ°Ñ€Ğ°Ğ»Ğ»ĞµĞ»ÑŒĞ½Ğ¾Ğµ Ğ²Ñ‹Ğ¿Ğ¾Ğ»Ğ½ĞµĞ½Ğ¸Ğµ Ğ´Ğ¾ 8 Ğ·Ğ°Ğ´Ğ°Ñ‡

### 5.1 Ğ£ÑÑ‚Ğ°Ğ½Ğ¾Ğ²ĞºĞ° Ğ¸ Ğ½Ğ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ° Ğ²Ñ‹Ğ±Ñ€Ğ°Ğ½Ğ½Ğ¾Ğ³Ğ¾ Ğ¸Ğ½ÑÑ‚Ñ€ÑƒĞ¼ĞµĞ½Ñ‚Ğ° (Apache Airflow)

**Ğ’Ñ‹Ğ±Ñ€Ğ°Ğ½Ğ½Ñ‹Ğ¹ Ğ¸Ğ½ÑÑ‚Ñ€ÑƒĞ¼ĞµĞ½Ñ‚ Ğ¾Ñ€ĞºĞµÑÑ‚Ñ€Ğ°Ñ†Ğ¸Ğ¸:** Apache Airflow 2.8.1

**ĞÑ€Ñ…Ğ¸Ñ‚ĞµĞºÑ‚ÑƒÑ€Ğ° Ñ€Ğ°Ğ·Ğ²ĞµÑ€Ñ‚Ñ‹Ğ²Ğ°Ğ½Ğ¸Ñ:**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        Airflow Stack                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Webserver   â”‚  Scheduler   â”‚   Worker     â”‚   airflow-init    â”‚
â”‚  (Ğ¿Ğ¾Ñ€Ñ‚ 8080) â”‚              â”‚  (Celery)    â”‚                   â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚              â”‚              â”‚
       â–¼              â–¼              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     Ğ˜Ğ½Ñ„Ñ€Ğ°ÑÑ‚Ñ€ÑƒĞºÑ‚ÑƒÑ€Ğ°                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ PostgreSQL  â”‚   Redis     â”‚   MLflow    â”‚   MinIO     â”‚ Nginx  â”‚
â”‚ (Metadata)  â”‚ (Broker)    â”‚ (Tracking)  â”‚ (Storage)   â”‚ (Auth) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Ğ ĞµĞ°Ğ»Ğ¸Ğ·Ğ¾Ğ²Ğ°Ğ½Ğ½Ğ°Ñ Ğ°Ñ€Ñ…Ğ¸Ñ‚ĞµĞºÑ‚ÑƒÑ€Ğ° Ñ‡ĞµÑ€ĞµĞ· Docker Compose:**

ĞŸĞ¾Ğ»Ğ½Ñ‹Ğ¹ ÑÑ‚ĞµĞº Ñ€Ğ°Ğ·Ğ²Ñ‘Ñ€Ğ½ÑƒÑ‚ Ğ² `docker-compose.yml` Ñ 10 ÑĞµÑ€Ğ²Ğ¸ÑĞ°Ğ¼Ğ¸:

| Ğ¡ĞµÑ€Ğ²Ğ¸Ñ | ĞŸĞ¾Ñ€Ñ‚ | ĞĞ°Ğ·Ğ½Ğ°Ñ‡ĞµĞ½Ğ¸Ğµ |
|--------|------|------------|
| **airflow-webserver** | 8080 | Ğ’ĞµĞ±-Ğ¸Ğ½Ñ‚ĞµÑ€Ñ„ĞµĞ¹Ñ Airflow |
| **airflow-scheduler** | â€” | ĞŸĞ»Ğ°Ğ½Ğ¸Ñ€Ğ¾Ğ²Ñ‰Ğ¸Ğº Ğ·Ğ°Ğ´Ğ°Ñ‡ |
| **airflow-worker** | â€” | Ğ˜ÑĞ¿Ğ¾Ğ»Ğ½Ğ¸Ñ‚ĞµĞ»ÑŒ Ğ·Ğ°Ğ´Ğ°Ñ‡ (Celery) |
| **airflow-init** | â€” | Ğ˜Ğ½Ğ¸Ñ†Ğ¸Ğ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ Ğ‘Ğ” Ğ¸ ÑĞ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ğµ Ğ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»Ñ |
| **postgres** | â€” | Ğ‘Ğ°Ğ·Ğ° Ğ¼ĞµÑ‚Ğ°Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Airflow |
| **redis** | â€” | Ğ‘Ñ€Ğ¾ĞºĞµÑ€ ÑĞ¾Ğ¾Ğ±Ñ‰ĞµĞ½Ğ¸Ğ¹ Celery |
| **mlflow** | 5000 (Ñ‡ĞµÑ€ĞµĞ· nginx) | Tracking server Ñ Ğ°ÑƒÑ‚ĞµĞ½Ñ‚Ğ¸Ñ„Ğ¸ĞºĞ°Ñ†Ğ¸ĞµĞ¹ |
| **minio** | 9000, 9001 | S3-ÑĞ¾Ğ²Ğ¼ĞµÑÑ‚Ğ¸Ğ¼Ğ¾Ğµ Ñ…Ñ€Ğ°Ğ½Ğ¸Ğ»Ğ¸Ñ‰Ğµ |
| **nginx** | 5000 | Reverse proxy Ñ Basic Auth Ğ´Ğ»Ñ MLflow |
| **train** | â€” | ĞšĞ¾Ğ½Ñ‚ĞµĞ¹Ğ½ĞµÑ€ Ğ´Ğ»Ñ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ (Ğ¿Ñ€Ğ¾Ñ„Ğ¸Ğ»ÑŒ train) |

```dockerfile
# docker/Dockerfile.airflow (Ñ„Ñ€Ğ°Ğ³Ğ¼ĞµĞ½Ñ‚)
FROM apache/airflow:2.8.1-python3.11

# Ğ£ÑÑ‚Ğ°Ğ½Ğ¾Ğ²ĞºĞ° Python Ğ·Ğ°Ğ²Ğ¸ÑĞ¸Ğ¼Ğ¾ÑÑ‚ĞµĞ¹ Ğ¿Ñ€Ğ¾ĞµĞºÑ‚Ğ°
RUN pip install --no-cache-dir \
    numpy>=2.0.0 \
    pandas>=2.0.0 \
    scikit-learn>=1.5.0 \
    mlflow>=2.10.0 \
    boto3>=1.34.0 \
    loguru>=0.7.0 \
    python-dotenv>=1.0.0 \
    matplotlib>=3.8.0 \
    apache-airflow-providers-celery>=3.5.0 \
    apache-airflow-providers-redis>=3.5.0 \
    apache-airflow-providers-postgres>=5.8.0 \
    apache-airflow-providers-amazon>=8.0.0

# ĞĞ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ° Python paths Ğ´Ğ»Ñ Ğ´Ğ¾ÑÑ‚ÑƒĞ¿Ğ° Ğº src/
ENV PYTHONPATH="/opt/airflow:/opt/airflow/src:${PYTHONPATH}"
```

**Docker Compose ĞºĞ¾Ğ½Ñ„Ğ¸Ğ³ÑƒÑ€Ğ°Ñ†Ğ¸Ñ:**

```yaml
x-airflow-common: &airflow-common
  build:
    context: .
    dockerfile: docker/Dockerfile.airflow
  environment: &airflow-common-env
    AIRFLOW__CORE__EXECUTOR: CeleryExecutor
    AIRFLOW__CORE__SQL_ALCHEMY_CONN: postgresql+psycopg2://airflow:airflow@postgres/airflow  # pragma: allowlist secret
    AIRFLOW__CELERY__RESULT_BACKEND: db+postgresql://airflow:airflow@postgres/airflow  # pragma: allowlist secret
    AIRFLOW__CELERY__BROKER_URL: redis://:@redis:6379/0
    # ĞŸĞ°Ñ€Ğ°Ğ»Ğ»ĞµĞ»Ğ¸Ğ·Ğ¼
    AIRFLOW__CORE__PARALLELISM: 16
    AIRFLOW__CORE__DAG_CONCURRENCY: 8
    AIRFLOW__CELERY__WORKER_CONCURRENCY: 4
    # Ğ˜Ğ½Ñ‚ĞµĞ³Ñ€Ğ°Ñ†Ğ¸Ñ Ñ ML Ğ¸Ğ½Ñ„Ñ€Ğ°ÑÑ‚Ñ€ÑƒĞºÑ‚ÑƒÑ€Ğ¾Ğ¹
    MLFLOW_TRACKING_URI: http://mlflow:5000
    MLFLOW_S3_ENDPOINT_URL: http://minio:9000
  volumes:
    - ./airflow/dags:/opt/airflow/dags
    - ./airflow/logs:/opt/airflow/logs
    - ./airflow/plugins:/opt/airflow/plugins
    - ./data:/opt/airflow/data
    - ./src:/opt/airflow/src
```

**Ğ’ĞµĞ±-Ğ¸Ğ½Ñ‚ĞµÑ€Ñ„ĞµĞ¹Ñ Apache Airflow:**

![Ğ”Ğ¾ÑÑ‚ÑƒĞ¿Ğ½Ñ‹Ğµ DAGs](figures/2.png)

*Ğ Ğ¸Ñ. 3: Ğ”Ğ¾ÑÑ‚ÑƒĞ¿Ğ½Ñ‹Ğµ DAGs ÑĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚Ğ¾Ğ² Ğ² Airflow UI*

![DAG Ñ ÑĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚Ğ¾Ğ¼](figures/1.png)

*Ğ Ğ¸Ñ. 4: DAG Airflow Ñ ÑĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚Ğ¾Ğ¼ boston_housing_experiments*

![Docker-compose ĞºĞ¾Ğ½ÑĞ¾Ğ»ÑŒ](figures/3.png)

*Ğ Ğ¸Ñ. 5: Docker-compose ĞºĞ¾Ğ½ÑĞ¾Ğ»ÑŒ Ñ Ğ·Ğ°Ğ¿ÑƒÑ‰ĞµĞ½Ğ½Ñ‹Ğ¼Ğ¸ ÑĞµÑ€Ğ²Ğ¸ÑĞ°Ğ¼Ğ¸*

![Gantt Ğ´Ğ¸Ğ°Ğ³Ñ€Ğ°Ğ¼Ğ¼Ğ°](figures/4.png)

*Ğ Ğ¸Ñ. 6: Gantt Ğ´Ğ¸Ğ°Ğ³Ñ€Ğ°Ğ¼Ğ¼Ğ° Ñ Ğ·Ğ°Ğ¿ÑƒÑ‰ĞµĞ½Ğ½Ñ‹Ğ¼Ğ¸ Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ°Ğ¼Ğ¸ Ğ² Airflow*

### 5.2 Ğ¡Ğ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ğµ workflow Ğ´Ğ»Ñ ML Ğ¿Ğ°Ğ¹Ğ¿Ğ»Ğ°Ğ¹Ğ½Ğ°

**Ğ¡Ñ‚Ñ€ÑƒĞºÑ‚ÑƒÑ€Ğ° `airflow/dags/`:**

```
airflow/dags/
â”œâ”€â”€ boston_housing_simple.py       # ĞŸÑ€Ğ¾ÑÑ‚Ğ¾Ğ¹ Ğ¿Ğ¾ÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ÑŒĞ½Ñ‹Ğ¹ Ğ¿Ğ°Ğ¹Ğ¿Ğ»Ğ°Ğ¹Ğ½
â”œâ”€â”€ boston_housing_experiments.py  # ĞŸĞ°Ñ€Ğ°Ğ»Ğ»ĞµĞ»ÑŒĞ½Ğ¾Ğµ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ğµ 19 Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹
â””â”€â”€ boston_housing_cached.py       # ĞŸĞ°Ğ¹Ğ¿Ğ»Ğ°Ğ¹Ğ½ Ñ ĞºÑÑˆĞ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸ĞµĞ¼ Ğ² MinIO
```

Ğ ĞµĞ°Ğ»Ğ¸Ğ·Ğ¾Ğ²Ğ°Ğ½Ğ¾ **3 DAG** Ñ Ñ€Ğ°Ğ·Ğ»Ğ¸Ñ‡Ğ½Ñ‹Ğ¼Ğ¸ Ğ¿Ğ°Ñ‚Ñ‚ĞµÑ€Ğ½Ğ°Ğ¼Ğ¸ Ğ¾Ñ€ĞºĞµÑÑ‚Ñ€Ğ°Ñ†Ğ¸Ğ¸:

#### DAG 1: boston_housing_simple

**ĞĞ°Ğ·Ğ½Ğ°Ñ‡ĞµĞ½Ğ¸Ğµ:** ĞŸÑ€Ğ¾ÑÑ‚Ğ¾Ğ¹ Ğ¿Ğ¾ÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ÑŒĞ½Ñ‹Ğ¹ Ğ¿Ğ°Ğ¹Ğ¿Ğ»Ğ°Ğ¹Ğ½ Ğ´Ğ»Ñ Ğ±Ñ‹ÑÑ‚Ñ€Ğ¾Ğ³Ğ¾ Ğ¿Ñ€Ğ¾Ñ‚Ğ¾Ñ‚Ğ¸Ğ¿Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ Ñ Ğ¾Ğ´Ğ½Ğ¾Ğ¹ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒÑ Random Forest.

**ĞÑ€Ñ…Ğ¸Ñ‚ĞµĞºÑ‚ÑƒÑ€Ğ°:**
```
download_data â†’ validate_data â†’ train_model â†’ evaluate_model â†’ save_artifacts
```

**ĞÑĞ¾Ğ±ĞµĞ½Ğ½Ğ¾ÑÑ‚Ğ¸:**
- ĞĞ±ÑƒÑ‡ĞµĞ½Ğ¸Ğµ Ğ¾Ğ´Ğ½Ğ¾Ğ¹ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ Random Forest
- Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ğ¸Ğµ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ğ¾Ğ² Ğ² Ğ»Ğ¾ĞºĞ°Ğ»ÑŒĞ½Ñ‹Ğµ Ñ„Ğ°Ğ¹Ğ»Ñ‹
- ĞŸÑ€Ğ¾ÑÑ‚Ğ°Ñ Ğ¿Ğ¾ÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ÑŒĞ½Ğ°Ñ Ğ°Ñ€Ñ…Ğ¸Ñ‚ĞµĞºÑ‚ÑƒÑ€Ğ° Ğ±ĞµĞ· Ğ¿Ğ°Ñ€Ğ°Ğ»Ğ»ĞµĞ»Ğ¸Ğ·Ğ¼Ğ°

**ĞšĞ¾Ğ½Ñ„Ğ¸Ğ³ÑƒÑ€Ğ°Ñ†Ğ¸Ñ:**
```python
@dag(
    dag_id="boston_housing_simple",
    schedule=None,  # Ğ ÑƒÑ‡Ğ½Ğ¾Ğ¹ Ğ·Ğ°Ğ¿ÑƒÑĞº
    start_date=datetime(2024, 1, 1),
    catchup=False,
    tags=["ml", "boston_housing", "random_forest"],
)
```

#### DAG 2: boston_housing_experiments

**ĞĞ°Ğ·Ğ½Ğ°Ñ‡ĞµĞ½Ğ¸Ğµ:** ĞŸĞ°Ñ€Ğ°Ğ»Ğ»ĞµĞ»ÑŒĞ½Ğ¾Ğµ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ğµ 19 ML Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ Ñ Ğ°Ğ³Ñ€ĞµĞ³Ğ°Ñ†Ğ¸ĞµĞ¹ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ğ¾Ğ² Ğ¸ Ğ°Ğ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ğ¼ Ğ»Ğ¾Ğ³Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸ĞµĞ¼ Ğ² MLflow.

**ĞÑ€Ñ…Ğ¸Ñ‚ĞµĞºÑ‚ÑƒÑ€Ğ°:**
```
                    download_data
                         â”‚
                    validate_data
                         â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚               â”‚               â”‚
    Linear Models   Tree Models    Other Models
      (7 ÑˆÑ‚.)        (9 ÑˆÑ‚.)        (3 ÑˆÑ‚.)
         â”‚               â”‚               â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                  aggregate_results
                         â”‚
                   generate_report
                         â”‚
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚          â”‚          â”‚
         Save to     Log to     Upload to
         Local      MLflow      MinIO
```

**ĞÑĞ¾Ğ±ĞµĞ½Ğ½Ğ¾ÑÑ‚Ğ¸:**
- ĞœĞ°ĞºÑĞ¸Ğ¼ÑƒĞ¼ 8 Ğ¿Ğ°Ñ€Ğ°Ğ»Ğ»ĞµĞ»ÑŒĞ½Ñ‹Ñ… Ğ·Ğ°Ğ´Ğ°Ñ‡ (`max_active_tasks=8`)
- ĞĞ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¾Ğµ Ğ»Ğ¾Ğ³Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ² MLflow Ñ Ñ‚ĞµĞ³Ğ°Ğ¼Ğ¸
- Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ğ¸Ğµ Ğ°Ñ€Ñ‚ĞµÑ„Ğ°ĞºÑ‚Ğ¾Ğ² Ğ² MinIO (Ğ¾Ñ‚Ñ‡Ñ‘Ñ‚Ñ‹, Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ñ‹, Ğ»ÑƒÑ‡ÑˆĞ°Ñ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ)
- Ğ“ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ñ Ğ¿Ğ¾Ğ´Ñ€Ğ¾Ğ±Ğ½Ğ¾Ğ³Ğ¾ Markdown Ğ¾Ñ‚Ñ‡Ñ‘Ñ‚Ğ°

**ĞŸĞ°Ñ€Ğ°Ğ»Ğ»ĞµĞ»ÑŒĞ½Ğ¾Ğµ Ğ²Ñ‹Ğ¿Ğ¾Ğ»Ğ½ĞµĞ½Ğ¸Ğµ Ñ‡ĞµÑ€ĞµĞ· expand():**
```python
# Ğ›Ğ¸Ğ½ĞµĞ¹Ğ½Ñ‹Ğµ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ (7 ÑĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚Ğ¾Ğ²)
linear_results = train_single_model.expand(
    model_config=LINEAR_MODELS,
    data_info=[data_info] * len(LINEAR_MODELS),
)

# Ğ”Ñ€ĞµĞ²Ğ¾Ğ²Ğ¸Ğ´Ğ½Ñ‹Ğµ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ (9 ÑĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚Ğ¾Ğ²)
tree_results = train_single_model.expand(
    model_config=TREE_MODELS,
    data_info=[data_info] * len(TREE_MODELS),
)

# Ğ”Ñ€ÑƒĞ³Ğ¸Ğµ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ (3 ÑĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚Ğ°)
other_results = train_single_model.expand(
    model_config=OTHER_MODELS,
    data_info=[data_info] * len(OTHER_MODELS),
)
```

#### DAG 3: boston_housing_cached

**ĞĞ°Ğ·Ğ½Ğ°Ñ‡ĞµĞ½Ğ¸Ğµ:** ML Ğ¿Ğ°Ğ¹Ğ¿Ğ»Ğ°Ğ¹Ğ½ Ñ Ğ¸Ğ½Ñ‚ĞµĞ»Ğ»ĞµĞºÑ‚ÑƒĞ°Ğ»ÑŒĞ½Ñ‹Ğ¼ ĞºÑÑˆĞ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸ĞµĞ¼ Ğ² MinIO.

**ĞÑĞ¾Ğ±ĞµĞ½Ğ½Ğ¾ÑÑ‚Ğ¸:**
- `ShortCircuitOperator` Ğ´Ğ»Ñ Ğ¿Ñ€Ğ¾Ğ¿ÑƒÑĞºĞ° Ğ·Ğ°Ğ´Ğ°Ñ‡ ĞµÑĞ»Ğ¸ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ Ğ² ĞºÑÑˆĞµ
- ĞŸÑ€Ğ¾Ğ²ĞµÑ€ĞºĞ° Ñ…ÑÑˆĞ° Ğ²Ñ…Ğ¾Ğ´Ğ½Ñ‹Ñ… Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ´Ğ»Ñ Ğ¸Ğ½Ğ²Ğ°Ğ»Ğ¸Ğ´Ğ°Ñ†Ğ¸Ğ¸ ĞºÑÑˆĞ°
- ĞĞ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¾Ğµ ÑĞ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ğ¸Ğµ Ğ² ĞºÑÑˆ Ğ¿Ğ¾ÑĞ»Ğµ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ

**Ğ›Ğ¾Ğ³Ğ¸ĞºĞ° ĞºÑÑˆĞ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ:**
```python
def check_cache_exists(data_path: str, **kwargs) -> bool:
    """
    True: Ğ¿Ñ€Ğ¾Ğ´Ğ¾Ğ»Ğ¶Ğ¸Ñ‚ÑŒ Ğ²Ñ‹Ğ¿Ğ¾Ğ»Ğ½ĞµĞ½Ğ¸Ğµ (Ğ½ĞµÑ‚ ĞºÑÑˆĞ°, Ğ½ÑƒĞ¶Ğ½Ğ¾ Ğ¾Ğ±ÑƒÑ‡Ğ°Ñ‚ÑŒ)
    False: Ğ¿Ñ€Ğ¾Ğ¿ÑƒÑÑ‚Ğ¸Ñ‚ÑŒ downstream Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ¸ (ĞºÑÑˆ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½)
    """
    cache = MinIOCache(bucket_name="airflow-cache")
    prefix = "models/random_forest_cached"
    exists, cache_key = cache.check_cache(prefix, MODEL_PARAMS, data_path)
    return not exists  # Ğ˜Ğ½Ğ²ĞµÑ€Ñ‚Ğ¸Ñ€ÑƒĞµĞ¼ Ğ´Ğ»Ñ ShortCircuitOperator
```

### 5.3 ĞĞ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ° Ğ·Ğ°Ğ²Ğ¸ÑĞ¸Ğ¼Ğ¾ÑÑ‚ĞµĞ¹ Ğ¼ĞµĞ¶Ğ´Ñƒ ÑÑ‚Ğ°Ğ¿Ğ°Ğ¼Ğ¸

**Ğ¢Ğ¸Ğ¿Ñ‹ Ğ·Ğ°Ğ²Ğ¸ÑĞ¸Ğ¼Ğ¾ÑÑ‚ĞµĞ¹:**

| Ğ¢Ğ¸Ğ¿ | ĞĞ¿Ğ¸ÑĞ°Ğ½Ğ¸Ğµ | ĞŸÑ€Ğ¸Ğ¼ĞµÑ€ |
|------|----------|---------|
| **Ğ›Ğ¸Ğ½ĞµĞ¹Ğ½Ñ‹Ğµ** | ĞŸĞ¾ÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ÑŒĞ½Ğ¾Ğµ Ğ²Ñ‹Ğ¿Ğ¾Ğ»Ğ½ĞµĞ½Ğ¸Ğµ | `data >> validate >> train >> evaluate` |
| **ĞŸĞ°Ñ€Ğ°Ğ»Ğ»ĞµĞ»ÑŒĞ½Ñ‹Ğµ** | ĞĞµĞ·Ğ°Ğ²Ğ¸ÑĞ¸Ğ¼Ğ¾Ğµ Ğ²Ñ‹Ğ¿Ğ¾Ğ»Ğ½ĞµĞ½Ğ¸Ğµ Ğ³Ñ€ÑƒĞ¿Ğ¿ Ğ·Ğ°Ğ´Ğ°Ñ‡ | `expand()` Ğ´Ğ»Ñ Ğ¼Ğ½Ğ¾Ğ¶ĞµÑÑ‚Ğ²ĞµĞ½Ğ½Ğ¾Ğ³Ğ¾ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ |
| **Ğ£ÑĞ»Ğ¾Ğ²Ğ½Ñ‹Ğµ** | Ğ’Ñ‹Ğ¿Ğ¾Ğ»Ğ½ĞµĞ½Ğ¸Ğµ Ğ·Ğ°Ğ²Ğ¸ÑĞ¸Ñ‚ Ğ¾Ñ‚ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ğ° Ğ¿Ñ€ĞµĞ´Ñ‹Ğ´ÑƒÑ‰Ğ¸Ñ… Ğ·Ğ°Ğ´Ğ°Ñ‡ | `ShortCircuitOperator` Ğ´Ğ»Ñ ĞºÑÑˆĞ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ |
| **Trigger Rules** | Ğ“Ğ¸Ğ±ĞºĞ°Ñ Ğ»Ğ¾Ğ³Ğ¸ĞºĞ° Ğ·Ğ°Ğ¿ÑƒÑĞºĞ° | `none_failed_min_one_success` |

**ĞŸÑ€Ğ¸Ğ¼ĞµÑ€Ñ‹ Ğ½Ğ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ¸ Ğ·Ğ°Ğ²Ğ¸ÑĞ¸Ğ¼Ğ¾ÑÑ‚ĞµĞ¹:**

```python
# Ğ›Ğ¸Ğ½ĞµĞ¹Ğ½Ñ‹Ğµ Ğ·Ğ°Ğ²Ğ¸ÑĞ¸Ğ¼Ğ¾ÑÑ‚Ğ¸
data_path >> cache_check >> train_result >> save_result >> summary

# Ğ£ÑĞ»Ğ¾Ğ²Ğ½Ñ‹Ğµ Ğ·Ğ°Ğ²Ğ¸ÑĞ¸Ğ¼Ğ¾ÑÑ‚Ğ¸ Ñ trigger rules
@task(trigger_rule="none_failed_min_one_success")
def generate_summary(cache_result=None, train_save_result=None):
    # Ğ’Ñ‹Ğ¿Ğ¾Ğ»Ğ½ÑĞµÑ‚ÑÑ ĞµÑĞ»Ğ¸ Ñ…Ğ¾Ñ‚Ñ Ğ±Ñ‹ Ğ¾Ğ´Ğ¸Ğ½ upstream task ÑƒÑĞ¿ĞµÑˆĞµĞ½
    pass

# ĞŸĞ°Ñ€Ğ°Ğ»Ğ»ĞµĞ»ÑŒĞ½Ñ‹Ğµ Ğ·Ğ°Ğ²Ğ¸ÑĞ¸Ğ¼Ğ¾ÑÑ‚Ğ¸
aggregated = aggregate_results(
    linear_results=linear_results,    # Ğ–Ğ´Ñ‘Ñ‚ Ğ·Ğ°Ğ²ĞµÑ€ÑˆĞµĞ½Ğ¸Ñ Ğ²ÑĞµÑ… Ğ»Ğ¸Ğ½ĞµĞ¹Ğ½Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹
    tree_results=tree_results,        # Ğ–Ğ´Ñ‘Ñ‚ Ğ·Ğ°Ğ²ĞµÑ€ÑˆĞµĞ½Ğ¸Ñ Ğ²ÑĞµÑ… Ğ´Ñ€ĞµĞ²Ğ¾Ğ²Ğ¸Ğ´Ğ½Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹
    other_results=other_results,      # Ğ–Ğ´Ñ‘Ñ‚ Ğ·Ğ°Ğ²ĞµÑ€ÑˆĞµĞ½Ğ¸Ñ Ğ²ÑĞµÑ… Ğ´Ñ€ÑƒĞ³Ğ¸Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹
)
```

### 5.4 Ğ ĞµĞ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ ĞºÑÑˆĞ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ Ğ¸ Ğ¿Ğ°Ñ€Ğ°Ğ»Ğ»ĞµĞ»ÑŒĞ½Ğ¾Ğ³Ğ¾ Ğ²Ñ‹Ğ¿Ğ¾Ğ»Ğ½ĞµĞ½Ğ¸Ñ

**Ğ¡Ñ‚Ñ€ÑƒĞºÑ‚ÑƒÑ€Ğ° Ğ¼Ğ¾Ğ´ÑƒĞ»Ñ `airflow/plugins/`:**

```
airflow/plugins/
â”œâ”€â”€ __init__.py
â””â”€â”€ minio_cache.py  # Ğ¡Ğ¸ÑÑ‚ĞµĞ¼Ğ° ĞºÑÑˆĞ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ Ğ°Ñ€Ñ‚ĞµÑ„Ğ°ĞºÑ‚Ğ¾Ğ² Ğ² MinIO
```

#### Ğ¡Ğ¸ÑÑ‚ĞµĞ¼Ğ° ĞºÑÑˆĞ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ Ğ½Ğ° Ğ±Ğ°Ğ·Ğµ MinIO

**ĞœĞ¾Ğ´ÑƒĞ»ÑŒ `airflow/plugins/minio_cache.py`:**

Ğ ĞµĞ°Ğ»Ğ¸Ğ·Ğ¾Ğ²Ğ°Ğ½ ĞºĞ»Ğ°ÑÑ `MinIOCache` Ğ¸ 3 Ğ²ÑĞ¿Ğ¾Ğ¼Ğ¾Ğ³Ğ°Ñ‚ĞµĞ»ÑŒĞ½Ñ‹Ğµ Ñ„ÑƒĞ½ĞºÑ†Ğ¸Ğ¸ Ğ´Ğ»Ñ ĞºÑÑˆĞ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ:

| ĞšĞ¾Ğ¼Ğ¿Ğ¾Ğ½ĞµĞ½Ñ‚ | ĞĞ°Ğ·Ğ½Ğ°Ñ‡ĞµĞ½Ğ¸Ğµ |
|-----------|------------|
| `MinIOCache` | ĞšĞ»Ğ°ÑÑ Ğ´Ğ»Ñ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ñ‹ Ñ ĞºÑÑˆĞµĞ¼ Ğ² MinIO (Ğ¿Ñ€Ğ¾Ğ²ĞµÑ€ĞºĞ°, Ğ·Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞ°, ÑĞºĞ°Ñ‡Ğ¸Ğ²Ğ°Ğ½Ğ¸Ğµ) |
| `check_model_cache` | Ğ¤ÑƒĞ½ĞºÑ†Ğ¸Ñ Ğ´Ğ»Ñ ShortCircuitOperator (Ğ¿Ñ€Ğ¾Ğ²ĞµÑ€ĞºĞ° Ğ½Ğ°Ğ»Ğ¸Ñ‡Ğ¸Ñ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ Ğ² ĞºÑÑˆĞµ) |
| `get_cached_model` | ĞŸĞ¾Ğ»ÑƒÑ‡ĞµĞ½Ğ¸Ğµ ĞºÑÑˆĞ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ğ¾Ğ¹ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ Ğ¸Ğ· MinIO |
| `save_model_to_cache` | Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ğ¸Ğµ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ½Ğ¾Ğ¹ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ Ğ² ĞºÑÑˆ Ñ Ğ¼ĞµÑ‚Ğ°Ğ´Ğ°Ğ½Ğ½Ñ‹Ğ¼Ğ¸ |

```python
class MinIOCache:
    """
    ĞšĞ»Ğ°ÑÑ Ğ´Ğ»Ñ ĞºÑÑˆĞ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ Ğ°Ñ€Ñ‚ĞµÑ„Ğ°ĞºÑ‚Ğ¾Ğ² Ğ² MinIO.

    ĞŸĞ¾Ğ·Ğ²Ğ¾Ğ»ÑĞµÑ‚:
    - ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑÑ‚ÑŒ ÑÑƒÑ‰ĞµÑÑ‚Ğ²Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ñ„Ğ°Ğ¹Ğ»Ğ¾Ğ² Ğ¿Ğ¾ Ñ…ÑÑˆ-ĞºĞ»ÑÑ‡Ğ°Ğ¼
    - Ğ’Ñ‹Ñ‡Ğ¸ÑĞ»ÑÑ‚ÑŒ Ñ…ÑÑˆĞ¸ Ğ´Ğ»Ñ Ğ¿Ñ€Ğ¾Ğ²ĞµÑ€ĞºĞ¸ Ğ¸Ğ·Ğ¼ĞµĞ½ĞµĞ½Ğ¸Ğ¹ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…
    - Ğ—Ğ°Ğ³Ñ€ÑƒĞ¶Ğ°Ñ‚ÑŒ/ÑĞºĞ°Ñ‡Ğ¸Ğ²Ğ°Ñ‚ÑŒ Ğ°Ñ€Ñ‚ĞµÑ„Ğ°ĞºÑ‚Ñ‹
    """

    def __init__(self, bucket_name: str = "airflow-cache"):
        self.endpoint_url = os.environ.get("MLFLOW_S3_ENDPOINT_URL", "http://minio:9000")
        self.access_key = os.environ.get("AWS_ACCESS_KEY_ID", "minioadmin")
        self.secret_key = os.environ.get("AWS_SECRET_ACCESS_KEY", "minioadmin")
        self.bucket_name = bucket_name
        self.client = boto3.client("s3", endpoint_url=self.endpoint_url, ...)
        self._ensure_bucket_exists()

    def compute_file_hash(self, file_path: str) -> str:
        """Ğ’Ñ‹Ñ‡Ğ¸ÑĞ»ÑĞµÑ‚ MD5 Ñ…ÑÑˆ Ñ„Ğ°Ğ¹Ğ»Ğ°."""
        ...

    def compute_params_hash(self, params: dict) -> str:
        """Ğ’Ñ‹Ñ‡Ğ¸ÑĞ»ÑĞµÑ‚ Ñ…ÑÑˆ Ğ¿Ğ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ğ¾Ğ²."""
        params_str = json.dumps(params, sort_keys=True)
        return hashlib.md5(params_str.encode()).hexdigest()

    def get_cache_key(self, prefix: str, params: dict, data_hash: str = None) -> str:
        """
        Ğ“ĞµĞ½ĞµÑ€Ğ¸Ñ€ÑƒĞµÑ‚ ĞºĞ»ÑÑ‡ ĞºÑÑˆĞ° Ğ½Ğ° Ğ¾ÑĞ½Ğ¾Ğ²Ğµ Ğ¿Ğ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ğ¾Ğ² Ğ¸ Ñ…ÑÑˆĞ° Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ….
        Ğ¤Ğ¾Ñ€Ğ¼Ğ°Ñ‚: prefix_params_hash_data_hash
        """
        params_hash = self.compute_params_hash(params)
        if data_hash:
            return f"{prefix}_{params_hash}_{data_hash}"
        return f"{prefix}_{params_hash}"

    def check_cache(self, prefix: str, params: dict, data_path: str = None) -> tuple[bool, str]:
        """ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµÑ‚ Ğ½Ğ°Ğ»Ğ¸Ñ‡Ğ¸Ğµ ĞºÑÑˆĞ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ğ¾Ğ³Ğ¾ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ğ°."""
        ...

    def upload(self, local_path: str, key: str) -> str:
        """Ğ—Ğ°Ğ³Ñ€ÑƒĞ¶Ğ°ĞµÑ‚ Ñ„Ğ°Ğ¹Ğ» Ğ² MinIO."""
        ...

    def download(self, key: str, local_path: str) -> str:
        """Ğ¡ĞºĞ°Ñ‡Ğ¸Ğ²Ğ°ĞµÑ‚ Ñ„Ğ°Ğ¹Ğ» Ğ¸Ğ· MinIO."""
        ...

    def put_json(self, key: str, data: dict) -> str:
        """Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½ÑĞµÑ‚ JSON Ğ² MinIO."""
        ...

    def get_json(self, key: str) -> dict:
        """Ğ§Ğ¸Ñ‚Ğ°ĞµÑ‚ JSON Ğ¸Ğ· MinIO."""
        ...
```

**Ğ˜Ğ½Ñ‚ĞµĞ³Ñ€Ğ°Ñ†Ğ¸Ñ Ñ Airflow:**

```python
# ĞŸÑ€Ğ¾Ğ²ĞµÑ€ĞºĞ° ĞºÑÑˆĞ°
cache_check = ShortCircuitOperator(
    task_id="check_cache",
    python_callable=check_cache_exists,
    op_kwargs={"data_path": data_path},
    provide_context=True,
)

# Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ğ¸Ğµ Ğ² ĞºÑÑˆ Ğ¿Ğ¾ÑĞ»Ğµ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ
save_result = save_to_cache(train_result)
```

#### ĞŸĞ°Ñ€Ğ°Ğ»Ğ»ĞµĞ»ÑŒĞ½Ğ¾Ğµ Ğ²Ñ‹Ğ¿Ğ¾Ğ»Ğ½ĞµĞ½Ğ¸Ğµ

**ĞĞ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ¸ Ğ¿Ğ°Ñ€Ğ°Ğ»Ğ»ĞµĞ»Ğ¸Ğ·Ğ¼Ğ° Ğ² Docker Compose:**

```yaml
environment:
  AIRFLOW__CORE__PARALLELISM: 16          # ĞœĞ°ĞºÑ. Ğ·Ğ°Ğ´Ğ°Ñ‡ Ğ²Ğ¾ Ğ²ÑÑ‘Ğ¼ Airflow
  AIRFLOW__CORE__DAG_CONCURRENCY: 8       # ĞœĞ°ĞºÑ. Ğ·Ğ°Ğ´Ğ°Ñ‡ Ğ½Ğ° Ğ¾Ğ´Ğ¸Ğ½ DAG
  AIRFLOW__CELERY__WORKER_CONCURRENCY: 4  # ĞœĞ°ĞºÑ. Ğ·Ğ°Ğ´Ğ°Ñ‡ Ğ½Ğ° Ğ²Ğ¾Ñ€ĞºĞµÑ€
```

**Ğ ĞµĞ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ Ñ‡ĞµÑ€ĞµĞ· expand() operator:**

```python
@dag(max_active_tasks=8)  # ĞĞ³Ñ€Ğ°Ğ½Ğ¸Ñ‡ĞµĞ½Ğ¸Ğµ Ğ½Ğ° ÑƒÑ€Ğ¾Ğ²Ğ½Ğµ DAG
def boston_housing_experiments_dag():

    # ĞŸĞ°Ñ€Ğ°Ğ»Ğ»ĞµĞ»ÑŒĞ½Ğ¾Ğµ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ğµ 19 Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹
    linear_results = train_single_model.expand(
        model_config=LINEAR_MODELS,      # 7 ĞºĞ¾Ğ½Ñ„Ğ¸Ğ³ÑƒÑ€Ğ°Ñ†Ğ¸Ğ¹
        data_info=[data_info] * 7,
    )

    tree_results = train_single_model.expand(
        model_config=TREE_MODELS,        # 9 ĞºĞ¾Ğ½Ñ„Ğ¸Ğ³ÑƒÑ€Ğ°Ñ†Ğ¸Ğ¹  
        data_info=[data_info] * 9,
    )

    other_results = train_single_model.expand(
        model_config=OTHER_MODELS,       # 3 ĞºĞ¾Ğ½Ñ„Ğ¸Ğ³ÑƒÑ€Ğ°Ñ†Ğ¸Ğ¸
        data_info=[data_info] * 3,
    )
```

**ĞœĞ¾Ğ½Ğ¸Ñ‚Ğ¾Ñ€Ğ¸Ğ½Ğ³ Ğ¿Ğ°Ñ€Ğ°Ğ»Ğ»ĞµĞ»ÑŒĞ½Ğ¾Ğ³Ğ¾ Ğ²Ñ‹Ğ¿Ğ¾Ğ»Ğ½ĞµĞ½Ğ¸Ñ:**

- **Airflow UI:** Ğ“Ñ€Ğ°Ñ„ Ğ·Ğ°Ğ²Ğ¸ÑĞ¸Ğ¼Ğ¾ÑÑ‚ĞµĞ¹ Ñ Ñ€ĞµĞ°Ğ»ÑŒĞ½Ñ‹Ğ¼ Ğ²Ñ€ĞµĞ¼ĞµĞ½ĞµĞ¼ Ğ²Ñ‹Ğ¿Ğ¾Ğ»Ğ½ĞµĞ½Ğ¸Ñ
- **Ğ›Ğ¾Ğ³Ğ¸:** Ğ¡Ñ‚Ñ€ÑƒĞºÑ‚ÑƒÑ€Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ğ¾Ğµ Ğ»Ğ¾Ğ³Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ñ‡ĞµÑ€ĞµĞ· `loguru`
- **ĞœĞµÑ‚Ñ€Ğ¸ĞºĞ¸:** Ğ’Ñ€ĞµĞ¼Ñ Ğ²Ñ‹Ğ¿Ğ¾Ğ»Ğ½ĞµĞ½Ğ¸Ñ ĞºĞ°Ğ¶Ğ´Ğ¾Ğ¹ Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ¸ Ğ² MLflow

---

## 6. ĞĞ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ° Ğ¸Ğ½ÑÑ‚Ñ€ÑƒĞ¼ĞµĞ½Ñ‚Ğ° ĞºĞ¾Ğ½Ñ„Ğ¸Ğ³ÑƒÑ€Ğ°Ñ†Ğ¸Ğ¹

**Ğ’Ñ‹Ğ¿Ğ¾Ğ»Ğ½ĞµĞ½Ğ½Ñ‹Ğµ Ğ·Ğ°Ğ´Ğ°Ğ½Ğ¸Ñ:**
- âœ… ĞĞ°ÑÑ‚Ñ€Ğ¾ĞµĞ½ Hydra + Pydantic Ğ´Ğ»Ñ ÑƒĞ¿Ñ€Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ñ ĞºĞ¾Ğ½Ñ„Ğ¸Ğ³ÑƒÑ€Ğ°Ñ†Ğ¸ÑĞ¼Ğ¸
- âœ… Ğ¡Ğ¾Ğ·Ğ´Ğ°Ğ½Ñ‹ ĞºĞ¾Ğ½Ñ„Ğ¸Ğ³ÑƒÑ€Ğ°Ñ†Ğ¸Ğ¸ Ğ´Ğ»Ñ 14 Ñ€Ğ°Ğ·Ğ»Ğ¸Ñ‡Ğ½Ñ‹Ñ… Ğ°Ğ»Ğ³Ğ¾Ñ€Ğ¸Ñ‚Ğ¼Ğ¾Ğ² ML
- âœ… ĞĞ°ÑÑ‚Ñ€Ğ¾ĞµĞ½Ğ° Ğ²Ğ°Ğ»Ğ¸Ğ´Ğ°Ñ†Ğ¸Ñ ĞºĞ¾Ğ½Ñ„Ğ¸Ğ³ÑƒÑ€Ğ°Ñ†Ğ¸Ğ¹ Ñ‡ĞµÑ€ĞµĞ· Pydantic ÑÑ…ĞµĞ¼Ñ‹
- âœ… Ğ¡Ğ¾Ğ·Ğ´Ğ°Ğ½Ğ° ÑĞ¸ÑÑ‚ĞµĞ¼Ğ° ĞºĞ¾Ğ¼Ğ¿Ğ¾Ğ·Ğ¸Ñ†Ğ¸Ğ¸ ĞºĞ¾Ğ½Ñ„Ğ¸Ğ³ÑƒÑ€Ğ°Ñ†Ğ¸Ğ¹ Ñ CLI Ğ¿ĞµÑ€ĞµĞ¾Ğ¿Ñ€ĞµĞ´ĞµĞ»ĞµĞ½Ğ¸ĞµĞ¼

### 6.1 ĞĞ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ° Ğ²Ñ‹Ğ±Ñ€Ğ°Ğ½Ğ½Ğ¾Ğ³Ğ¾ Ğ¸Ğ½ÑÑ‚Ñ€ÑƒĞ¼ĞµĞ½Ñ‚Ğ° Ğ´Ğ»Ñ ÑƒĞ¿Ñ€Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ñ ĞºĞ¾Ğ½Ñ„Ğ¸Ğ³ÑƒÑ€Ğ°Ñ†Ğ¸ÑĞ¼Ğ¸

**Ğ’Ñ‹Ğ±Ñ€Ğ°Ğ½Ğ½Ñ‹Ğ¹ ÑÑ‚ĞµĞº:** Hydra + Pydantic â€” ĞºĞ¾Ğ¼Ğ±Ğ¸Ğ½Ğ°Ñ†Ğ¸Ñ Ğ´Ğ»Ñ ML Ğ¿Ñ€Ğ¾ĞµĞºÑ‚Ğ¾Ğ², Ğ³Ğ´Ğµ Hydra Ğ¾Ğ±ĞµÑĞ¿ĞµÑ‡Ğ¸Ğ²Ğ°ĞµÑ‚ ĞºĞ¾Ğ¼Ğ¿Ğ¾Ğ·Ğ¸Ñ†Ğ¸Ñ YAML-ĞºĞ¾Ğ½Ñ„Ğ¸Ğ³ÑƒÑ€Ğ°Ñ†Ğ¸Ğ¹ Ğ¸ CLI Ğ¿ĞµÑ€ĞµĞ¾Ğ¿Ñ€ĞµĞ´ĞµĞ»ĞµĞ½Ğ¸Ğµ, Ğ° Pydantic â€” ÑÑ‚Ñ€Ğ¾Ğ³ÑƒÑ Ğ²Ğ°Ğ»Ğ¸Ğ´Ğ°Ñ†Ğ¸Ñ ÑÑ…ĞµĞ¼.

**Ğ£ÑÑ‚Ğ°Ğ½Ğ¾Ğ²ĞºĞ° Ğ·Ğ°Ğ²Ğ¸ÑĞ¸Ğ¼Ğ¾ÑÑ‚ĞµĞ¹:**

```bash
uv add "hydra-core>=1.3.2" "pydantic-settings>=2.0"
```

**ĞÑ€Ñ…Ğ¸Ñ‚ĞµĞºÑ‚ÑƒÑ€Ğ° ÑĞ¸ÑÑ‚ĞµĞ¼Ñ‹ ĞºĞ¾Ğ½Ñ„Ğ¸Ğ³ÑƒÑ€Ğ°Ñ†Ğ¸Ğ¹:**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Hydra + Pydantic Configuration System                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚                     YAML Configurations (conf/)                  â”‚    â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚    â”‚
â”‚  â”‚  â”‚config.yaml  â”‚  â”‚ model/*.yamlâ”‚  â”‚ experiment/*.yaml       â”‚  â”‚    â”‚
â”‚  â”‚  â”‚  (defaults) â”‚  â”‚ (14 Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹)â”‚  â”‚ (ĞºĞ¾Ğ¼Ğ¿Ğ¾Ğ·Ğ¸Ñ†Ğ¸Ğ¸)            â”‚  â”‚    â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚    â”‚
â”‚  â”‚         â”‚                â”‚                      â”‚                â”‚    â”‚
â”‚  â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                â”‚    â”‚
â”‚  â”‚                          â”‚                                       â”‚    â”‚
â”‚  â”‚                    â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”                                 â”‚    â”‚
â”‚  â”‚                    â”‚   Hydra   â”‚  CLI: model=ridge model.alpha=0.5â”‚   â”‚
â”‚  â”‚                    â”‚  Compose  â”‚                                 â”‚    â”‚
â”‚  â”‚                    â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜                                 â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                             â”‚                                            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚                 Pydantic Validation (src/schemas/)               â”‚    â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚    â”‚
â”‚  â”‚  â”‚ModelConfig  â”‚  â”‚ DataConfig  â”‚  â”‚ TrainingConfig          â”‚  â”‚    â”‚
â”‚  â”‚  â”‚ (14 ÑÑ…ĞµĞ¼)   â”‚  â”‚ (Ğ²Ğ°Ğ»Ğ¸Ğ´Ğ°Ñ†Ğ¸Ñ) â”‚  â”‚ (ÑĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚Ñ‹)          â”‚  â”‚    â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚    â”‚
â”‚  â”‚         â”‚                â”‚                      â”‚                â”‚    â”‚
â”‚  â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                â”‚    â”‚
â”‚  â”‚                          â”‚                                       â”‚    â”‚
â”‚  â”‚                    â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”                                 â”‚    â”‚
â”‚  â”‚                    â”‚Experiment â”‚                                 â”‚    â”‚
â”‚  â”‚                    â”‚  Config   â”‚                                 â”‚    â”‚
â”‚  â”‚                    â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜                                 â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                             â”‚                                            â”‚
â”‚                       â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”                                      â”‚
â”‚                       â”‚train_hydraâ”‚  DVCLive + MLflow Ğ¸Ğ½Ñ‚ĞµĞ³Ñ€Ğ°Ñ†Ğ¸Ñ        â”‚
â”‚                       â”‚   .py     â”‚                                      â”‚
â”‚                       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Ğ¡Ñ‚Ñ€ÑƒĞºÑ‚ÑƒÑ€Ğ° Ñ„Ğ°Ğ¹Ğ»Ğ¾Ğ² ĞºĞ¾Ğ½Ñ„Ğ¸Ğ³ÑƒÑ€Ğ°Ñ†Ğ¸Ğ¸:**

```
conf/                              # Hydra ĞºĞ¾Ğ½Ñ„Ğ¸Ğ³ÑƒÑ€Ğ°Ñ†Ğ¸Ğ¸
â”œâ”€â”€ config.yaml                    # Ğ“Ğ»Ğ°Ğ²Ğ½Ğ°Ñ ĞºĞ¾Ğ½Ñ„Ğ¸Ğ³ÑƒÑ€Ğ°Ñ†Ğ¸Ñ Ñ defaults
â”œâ”€â”€ model/                         # 14 ĞºĞ¾Ğ½Ñ„Ğ¸Ğ³ÑƒÑ€Ğ°Ñ†Ğ¸Ğ¹ Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹
â”‚   â”œâ”€â”€ random_forest.yaml
â”‚   â”œâ”€â”€ gradient_boosting.yaml
â”‚   â”œâ”€â”€ ridge.yaml
â”‚   â”œâ”€â”€ lasso.yaml
â”‚   â”œâ”€â”€ elastic_net.yaml
â”‚   â”œâ”€â”€ linear_regression.yaml
â”‚   â”œâ”€â”€ huber.yaml
â”‚   â”œâ”€â”€ sgd.yaml
â”‚   â”œâ”€â”€ decision_tree.yaml
â”‚   â”œâ”€â”€ extra_trees.yaml
â”‚   â”œâ”€â”€ adaboost.yaml
â”‚   â”œâ”€â”€ bagging.yaml
â”‚   â”œâ”€â”€ svr.yaml
â”‚   â””â”€â”€ knn.yaml
â”œâ”€â”€ data/
â”‚   â””â”€â”€ boston.yaml                # ĞšĞ¾Ğ½Ñ„Ğ¸Ğ³ÑƒÑ€Ğ°Ñ†Ğ¸Ñ Ğ´Ğ°Ñ‚Ğ°ÑĞµÑ‚Ğ°
â”œâ”€â”€ training/
â”‚   â””â”€â”€ default.yaml               # ĞŸĞ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ñ‹ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ
â””â”€â”€ experiment/                    # ĞšĞ¾Ğ¼Ğ¿Ğ¾Ğ·Ğ¸Ñ†Ğ¸Ğ¸ Ğ´Ğ»Ñ ÑĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚Ğ¾Ğ²
    â”œâ”€â”€ baseline.yaml
    â”œâ”€â”€ tuned.yaml
    â””â”€â”€ linear_comparison.yaml

src/schemas/                       # Pydantic ÑÑ…ĞµĞ¼Ñ‹ Ğ²Ğ°Ğ»Ğ¸Ğ´Ğ°Ñ†Ğ¸Ğ¸
â”œâ”€â”€ __init__.py
â”œâ”€â”€ base.py                        # Ğ‘Ğ°Ğ·Ğ¾Ğ²Ñ‹Ğµ ĞºĞ»Ğ°ÑÑÑ‹
â”œâ”€â”€ model_config.py                # 14 ÑÑ…ĞµĞ¼ Ğ¿Ğ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ğ¾Ğ² Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹
â”œâ”€â”€ data_config.py                 # Ğ¡Ñ…ĞµĞ¼Ğ° Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…
â””â”€â”€ training_config.py             # Ğ¡Ñ…ĞµĞ¼Ğ° Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ + ExperimentConfig
```

### 6.2 Ğ¡Ğ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ğµ ĞºĞ¾Ğ½Ñ„Ğ¸Ğ³ÑƒÑ€Ğ°Ñ†Ğ¸Ğ¹ Ğ´Ğ»Ñ Ñ€Ğ°Ğ·Ğ½Ñ‹Ñ… Ğ°Ğ»Ğ³Ğ¾Ñ€Ğ¸Ñ‚Ğ¼Ğ¾Ğ²

**Ğ“Ğ»Ğ°Ğ²Ğ½Ğ°Ñ ĞºĞ¾Ğ½Ñ„Ğ¸Ğ³ÑƒÑ€Ğ°Ñ†Ğ¸Ñ `conf/config.yaml`:**

```yaml
# Ğ“Ğ»Ğ°Ğ²Ğ½Ğ°Ñ ĞºĞ¾Ğ½Ñ„Ğ¸Ğ³ÑƒÑ€Ğ°Ñ†Ğ¸Ñ Hydra Ğ´Ğ»Ñ Boston Housing ML Ğ¿Ñ€Ğ¾ĞµĞºÑ‚Ğ°
defaults:
  - model: random_forest      # ĞœĞ¾Ğ´ĞµĞ»ÑŒ Ğ¿Ğ¾ ÑƒĞ¼Ğ¾Ğ»Ñ‡Ğ°Ğ½Ğ¸Ñ
  - data: boston              # Ğ”Ğ°Ñ‚Ğ°ÑĞµÑ‚
  - training: default         # ĞŸĞ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ñ‹ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ
  - _self_                    # ĞŸĞµÑ€ĞµĞ¾Ğ¿Ñ€ĞµĞ´ĞµĞ»ĞµĞ½Ğ¸Ñ Ğ¿Ñ€Ğ¸Ğ¼ĞµĞ½ÑÑÑ‚ÑÑ Ğ¿Ğ¾ÑĞ»ĞµĞ´Ğ½Ğ¸Ğ¼Ğ¸

name: boston_housing_experiment
description: "ĞŸÑ€Ğ¾Ğ³Ğ½Ğ¾Ğ·Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ñ†ĞµĞ½ Ğ½Ğ° Ğ½ĞµĞ´Ğ²Ğ¸Ğ¶Ğ¸Ğ¼Ğ¾ÑÑ‚ÑŒ Ğ² Ğ‘Ğ¾ÑÑ‚Ğ¾Ğ½Ğµ"
tags:
  - regression
  - boston-housing
  - scikit-learn

hydra:
  run:
    dir: outputs/${now:%Y-%m-%d}/${now:%H-%M-%S}
  job:
    chdir: false  # ĞĞµ Ğ¼ĞµĞ½ÑÑ‚ÑŒ Ñ€Ğ°Ğ±Ğ¾Ñ‡ÑƒÑ Ğ´Ğ¸Ñ€ĞµĞºÑ‚Ğ¾Ñ€Ğ¸Ñ
```

**ĞŸÑ€Ğ¸Ğ¼ĞµÑ€ ĞºĞ¾Ğ½Ñ„Ğ¸Ğ³ÑƒÑ€Ğ°Ñ†Ğ¸Ğ¸ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ `conf/model/random_forest.yaml`:**

```yaml
# @package model
name: random_forest

# ĞŸĞ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ñ‹ Ğ°Ğ½ÑĞ°Ğ¼Ğ±Ğ»Ñ
n_estimators: 100        # ĞšĞ¾Ğ»Ğ¸Ñ‡ĞµÑÑ‚Ğ²Ğ¾ Ğ´ĞµÑ€ĞµĞ²ÑŒĞµĞ² (10-1000)
max_depth: 10            # ĞœĞ°ĞºÑĞ¸Ğ¼Ğ°Ğ»ÑŒĞ½Ğ°Ñ Ğ³Ğ»ÑƒĞ±Ğ¸Ğ½Ğ° (1-100)
min_samples_split: 2     # ĞœĞ¸Ğ½Ğ¸Ğ¼ÑƒĞ¼ Ğ¾Ğ±Ñ€Ğ°Ğ·Ñ†Ğ¾Ğ² Ğ´Ğ»Ñ Ñ€Ğ°Ğ·Ğ±Ğ¸ĞµĞ½Ğ¸Ñ
min_samples_leaf: 1      # ĞœĞ¸Ğ½Ğ¸Ğ¼ÑƒĞ¼ Ğ¾Ğ±Ñ€Ğ°Ğ·Ñ†Ğ¾Ğ² Ğ² Ğ»Ğ¸ÑÑ‚Ğµ
max_features: sqrt       # ĞŸÑ€Ğ¸Ğ·Ğ½Ğ°ĞºĞ¸ Ğ´Ğ»Ñ Ñ€Ğ°Ğ·Ğ±Ğ¸ĞµĞ½Ğ¸Ñ

# ĞŸÑ€Ğ¾Ğ¸Ğ·Ğ²Ğ¾Ğ´Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ÑÑ‚ÑŒ
n_jobs: -1               # ĞŸĞ°Ñ€Ğ°Ğ»Ğ»ĞµĞ»ÑŒĞ½Ñ‹Ğµ Ğ¿Ğ¾Ñ‚Ğ¾ĞºĞ¸ (-1 = Ğ²ÑĞµ ÑĞ´Ñ€Ğ°)
bootstrap: true          # Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ÑŒ bootstrap Ğ²Ñ‹Ğ±Ğ¾Ñ€ĞºĞ¸

# Ğ’Ğ¾ÑĞ¿Ñ€Ğ¾Ğ¸Ğ·Ğ²Ğ¾Ğ´Ğ¸Ğ¼Ğ¾ÑÑ‚ÑŒ
random_state: 42
```

**ĞŸÑ€Ğ¸Ğ¼ĞµÑ€ ĞºĞ¾Ğ½Ñ„Ğ¸Ğ³ÑƒÑ€Ğ°Ñ†Ğ¸Ğ¸ ÑĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚Ğ° `conf/experiment/tuned.yaml`:**

```yaml
# @package _global_
# ĞĞ°ÑÑ‚Ñ€Ğ¾ĞµĞ½Ğ½Ñ‹Ğ¹ ÑĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚ Ñ Ğ¾Ğ¿Ñ‚Ğ¸Ğ¼Ğ¸Ğ·Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ğ¼Ğ¸ Ğ¿Ğ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ğ°Ğ¼Ğ¸

defaults:
  - override /model: random_forest
  - override /training: default

name: tuned_experiment
description: "Ğ­ĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚ Ñ Ğ¾Ğ¿Ñ‚Ğ¸Ğ¼Ğ¸Ğ·Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ğ¼Ğ¸ Ğ³Ğ¸Ğ¿ĞµÑ€Ğ¿Ğ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ğ°Ğ¼Ğ¸"
tags:
  - tuned
  - optimized

model:
  n_estimators: 200
  max_depth: 15
  min_samples_split: 5
  min_samples_leaf: 2

training:
  experiment_name: boston-housing-tuned
  cross_validation: false
```

**Ğ’ÑĞµ 14 Ğ¿Ğ¾Ğ´Ğ´ĞµÑ€Ğ¶Ğ¸Ğ²Ğ°ĞµĞ¼Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹:**

| ĞšĞ°Ñ‚ĞµĞ³Ğ¾Ñ€Ğ¸Ñ | ĞœĞ¾Ğ´ĞµĞ»Ğ¸ | ĞšĞ¾Ğ½Ñ„Ğ¸Ğ³ÑƒÑ€Ğ°Ñ†Ğ¸Ğ¾Ğ½Ğ½Ñ‹Ğ¹ Ñ„Ğ°Ğ¹Ğ» |
|-----------|--------|----------------------|
| **Ğ›Ğ¸Ğ½ĞµĞ¹Ğ½Ñ‹Ğµ** | Linear Regression, Ridge, Lasso, ElasticNet, Huber, SGD | `conf/model/{linear_regression,ridge,lasso,elastic_net,huber,sgd}.yaml` |
| **ĞĞ½ÑĞ°Ğ¼Ğ±Ğ»Ğ¸** | Random Forest, Extra Trees, Gradient Boosting, AdaBoost, Bagging | `conf/model/{random_forest,extra_trees,gradient_boosting,adaboost,bagging}.yaml` |
| **Ğ”Ñ€ÑƒĞ³Ğ¸Ğµ** | Decision Tree, SVR, KNN | `conf/model/{decision_tree,svr,knn}.yaml` |

### 6.3 ĞĞ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ° Ğ²Ğ°Ğ»Ğ¸Ğ´Ğ°Ñ†Ğ¸Ğ¸ ĞºĞ¾Ğ½Ñ„Ğ¸Ğ³ÑƒÑ€Ğ°Ñ†Ğ¸Ğ¹

**Pydantic ÑÑ…ĞµĞ¼Ñ‹ Ğ´Ğ»Ñ ÑÑ‚Ñ€Ğ¾Ğ³Ğ¾Ğ¹ Ğ²Ğ°Ğ»Ğ¸Ğ´Ğ°Ñ†Ğ¸Ğ¸ Ñ‚Ğ¸Ğ¿Ğ¾Ğ² (`src/schemas/model_config.py`):**

```python
from pydantic import Field, field_validator
from src.schemas.base import BaseConfig

class RandomForestConfig(BaseConfig):
    """ĞšĞ¾Ğ½Ñ„Ğ¸Ğ³ÑƒÑ€Ğ°Ñ†Ğ¸Ñ Random Forest Ñ Ğ²Ğ°Ğ»Ğ¸Ğ´Ğ°Ñ†Ğ¸ĞµĞ¹."""

    name: Literal["random_forest"] = "random_forest"

    n_estimators: int = Field(
        default=100,
        ge=10,          # >= 10
        le=1000,        # <= 1000
        description="ĞšĞ¾Ğ»Ğ¸Ñ‡ĞµÑÑ‚Ğ²Ğ¾ Ğ´ĞµÑ€ĞµĞ²ÑŒĞµĞ² Ğ² Ğ»ĞµÑÑƒ",
    )
    max_depth: int | None = Field(
        default=10,
        ge=1,
        le=100,
        description="ĞœĞ°ĞºÑĞ¸Ğ¼Ğ°Ğ»ÑŒĞ½Ğ°Ñ Ğ³Ğ»ÑƒĞ±Ğ¸Ğ½Ğ° Ğ´ĞµÑ€ĞµĞ²ÑŒĞµĞ²",
    )
    min_samples_split: int = Field(
        default=2,
        ge=2,
        le=100,
        description="ĞœĞ¸Ğ½Ğ¸Ğ¼ÑƒĞ¼ Ğ¾Ğ±Ñ€Ğ°Ğ·Ñ†Ğ¾Ğ² Ğ´Ğ»Ñ Ñ€Ğ°Ğ·Ğ±Ğ¸ĞµĞ½Ğ¸Ñ ÑƒĞ·Ğ»Ğ°",
    )
    random_state: int = Field(default=42, ge=0)

    @field_validator("n_estimators")
    @classmethod
    def validate_n_estimators(cls, v: int) -> int:
        if v < 10:
            raise ValueError(f"n_estimators Ğ´Ğ¾Ğ»Ğ¶ĞµĞ½ Ğ±Ñ‹Ñ‚ÑŒ >= 10, Ğ¿Ğ¾Ğ»ÑƒÑ‡ĞµĞ½Ğ¾: {v}")
        return v

    def get_params(self) -> dict:
        """Ğ’Ğ¾Ğ·Ğ²Ñ€Ğ°Ñ‰Ğ°ĞµÑ‚ Ğ¿Ğ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ñ‹ Ğ´Ğ»Ñ ÑĞ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ñ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸."""
        return self.model_dump(exclude={"name"}, exclude_none=True)
```

**Ğ’Ğ°Ğ»Ğ¸Ğ´Ğ°Ñ†Ğ¸Ñ ĞºĞ¾Ğ½Ñ„Ğ¸Ğ³ÑƒÑ€Ğ°Ñ†Ğ¸Ğ¸ ÑĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚Ğ° (`src/schemas/training_config.py`):**

```python
class ExperimentConfig(BaseConfig):
    """ĞŸĞ¾Ğ»Ğ½Ğ°Ñ ĞºĞ¾Ğ½Ñ„Ğ¸Ğ³ÑƒÑ€Ğ°Ñ†Ğ¸Ñ ÑĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚Ğ° Ñ ĞºĞ¾Ğ¼Ğ¿Ğ¾Ğ·Ğ¸Ñ†Ğ¸ĞµĞ¹."""

    model: dict[str, Any]
    data: dict[str, Any]
    training: dict[str, Any]
    name: str = "default"
    tags: list[str] = []

    def get_validated_model_config(self) -> ModelConfig:
        """Ğ’Ğ¾Ğ·Ğ²Ñ€Ğ°Ñ‰Ğ°ĞµÑ‚ Ğ²Ğ°Ğ»Ğ¸Ğ´Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½ÑƒÑ ĞºĞ¾Ğ½Ñ„Ğ¸Ğ³ÑƒÑ€Ğ°Ñ†Ğ¸Ñ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸."""
        model_name = self.model.get("name", "random_forest")
        config_class = get_model_config_class(model_name)
        return config_class(**self.model)

    def validate_all(self) -> tuple[ModelConfig, DataConfig, TrainingConfig]:
        """Ğ’Ğ°Ğ»Ğ¸Ğ´Ğ¸Ñ€ÑƒĞµÑ‚ Ğ²ÑĞµ ĞºĞ¾Ğ½Ñ„Ğ¸Ğ³ÑƒÑ€Ğ°Ñ†Ğ¸Ğ¸ Ğ¸ Ğ²Ğ¾Ğ·Ğ²Ñ€Ğ°Ñ‰Ğ°ĞµÑ‚ Ğ¸Ñ…."""
        return (
            self.get_validated_model_config(),
            self.get_validated_data_config(),
            self.get_validated_training_config(),
        )

    @classmethod
    def from_hydra(cls, cfg: DictConfig) -> "ExperimentConfig":
        """Ğ¡Ğ¾Ğ·Ğ´Ğ°Ñ‘Ñ‚ ExperimentConfig Ğ¸Ğ· Hydra DictConfig."""
        config_dict = OmegaConf.to_container(cfg, resolve=True)
        return cls(**config_dict)
```

**Ğ’Ğ°Ğ»Ğ¸Ğ´Ğ°Ñ†Ğ¸Ñ Ğ² ÑĞºÑ€Ğ¸Ğ¿Ñ‚Ğµ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ (`src/modeling/train_hydra.py`):**

```python
def validate_config(cfg: DictConfig) -> ExperimentConfig:
    """Ğ’Ğ°Ğ»Ğ¸Ğ´Ğ°Ñ†Ğ¸Ñ ĞºĞ¾Ğ½Ñ„Ğ¸Ğ³ÑƒÑ€Ğ°Ñ†Ğ¸Ğ¸ Ñ‡ĞµÑ€ĞµĞ· Pydantic."""
    try:
        config_dict = OmegaConf.to_container(cfg, resolve=True)

        exp_config = ExperimentConfig(
            model=config_dict.get("model", {}),
            data=config_dict.get("data", {}),
            training=config_dict.get("training", {}),
        )

        # Ğ’Ğ°Ğ»Ğ¸Ğ´Ğ¸Ñ€ÑƒĞµĞ¼ Ğ²ÑĞµ Ğ²Ğ»Ğ¾Ğ¶ĞµĞ½Ğ½Ñ‹Ğµ ĞºĞ¾Ğ½Ñ„Ğ¸Ğ³ÑƒÑ€Ğ°Ñ†Ğ¸Ğ¸
        model_config, data_config, training_config = exp_config.validate_all()
        logger.success(f"ĞšĞ¾Ğ½Ñ„Ğ¸Ğ³ÑƒÑ€Ğ°Ñ†Ğ¸Ñ Ğ²Ğ°Ğ»Ğ¸Ğ´Ğ½Ğ°: model={model_config.name}")

        return exp_config
    except ValidationError as e:
        logger.error(f"ĞÑˆĞ¸Ğ±ĞºĞ° Ğ²Ğ°Ğ»Ğ¸Ğ´Ğ°Ñ†Ğ¸Ğ¸: {e}")
        raise
```

### 6.4 Ğ¡Ğ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ğµ ÑĞ¸ÑÑ‚ĞµĞ¼Ñ‹ ĞºĞ¾Ğ¼Ğ¿Ğ¾Ğ·Ğ¸Ñ†Ğ¸Ğ¸ ĞºĞ¾Ğ½Ñ„Ğ¸Ğ³ÑƒÑ€Ğ°Ñ†Ğ¸Ğ¹

**Hydra defaults Ğ´Ğ»Ñ ĞºĞ¾Ğ¼Ğ¿Ğ¾Ğ·Ğ¸Ñ†Ğ¸Ğ¸:**

```yaml
# conf/config.yaml
defaults:
  - model: random_forest      # ĞŸĞ¾Ğ´ĞºĞ»ÑÑ‡Ğ°ĞµÑ‚ conf/model/random_forest.yaml
  - data: boston              # ĞŸĞ¾Ğ´ĞºĞ»ÑÑ‡Ğ°ĞµÑ‚ conf/data/boston.yaml
  - training: default         # ĞŸĞ¾Ğ´ĞºĞ»ÑÑ‡Ğ°ĞµÑ‚ conf/training/default.yaml
  - _self_                    # ĞŸĞµÑ€ĞµĞ¾Ğ¿Ñ€ĞµĞ´ĞµĞ»ĞµĞ½Ğ¸Ñ Ğ¸Ğ· ÑÑ‚Ğ¾Ğ³Ğ¾ Ñ„Ğ°Ğ¹Ğ»Ğ°
```

**Ğ­ĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚Ñ‹ ĞºĞ°Ğº ĞºĞ¾Ğ¼Ğ¿Ğ¾Ğ·Ğ¸Ñ†Ğ¸Ğ¸ (`conf/experiment/baseline.yaml`):**

```yaml
# @package _global_
defaults:
  - override /model: random_forest
  - override /training: default

name: baseline_experiment
model:
  n_estimators: 100
  max_depth: 10
```

**ĞŸÑ€Ğ¸Ğ¼ĞµÑ€Ñ‹ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ CLI:**

```bash
# Ğ‘Ğ°Ğ·Ğ¾Ğ²Ñ‹Ğ¹ Ğ·Ğ°Ğ¿ÑƒÑĞº (Random Forest Ğ¿Ğ¾ ÑƒĞ¼Ğ¾Ğ»Ñ‡Ğ°Ğ½Ğ¸Ñ)
uv run python src/modeling/train_hydra.py

# Ğ¡Ğ¼ĞµĞ½Ğ° Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸
uv run python src/modeling/train_hydra.py model=gradient_boosting

# ĞŸĞµÑ€ĞµĞ¾Ğ¿Ñ€ĞµĞ´ĞµĞ»ĞµĞ½Ğ¸Ğµ Ğ¿Ğ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ğ¾Ğ²
uv run python src/modeling/train_hydra.py model=random_forest \
    model.n_estimators=500 \
    model.max_depth=20

# Ğ“Ğ¾Ñ‚Ğ¾Ğ²Ñ‹Ğ¹ ÑĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚
uv run python src/modeling/train_hydra.py +experiment=tuned

# Multirun (Ğ½ĞµÑĞºĞ¾Ğ»ÑŒĞºĞ¾ Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ Ğ¿Ğ°Ñ€Ğ°Ğ»Ğ»ĞµĞ»ÑŒĞ½Ğ¾)
uv run python src/modeling/train_hydra.py --multirun \
    model=ridge,lasso,elastic_net

# ĞŸÑ€Ğ¾ÑĞ¼Ğ¾Ñ‚Ñ€ ĞºĞ¾Ğ½Ñ„Ğ¸Ğ³ÑƒÑ€Ğ°Ñ†Ğ¸Ğ¸ Ğ±ĞµĞ· Ğ·Ğ°Ğ¿ÑƒÑĞºĞ°
uv run python src/modeling/train_hydra.py --cfg job
```

**Ğ ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ñ‹ Ñ‚ĞµÑÑ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ:**

| Ğ­ĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚ | ĞœĞ¾Ğ´ĞµĞ»ÑŒ | RÂ² Score | RMSE | ĞšĞ¾Ğ¼Ğ°Ğ½Ğ´Ğ° |
|-------------|--------|----------|------|---------|
| Default | Random Forest | 0.8482 | 3.34 | `model=random_forest` |
| Tuned | Random Forest (Ğ¾Ğ¿Ñ‚Ğ¸Ğ¼.) | 0.8482 | 3.34 | `+experiment=tuned` |
| Ridge | Ridge Regression | 0.6662 | 4.95 | `model=ridge` |

**Ğ˜Ğ½Ñ‚ĞµĞ³Ñ€Ğ°Ñ†Ğ¸Ñ Ñ MLflow Ğ¸ DVCLive:**

```python
@hydra.main(version_base=None, config_path="../../conf", config_name="config")
def main(cfg: DictConfig) -> float:
    # Ğ’Ğ°Ğ»Ğ¸Ğ´Ğ°Ñ†Ğ¸Ñ Ñ‡ĞµÑ€ĞµĞ· Pydantic
    exp_config = validate_config(cfg)
    model_config = exp_config.get_validated_model_config()

    # DVCLive Ğ´Ğ»Ñ Ğ»Ğ¾Ğ³Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ
    with Live(save_dvc_exp=True) as live:
        live.log_param("model_name", model_config.name)
        for key, value in model_config.get_params().items():
            live.log_param(f"model.{key}", value)

        # ... Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ğµ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ ...

        for metric_name, metric_value in metrics.items():
            live.log_metric(metric_name, metric_value)

    return metrics["r2_score"]
```

---

## 7. Ğ˜Ğ½Ñ‚ĞµĞ³Ñ€Ğ°Ñ†Ğ¸Ñ Ğ¸ Ñ‚ĞµÑÑ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ ÑĞ¸ÑÑ‚ĞµĞ¼

**Ğ’Ñ‹Ğ¿Ğ¾Ğ»Ğ½ĞµĞ½Ğ½Ñ‹Ğµ Ğ·Ğ°Ğ´Ğ°Ğ½Ğ¸Ñ:**
- âœ… Ğ˜Ğ½Ñ‚ĞµĞ³Ñ€Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ñ‹ Ğ²ÑĞµ Ğ¸Ğ½ÑÑ‚Ñ€ÑƒĞ¼ĞµĞ½Ñ‚Ñ‹ (Airflow + MLflow + MinIO + Hydra)
- âœ… Ğ¡Ğ¾Ğ·Ğ´Ğ°Ğ½Ğ° ÑĞ¸ÑÑ‚ĞµĞ¼Ğ° Ğ¼Ğ¾Ğ½Ğ¸Ñ‚Ğ¾Ñ€Ğ¸Ğ½Ğ³Ğ° Ğ²Ñ‹Ğ¿Ğ¾Ğ»Ğ½ĞµĞ½Ğ¸Ñ (loguru + Airflow UI + MLflow UI)
- âœ… ĞĞ°ÑÑ‚Ñ€Ğ¾ĞµĞ½Ñ‹ ÑƒĞ²ĞµĞ´Ğ¾Ğ¼Ğ»ĞµĞ½Ğ¸Ñ Ğ¾ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ğ°Ñ… (callbacks + ÑĞ²Ğ¾Ğ´Ğ½Ñ‹Ğµ Ğ¾Ñ‚Ñ‡ĞµÑ‚Ñ‹)
- âœ… ĞŸÑ€Ğ¾Ñ‚ĞµÑÑ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ° Ğ²Ğ¾ÑĞ¿Ñ€Ğ¾Ğ¸Ğ·Ğ²Ğ¾Ğ´Ğ¸Ğ¼Ğ¾ÑÑ‚ÑŒ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ğ¾Ğ² (random seed + ĞºÑÑˆĞ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ)

### 7.1 Ğ˜Ğ½Ñ‚ĞµĞ³Ñ€Ğ°Ñ†Ğ¸Ñ Ğ²Ñ‹Ğ±Ñ€Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ¸Ğ½ÑÑ‚Ñ€ÑƒĞ¼ĞµĞ½Ñ‚Ğ¾Ğ²

**ĞÑ€Ñ…Ğ¸Ñ‚ĞµĞºÑ‚ÑƒÑ€Ğ° Ğ¸Ğ½Ñ‚ĞµĞ³Ñ€Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ğ¾Ğ¹ ÑĞ¸ÑÑ‚ĞµĞ¼Ñ‹:**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     Ğ˜Ğ½Ñ‚ĞµĞ³Ñ€Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ğ°Ñ ML ĞŸĞ»Ğ°Ñ‚Ñ„Ğ¾Ñ€Ğ¼Ğ°                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚   Apache Airflow â”‚    â”‚      MLflow      â”‚    â”‚      MinIO       â”‚   â”‚
â”‚  â”‚  (ĞÑ€ĞºĞµÑÑ‚Ñ€Ğ°Ñ†Ğ¸Ñ)   â”‚â—€â”€â”€â–¶â”‚   (Ğ¢Ñ€ĞµĞºĞ¸Ğ½Ğ³)      â”‚â—€â”€â”€â–¶â”‚   (Ğ¥Ñ€Ğ°Ğ½Ğ¸Ğ»Ğ¸Ñ‰Ğµ)    â”‚   â”‚
â”‚  â”‚                  â”‚    â”‚                  â”‚    â”‚                  â”‚   â”‚
â”‚  â”‚ â€¢ 3 DAG          â”‚    â”‚ â€¢ Ğ­ĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚Ñ‹   â”‚    â”‚ â€¢ ĞÑ€Ñ‚ĞµÑ„Ğ°ĞºÑ‚Ñ‹      â”‚   â”‚
â”‚  â”‚ â€¢ ĞŸĞ°Ñ€Ğ°Ğ»Ğ»ĞµĞ»Ğ¸Ğ·Ğ¼    â”‚    â”‚ â€¢ ĞœĞµÑ‚Ñ€Ğ¸ĞºĞ¸        â”‚    â”‚ â€¢ ĞšÑÑˆĞ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ    â”‚   â”‚
â”‚  â”‚ â€¢ ĞšÑÑˆĞ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ    â”‚    â”‚ â€¢ ĞœĞ¾Ğ´ĞµĞ»Ğ¸         â”‚    â”‚ â€¢ S3 API         â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚           â”‚                        â”‚                        â”‚           â”‚
â”‚           â–¼                        â–¼                        â–¼           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚                        ĞĞ±Ñ‰Ğ°Ñ Ğ¸Ğ½Ñ‚ĞµĞ³Ñ€Ğ°Ñ†Ğ¸Ñ                             â”‚ â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤ â”‚
â”‚  â”‚ â€¢ Docker Compose Ğ¾Ñ€ĞºĞµÑÑ‚Ñ€Ğ°Ñ†Ğ¸Ñ Ğ²ÑĞµÑ… ÑĞµÑ€Ğ²Ğ¸ÑĞ¾Ğ²                          â”‚ â”‚
â”‚  â”‚ â€¢ ĞĞ±Ñ‰Ğ¸Ğµ Ğ¿ĞµÑ€ĞµĞ¼ĞµĞ½Ğ½Ñ‹Ğµ Ğ¾ĞºÑ€ÑƒĞ¶ĞµĞ½Ğ¸Ñ (.env)                                 â”‚ â”‚
â”‚  â”‚ â€¢ Ğ•Ğ´Ğ¸Ğ½Ğ°Ñ Ğ°ÑƒÑ‚ĞµĞ½Ñ‚Ğ¸Ñ„Ğ¸ĞºĞ°Ñ†Ğ¸Ñ (Nginx + Basic Auth)                       â”‚ â”‚
â”‚  â”‚ â€¢ ĞœĞ¾Ğ½Ğ¸Ñ‚Ğ¾Ñ€Ğ¸Ğ½Ğ³ Ñ‡ĞµÑ€ĞµĞ· ÑÑ‚Ñ€ÑƒĞºÑ‚ÑƒÑ€Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ğµ Ğ»Ğ¾Ğ³Ğ¸ (loguru)                  â”‚ â”‚
â”‚  â”‚ â€¢ ĞĞ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ğµ ÑƒĞ²ĞµĞ´Ğ¾Ğ¼Ğ»ĞµĞ½Ğ¸Ñ Ğ² Airflow UI + MLflow UI              â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**ĞšĞ»ÑÑ‡ĞµĞ²Ñ‹Ğµ Ñ‚Ğ¾Ñ‡ĞºĞ¸ Ğ¸Ğ½Ñ‚ĞµĞ³Ñ€Ğ°Ñ†Ğ¸Ğ¸:**

### **1. Airflow â†’ MLflow Ğ¸Ğ½Ñ‚ĞµĞ³Ñ€Ğ°Ñ†Ğ¸Ñ**

```python
# Ğ’ Airflow DAG
def generate_report(aggregated: dict) -> dict:
    """ĞĞ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¾Ğµ Ğ»Ğ¾Ğ³Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ğ¾Ğ² Ğ² MLflow Ğ¸Ğ· Airflow."""

    import mlflow

    mlflow_uri = os.environ.get("MLFLOW_TRACKING_URI", "http://mlflow:5000")
    mlflow.set_tracking_uri(mlflow_uri)
    mlflow.set_experiment("boston_housing_experiments")

    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")

    with mlflow.start_run(run_name=f"experiments_summary_{timestamp}"):
        # Ğ›Ğ¾Ğ³Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ°Ğ³Ñ€ĞµĞ³Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ¼ĞµÑ‚Ñ€Ğ¸Ğº
        mlflow.log_metric("total_experiments", aggregated["total_experiments"])
        mlflow.log_metric("best_r2", aggregated["summary"]["best_r2"])
        mlflow.log_metric("mean_r2", aggregated["summary"]["mean_r2"])

        # Ğ›Ğ¾Ğ³Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ¿Ğ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ğ¾Ğ² Ğ»ÑƒÑ‡ÑˆĞµĞ¹ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸
        mlflow.log_param("best_model", aggregated["best_model"]["run_id"])

        # Ğ›Ğ¾Ğ³Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ°Ñ€Ñ‚ĞµÑ„Ğ°ĞºÑ‚Ğ¾Ğ²
        mlflow.log_artifact(report_path, "reports")
        mlflow.log_artifact(aggregated["results_path"], "results")

        # Ğ¢ĞµĞ³Ğ¸ Ğ´Ğ»Ñ Ğ¸Ğ´ĞµĞ½Ñ‚Ğ¸Ñ„Ğ¸ĞºĞ°Ñ†Ğ¸Ğ¸ Ğ¸ÑÑ‚Ğ¾Ñ‡Ğ½Ğ¸ĞºĞ°
        mlflow.set_tag("source", "airflow")
        mlflow.set_tag("dag", "boston_housing_experiments")
```

### **2. Airflow â†’ MinIO Ğ¸Ğ½Ñ‚ĞµĞ³Ñ€Ğ°Ñ†Ğ¸Ñ**

```python
# ĞšÑÑˆĞ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ°Ñ€Ñ‚ĞµÑ„Ğ°ĞºÑ‚Ğ¾Ğ² Ğ² MinIO Ğ¸Ğ· Airflow
class MinIOCache:
    def __init__(self):
        # Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµĞ¼ Ñ‚Ğµ Ğ¶Ğµ Ğ¿ĞµÑ€ĞµĞ¼ĞµĞ½Ğ½Ñ‹Ğµ Ğ¾ĞºÑ€ÑƒĞ¶ĞµĞ½Ğ¸Ñ Ñ‡Ñ‚Ğ¾ Ğ¸ Ğ² Airflow
        self.endpoint_url = os.environ.get("MLFLOW_S3_ENDPOINT_URL", "http://minio:9000")
        self.access_key = os.environ.get("AWS_ACCESS_KEY_ID", "minioadmin")
        self.secret_key = os.environ.get("AWS_SECRET_ACCESS_KEY", "minioadmin")

        self.client = boto3.client(
            "s3",
            endpoint_url=self.endpoint_url,
            aws_access_key_id=self.access_key,
            aws_secret_access_key=self.secret_key,
        )

# Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ² Airflow task
@task
def save_to_cache(train_result: dict) -> dict:
    """Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ğ¸Ğµ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ Ğ² MinIO Ñ Ğ°Ğ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¾Ğ¹ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸ĞµĞ¹ ĞºĞ»ÑÑ‡ĞµĞ¹."""

    from minio_cache import save_model_to_cache

    model_uri = save_model_to_cache(
        model_path=train_result["model_path"],
        model_name="random_forest_cached",
        params=train_result["params"],
        data_path=train_result["data_path"],
        metrics=train_result["metrics"],
        bucket_name="airflow-cache",
    )

    return {"status": "saved", "cache_uri": model_uri}
```

### **3. MLflow â†’ MinIO Ğ¸Ğ½Ñ‚ĞµĞ³Ñ€Ğ°Ñ†Ğ¸Ñ**

```python
# MLflow Ğ°Ğ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¸ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµÑ‚ MinIO Ğ´Ğ»Ñ Ğ°Ñ€Ñ‚ĞµÑ„Ğ°ĞºÑ‚Ğ¾Ğ²
# ĞĞ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ° Ğ² Ğ¿ĞµÑ€ĞµĞ¼ĞµĞ½Ğ½Ñ‹Ñ… Ğ¾ĞºÑ€ÑƒĞ¶ĞµĞ½Ğ¸Ñ:

MLFLOW_S3_ENDPOINT_URL=http://minio:9000
AWS_ACCESS_KEY_ID=minioadmin  
AWS_SECRET_ACCESS_KEY=minioadmin

# Ğ’ÑĞµ Ğ°Ñ€Ñ‚ĞµÑ„Ğ°ĞºÑ‚Ñ‹ MLflow Ğ°Ğ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¸ ÑĞ¾Ñ…Ñ€Ğ°Ğ½ÑÑÑ‚ÑÑ Ğ² MinIO
mlflow.sklearn.log_model(model, "model")  # â†’ s3://mlflow-artifacts/...
mlflow.log_artifact("report.html")        # â†’ s3://mlflow-artifacts/...
```

### 7.2 Ğ¡Ğ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ğµ ÑĞ¸ÑÑ‚ĞµĞ¼Ñ‹ Ğ¼Ğ¾Ğ½Ğ¸Ñ‚Ğ¾Ñ€Ğ¸Ğ½Ğ³Ğ° Ğ²Ñ‹Ğ¿Ğ¾Ğ»Ğ½ĞµĞ½Ğ¸Ñ

**ĞœĞ½Ğ¾Ğ³Ğ¾ÑƒÑ€Ğ¾Ğ²Ğ½ĞµĞ²Ğ°Ñ ÑĞ¸ÑÑ‚ĞµĞ¼Ğ° Ğ¼Ğ¾Ğ½Ğ¸Ñ‚Ğ¾Ñ€Ğ¸Ğ½Ğ³Ğ°:**

### **Ğ£Ñ€Ğ¾Ğ²ĞµĞ½ÑŒ 1: Ğ¡Ñ‚Ñ€ÑƒĞºÑ‚ÑƒÑ€Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ğµ Ğ»Ğ¾Ğ³Ğ¸ (loguru)**

```python
from loguru import logger

# ĞšĞ¾Ğ½Ñ„Ğ¸Ğ³ÑƒÑ€Ğ°Ñ†Ğ¸Ñ Ğ»Ğ¾Ğ³Ğ³ĞµÑ€Ğ° Ğ² src/config.py
logger.remove(0)  # Ğ£Ğ´Ğ°Ğ»ÑĞµĞ¼ ÑÑ‚Ğ°Ğ½Ğ´Ğ°Ñ€Ñ‚Ğ½Ñ‹Ğ¹ Ñ…ÑĞ½Ğ´Ğ»ĞµÑ€
logger.add(
    sys.stderr,
    format="<green>{time:YYYY-MM-DD HH:mm:ss}</green> | "
           "<level>{level: <8}</level> | "
           "<cyan>{name}</cyan>:<cyan>{function}</cyan>:<cyan>{line}</cyan> - "
           "<level>{message}</level>",
    level="INFO"
)

# Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ² ML Ğ¿Ğ°Ğ¹Ğ¿Ğ»Ğ°Ğ¹Ğ½Ğ°Ñ…
@task
def train_single_model(model_config: dict, data_info: dict) -> dict:
    """ĞĞ±ÑƒÑ‡ĞµĞ½Ğ¸Ğµ Ñ Ğ¿Ğ¾Ğ´Ñ€Ğ¾Ğ±Ğ½Ñ‹Ğ¼ Ğ»Ğ¾Ğ³Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸ĞµĞ¼."""

    model_name = model_config["name"]
    params = model_config["params"]

    logger.info(f"ğŸš€ ĞĞ°Ñ‡Ğ°Ğ»Ğ¾ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ: {model_name}")
    logger.debug(f"   ĞŸĞ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ñ‹: {params}")
    logger.debug(f"   Ğ Ğ°Ğ·Ğ¼ĞµÑ€ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…: train={data_info['n_train']}, test={data_info['n_test']}")

    start_time = time.time()

    try:
        # ĞĞ±ÑƒÑ‡ĞµĞ½Ğ¸Ğµ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸
        model = create_model(model_name, params)
        model.fit(X_train, y_train)

        train_time = time.time() - start_time
        logger.info(f"âœ… ĞĞ±ÑƒÑ‡ĞµĞ½Ğ¸Ğµ Ğ·Ğ°Ğ²ĞµÑ€ÑˆĞµĞ½Ğ¾ Ğ·Ğ° {train_time:.2f}Ñ")

        # Ğ’Ñ‹Ñ‡Ğ¸ÑĞ»ĞµĞ½Ğ¸Ğµ Ğ¼ĞµÑ‚Ñ€Ğ¸Ğº
        y_pred = model.predict(X_test)
        metrics = {
            "r2_score": float(r2_score(y_test, y_pred)),
            "rmse": float(np.sqrt(mean_squared_error(y_test, y_pred))),
        }

        logger.success(f"ğŸ“Š ĞœĞµÑ‚Ñ€Ğ¸ĞºĞ¸: RÂ²={metrics['r2_score']:.4f}, RMSE={metrics['rmse']:.4f}")

        return {
            "run_id": f"{model_name}_{params_str}",
            "metrics": metrics,
            "train_time": train_time,
        }

    except Exception as e:
        logger.error(f"âŒ ĞÑˆĞ¸Ğ±ĞºĞ° Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ {model_name}: {e}")
        raise
```

### **Ğ£Ñ€Ğ¾Ğ²ĞµĞ½ÑŒ 2: ĞœĞ¾Ğ½Ğ¸Ñ‚Ğ¾Ñ€Ğ¸Ğ½Ğ³ Airflow**

```python
# ĞĞ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ¸ Ğ¼Ğ¾Ğ½Ğ¸Ñ‚Ğ¾Ñ€Ğ¸Ğ½Ğ³Ğ° Ğ² default_args DAG
default_args = {
    "owner": "boston_housing",
    "depends_on_past": False,
    "email_on_failure": False,    # ĞÑ‚ĞºĞ»ÑÑ‡Ğ°ĞµĞ¼ email, Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµĞ¼ UI
    "email_on_retry": False,
    "retries": 1,
    "retry_delay": timedelta(minutes=2),
    "on_failure_callback": log_failure_callback,
    "on_success_callback": log_success_callback,
}

def log_failure_callback(context):
    """Callback Ğ¿Ñ€Ğ¸ Ğ½ĞµÑƒĞ´Ğ°Ñ‡Ğ½Ğ¾Ğ¼ Ğ²Ñ‹Ğ¿Ğ¾Ğ»Ğ½ĞµĞ½Ğ¸Ğ¸ Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ¸."""
    task_instance = context.get('task_instance')
    dag_run = context.get('dag_run')

    logger.error(f"ğŸ”¥ Task failed: {task_instance.dag_id}.{task_instance.task_id}")
    logger.error(f"   DAG run: {dag_run.run_id}")
    logger.error(f"   Execution date: {context.get('execution_date')}")

    # ĞœĞ¾Ğ¶Ğ½Ğ¾ Ğ´Ğ¾Ğ±Ğ°Ğ²Ğ¸Ñ‚ÑŒ Ğ¾Ñ‚Ğ¿Ñ€Ğ°Ğ²ĞºÑƒ Ğ² Ğ²Ğ½ĞµÑˆĞ½Ğ¸Ğµ ÑĞ¸ÑÑ‚ĞµĞ¼Ñ‹ Ğ¼Ğ¾Ğ½Ğ¸Ñ‚Ğ¾Ñ€Ğ¸Ğ½Ğ³Ğ°
    # send_alert_to_slack(task_instance, dag_run)

def log_success_callback(context):
    """Callback Ğ¿Ñ€Ğ¸ ÑƒÑĞ¿ĞµÑˆĞ½Ğ¾Ğ¼ Ğ²Ñ‹Ğ¿Ğ¾Ğ»Ğ½ĞµĞ½Ğ¸Ğ¸ Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ¸."""
    task_instance = context.get('task_instance')
    duration = task_instance.end_date - task_instance.start_date

    logger.success(f"âœ… Task completed: {task_instance.dag_id}.{task_instance.task_id}")
    logger.info(f"   Duration: {duration.total_seconds():.2f}s")
```

### **Ğ£Ñ€Ğ¾Ğ²ĞµĞ½ÑŒ 3: ĞœĞ¾Ğ½Ğ¸Ñ‚Ğ¾Ñ€Ğ¸Ğ½Ğ³ Ñ‡ĞµÑ€ĞµĞ· MLflow UI**

```python
# ĞĞ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¾Ğµ Ğ»Ğ¾Ğ³Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ ÑĞ¸ÑÑ‚ĞµĞ¼Ğ½Ñ‹Ñ… Ğ¼ĞµÑ‚Ñ€Ğ¸Ğº
@mlflow_run(experiment_name="boston-housing")
def train_with_monitoring(model_name: str, params: dict):
    """ĞĞ±ÑƒÑ‡ĞµĞ½Ğ¸Ğµ Ñ Ğ¼Ğ¾Ğ½Ğ¸Ñ‚Ğ¾Ñ€Ğ¸Ğ½Ğ³Ğ¾Ğ¼ Ğ¿Ñ€Ğ¾Ğ¸Ğ·Ğ²Ğ¾Ğ´Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ÑÑ‚Ğ¸."""

    import psutil
    import time

    # ĞœĞ¾Ğ½Ğ¸Ñ‚Ğ¾Ñ€Ğ¸Ğ½Ğ³ Ñ€ĞµÑÑƒÑ€ÑĞ¾Ğ²
    process = psutil.Process()
    start_memory = process.memory_info().rss / 1024 / 1024  # MB
    start_cpu_percent = process.cpu_percent()

    # Ğ›Ğ¾Ğ³Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ ÑĞ¸ÑÑ‚ĞµĞ¼Ğ½Ğ¾Ğ¹ Ğ¸Ğ½Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ†Ğ¸Ğ¸
    mlflow.log_param("system_memory_gb", psutil.virtual_memory().total / 1024**3)
    mlflow.log_param("system_cpu_count", psutil.cpu_count())
    mlflow.log_param("start_memory_mb", start_memory)

    start_time = time.time()

    # ĞĞ±ÑƒÑ‡ĞµĞ½Ğ¸Ğµ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸
    model = train_model(model_name, params)

    # ĞœĞ¾Ğ½Ğ¸Ñ‚Ğ¾Ñ€Ğ¸Ğ½Ğ³ Ğ¿Ğ¾ÑĞ»Ğµ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ
    end_time = time.time()
    end_memory = process.memory_info().rss / 1024 / 1024  # MB
    memory_delta = end_memory - start_memory

    # Ğ›Ğ¾Ğ³Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ¼ĞµÑ‚Ñ€Ğ¸Ğº Ğ¿Ñ€Ğ¾Ğ¸Ğ·Ğ²Ğ¾Ğ´Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ÑÑ‚Ğ¸
    mlflow.log_metric("train_time_seconds", end_time - start_time)
    mlflow.log_metric("memory_usage_mb", end_memory)
    mlflow.log_metric("memory_delta_mb", memory_delta)
    mlflow.log_metric("cpu_percent", process.cpu_percent())

    return model
```

### 7.3 ĞĞ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ° ÑƒĞ²ĞµĞ´Ğ¾Ğ¼Ğ»ĞµĞ½Ğ¸Ğ¹ Ğ¾ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ğ°Ñ…

**Ğ¡Ğ¸ÑÑ‚ĞµĞ¼Ğ° ÑƒĞ²ĞµĞ´Ğ¾Ğ¼Ğ»ĞµĞ½Ğ¸Ğ¹ Ñ‡ĞµÑ€ĞµĞ· Ğ¸Ğ½Ñ‚ĞµÑ€Ñ„ĞµĞ¹ÑÑ‹:**

### **1. Airflow UI Dashboard**

```python
# ĞšĞ°ÑÑ‚Ğ¾Ğ¼Ğ½Ñ‹Ğµ Ğ¾Ğ¿ĞµÑ€Ğ°Ñ‚Ğ¾Ñ€Ñ‹ Ğ´Ğ»Ñ ÑĞ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ñ rich-ÑƒĞ²ĞµĞ´Ğ¾Ğ¼Ğ»ĞµĞ½Ğ¸Ğ¹
from airflow.operators.bash import BashOperator
from airflow.operators.python import PythonOperator

@task
def send_completion_notification(results: dict) -> dict:
    """Ğ¡Ğ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ğµ ÑƒĞ²ĞµĞ´Ğ¾Ğ¼Ğ»ĞµĞ½Ğ¸Ñ Ğ¾ Ğ·Ğ°Ğ²ĞµÑ€ÑˆĞµĞ½Ğ¸Ğ¸ ÑĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚Ğ°."""

    total_experiments = results.get("total_experiments", 0)
    best_r2 = results.get("summary", {}).get("best_r2", 0)
    best_model = results.get("best_model", {}).get("run_id", "unknown")

    # Ğ¡Ğ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ğµ Ğ¿Ğ¾Ğ´Ñ€Ğ¾Ğ±Ğ½Ğ¾Ğ³Ğ¾ ÑÑ‚Ğ°Ñ‚ÑƒÑĞ° Ğ´Ğ»Ñ Airflow UI
    notification = {
        "status": "SUCCESS" if best_r2 > 0.8 else "WARNING",
        "summary": f"Ğ—Ğ°Ğ²ĞµÑ€ÑˆĞµĞ½Ğ¾ {total_experiments} ÑĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚Ğ¾Ğ²",
        "best_result": f"Ğ›ÑƒÑ‡ÑˆĞ°Ñ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ: {best_model} (RÂ²={best_r2:.4f})",
        "timestamp": datetime.now().isoformat(),
    }

    # Ğ›Ğ¾Ğ³Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ´Ğ»Ñ Ğ¾Ñ‚Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ñ Ğ² Airflow UI
    logger.info("=" * 60)
    logger.info("ğŸ‰ Ğ­ĞšĞ¡ĞŸĞ•Ğ Ğ˜ĞœĞ•ĞĞ¢Ğ« Ğ—ĞĞ’Ğ•Ğ Ğ¨Ğ•ĞĞ«")
    logger.info("=" * 60)
    logger.info(f"ğŸ“Š Ğ’ÑĞµĞ³Ğ¾ ÑĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚Ğ¾Ğ²: {total_experiments}")
    logger.info(f"ğŸ† Ğ›ÑƒÑ‡ÑˆĞ¸Ğ¹ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚: RÂ² = {best_r2:.4f}")
    logger.info(f"ğŸ¤– Ğ›ÑƒÑ‡ÑˆĞ°Ñ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ: {best_model}")
    logger.info("=" * 60)

    return notification
```

### **2. MLflow UI Ğ¸Ğ½Ñ‚ĞµĞ³Ñ€Ğ°Ñ†Ğ¸Ñ**

```python
# ĞĞ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¾Ğµ ÑĞ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ğµ ÑĞ²Ğ¾Ğ´Ğ½Ñ‹Ñ… run'Ğ¾Ğ² Ğ² MLflow
@task
def create_mlflow_summary(aggregated_results: dict) -> dict:
    """Ğ¡Ğ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ğµ ÑĞ²Ğ¾Ğ´Ğ½Ğ¾Ğ³Ğ¾ run'Ğ° Ğ² MLflow Ñ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ğ°Ğ¼Ğ¸ Ğ²ÑĞµÑ… ÑĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚Ğ¾Ğ²."""

    import mlflow

    mlflow.set_experiment("boston_housing_summary")

    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")

    with mlflow.start_run(run_name=f"batch_summary_{timestamp}"):

        # Ğ›Ğ¾Ğ³Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ°Ğ³Ñ€ĞµĞ³Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ¼ĞµÑ‚Ñ€Ğ¸Ğº
        summary = aggregated_results["summary"]
        mlflow.log_metric("experiments_count", aggregated_results["total_experiments"])
        mlflow.log_metric("best_r2_score", summary["best_r2"])
        mlflow.log_metric("mean_r2_score", summary["mean_r2"])
        mlflow.log_metric("std_r2_score", summary["std_r2"])
        mlflow.log_metric("worst_r2_score", summary["worst_r2"])

        # Ğ¡Ğ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ğµ Ğ²Ğ¸Ğ·ÑƒĞ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ğ¾Ğ²
        results_df = pd.read_csv(aggregated_results["results_path"])

        # Ğ“Ñ€Ğ°Ñ„Ğ¸Ğº ÑÑ€Ğ°Ğ²Ğ½ĞµĞ½Ğ¸Ñ Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹
        fig, ax = plt.subplots(figsize=(12, 8))
        results_df.plot(x='run_id', y='r2_score', kind='bar', ax=ax)
        ax.set_title('Ğ¡Ñ€Ğ°Ğ²Ğ½ĞµĞ½Ğ¸Ğµ RÂ² Score Ğ¿Ğ¾ Ğ¼Ğ¾Ğ´ĞµĞ»ÑĞ¼')
        ax.set_xlabel('ĞœĞ¾Ğ´ĞµĞ»ÑŒ')
        ax.set_ylabel('RÂ² Score')
        plt.xticks(rotation=45, ha='right')
        plt.tight_layout()

        plot_path = "/tmp/models_comparison.png"
        plt.savefig(plot_path, dpi=300, bbox_inches='tight')
        mlflow.log_artifact(plot_path, "plots")

        # Ğ¢ĞµĞ³Ğ¸ Ğ´Ğ»Ñ Ğ½Ğ°Ğ²Ğ¸Ğ³Ğ°Ñ†Ğ¸Ğ¸
        mlflow.set_tag("experiment_type", "batch_comparison")
        mlflow.set_tag("source", "airflow_batch")
        mlflow.set_tag("algorithms_count", len(results_df))

        logger.success("âœ… Ğ¡Ğ²Ğ¾Ğ´Ğ½Ñ‹Ğ¹ Ğ¾Ñ‚Ñ‡Ñ‘Ñ‚ ÑĞ¾Ğ·Ğ´Ğ°Ğ½ Ğ² MLflow")

        return {
            "mlflow_run_id": mlflow.active_run().info.run_id,
            "summary_created": True
        }
```

### **3. Ğ˜Ğ½Ñ‚ĞµĞ³Ñ€Ğ°Ñ†Ğ¸Ñ Ñ Ğ²Ğ½ĞµÑˆĞ½Ğ¸Ğ¼Ğ¸ ÑĞ¸ÑÑ‚ĞµĞ¼Ğ°Ğ¼Ğ¸**

```python
# ĞĞ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ° webhook'Ğ¾Ğ² Ğ´Ğ»Ñ Ğ²Ğ½ĞµÑˆĞ½Ğ¸Ñ… ÑƒĞ²ĞµĞ´Ğ¾Ğ¼Ğ»ĞµĞ½Ğ¸Ğ¹
@task
def send_webhook_notification(results: dict) -> dict:
    """ĞÑ‚Ğ¿Ñ€Ğ°Ğ²ĞºĞ° webhook ÑƒĞ²ĞµĞ´Ğ¾Ğ¼Ğ»ĞµĞ½Ğ¸Ñ Ğ²Ğ¾ Ğ²Ğ½ĞµÑˆĞ½Ğ¸Ğµ ÑĞ¸ÑÑ‚ĞµĞ¼Ñ‹."""

    import requests

    webhook_url = os.environ.get("WEBHOOK_URL")
    if not webhook_url:
        logger.warning("WEBHOOK_URL Ğ½Ğµ Ğ½Ğ°ÑÑ‚Ñ€Ğ¾ĞµĞ½, Ğ¿Ñ€Ğ¾Ğ¿ÑƒÑĞºĞ°ĞµĞ¼ Ğ²Ğ½ĞµÑˆĞ½Ğ¸Ğµ ÑƒĞ²ĞµĞ´Ğ¾Ğ¼Ğ»ĞµĞ½Ğ¸Ñ")
        return {"status": "skipped"}

    payload = {
        "text": f"ğŸ¤– ML Pipeline Ğ·Ğ°Ğ²ĞµÑ€ÑˆÑ‘Ğ½",
        "attachments": [{
            "color": "good" if results["summary"]["best_r2"] > 0.8 else "warning",
            "fields": [
                {
                    "title": "Ğ­ĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚Ğ¾Ğ²",
                    "value": str(results["total_experiments"]),
                    "short": True
                },
                {
                    "title": "Ğ›ÑƒÑ‡ÑˆĞ¸Ğ¹ RÂ²",
                    "value": f"{results['summary']['best_r2']:.4f}",
                    "short": True
                },
                {
                    "title": "Ğ›ÑƒÑ‡ÑˆĞ°Ñ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ",
                    "value": results["best_model"]["run_id"],
                    "short": False
                }
            ]
        }]
    }

    try:
        response = requests.post(webhook_url, json=payload, timeout=10)
        response.raise_for_status()
        logger.success("âœ… Webhook ÑƒĞ²ĞµĞ´Ğ¾Ğ¼Ğ»ĞµĞ½Ğ¸Ğµ Ğ¾Ñ‚Ğ¿Ñ€Ğ°Ğ²Ğ»ĞµĞ½Ğ¾")
        return {"status": "sent", "response_code": response.status_code}
    except requests.RequestException as e:
        logger.warning(f"âš ï¸ ĞÑˆĞ¸Ğ±ĞºĞ° Ğ¾Ñ‚Ğ¿Ñ€Ğ°Ğ²ĞºĞ¸ webhook: {e}")
        return {"status": "error", "error": str(e)}
```

### 7.4 Ğ¢ĞµÑÑ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ²Ğ¾ÑĞ¿Ñ€Ğ¾Ğ¸Ğ·Ğ²Ğ¾Ğ´Ğ¸Ğ¼Ğ¾ÑÑ‚Ğ¸

**Ğ¡Ğ¸ÑÑ‚ĞµĞ¼Ğ° Ğ¾Ğ±ĞµÑĞ¿ĞµÑ‡ĞµĞ½Ğ¸Ñ Ğ²Ğ¾ÑĞ¿Ñ€Ğ¾Ğ¸Ğ·Ğ²Ğ¾Ğ´Ğ¸Ğ¼Ğ¾ÑÑ‚Ğ¸ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ğ¾Ğ²:**

### **1. Ğ”ĞµÑ‚ĞµÑ€Ğ¼Ğ¸Ğ½Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ğ¾ÑÑ‚ÑŒ Ñ‡ĞµÑ€ĞµĞ· Ñ„Ğ¸ĞºÑĞ°Ñ†Ğ¸Ñ seed'Ğ¾Ğ²**

```python
# Ğ“Ğ»Ğ¾Ğ±Ğ°Ğ»ÑŒĞ½Ğ°Ñ Ğ½Ğ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ° random seed Ğ²Ğ¾ Ğ²ÑĞµÑ… ÑĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚Ğ°Ñ…
def set_reproducible_environment(random_state: int = 42):
    """ĞĞ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ° Ğ¾ĞºÑ€ÑƒĞ¶ĞµĞ½Ğ¸Ñ Ğ´Ğ»Ñ Ğ²Ğ¾ÑĞ¿Ñ€Ğ¾Ğ¸Ğ·Ğ²Ğ¾Ğ´Ğ¸Ğ¼Ñ‹Ñ… Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ğ¾Ğ²."""

    import random
    import numpy as np
    import os

    # Python random
    random.seed(random_state)

    # NumPy random  
    np.random.seed(random_state)

    # Scikit-learn Ğ¿Ğ¾ ÑƒĞ¼Ğ¾Ğ»Ñ‡Ğ°Ğ½Ğ¸Ñ
    os.environ['PYTHONHASHSEED'] = str(random_state)

    logger.info(f"ğŸ”’ Ğ£ÑÑ‚Ğ°Ğ½Ğ¾Ğ²Ğ»ĞµĞ½ random_state={random_state} Ğ´Ğ»Ñ Ğ²Ğ¾ÑĞ¿Ñ€Ğ¾Ğ¸Ğ·Ğ²Ğ¾Ğ´Ğ¸Ğ¼Ğ¾ÑÑ‚Ğ¸")

# ĞŸÑ€Ğ¸Ğ¼ĞµĞ½ĞµĞ½Ğ¸Ğµ Ğ²Ğ¾ Ğ²ÑĞµÑ… Ğ¼Ğ¾Ğ´ĞµĞ»ÑÑ…
BASE_EXPERIMENT_CONFIG = {
    "random_state": 42,
    "test_size": 0.2,
}

# Ğ’ÑĞµ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ Ğ½Ğ°ÑĞ»ĞµĞ´ÑƒÑÑ‚ Ğ´ĞµÑ‚ĞµÑ€Ğ¼Ğ¸Ğ½Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ğ¾ÑÑ‚ÑŒ
def create_model(model_name: str, params: dict):
    """Ğ¡Ğ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ğµ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ Ñ Ğ¿Ñ€Ğ¸Ğ½ÑƒĞ´Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾Ğ¹ ÑƒÑÑ‚Ğ°Ğ½Ğ¾Ğ²ĞºĞ¾Ğ¹ random_state."""

    # ĞŸÑ€Ğ¸Ğ½ÑƒĞ´Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ Ğ´Ğ¾Ğ±Ğ°Ğ²Ğ»ÑĞµĞ¼ random_state ĞµÑĞ»Ğ¸ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ ĞµĞ³Ğ¾ Ğ¿Ğ¾Ğ´Ğ´ĞµÑ€Ğ¶Ğ¸Ğ²Ğ°ĞµÑ‚
    if hasattr(model_class, '_check_n_features') and 'random_state' not in params:
        params['random_state'] = BASE_EXPERIMENT_CONFIG['random_state']

    return model_class(**params)
```

### **2. ĞšÑÑˆĞ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ´Ğ»Ñ Ğ¿Ñ€Ğ¾Ğ²ĞµÑ€ĞºĞ¸ Ğ¸Ğ´ĞµĞ½Ñ‚Ğ¸Ñ‡Ğ½Ğ¾ÑÑ‚Ğ¸**

```python
class ReproducibilityTester:
    """ĞšĞ»Ğ°ÑÑ Ğ´Ğ»Ñ Ñ‚ĞµÑÑ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ Ğ²Ğ¾ÑĞ¿Ñ€Ğ¾Ğ¸Ğ·Ğ²Ğ¾Ğ´Ğ¸Ğ¼Ğ¾ÑÑ‚Ğ¸ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ğ¾Ğ²."""

    def __init__(self, cache: MinIOCache):
        self.cache = cache

    def test_model_reproducibility(
        self,
        model_name: str,
        params: dict,
        data_path: str,
        tolerance: float = 1e-6
    ) -> dict:
        """
        Ğ¢ĞµÑÑ‚Ğ¸Ñ€ÑƒĞµÑ‚ Ğ²Ğ¾ÑĞ¿Ñ€Ğ¾Ğ¸Ğ·Ğ²Ğ¾Ğ´Ğ¸Ğ¼Ğ¾ÑÑ‚ÑŒ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ Ğ¿ÑƒÑ‚Ñ‘Ğ¼ Ğ´Ğ²Ğ¾Ğ¹Ğ½Ğ¾Ğ³Ğ¾ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ.

        Returns:
            dict Ñ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ğ°Ğ¼Ğ¸ Ñ‚ĞµÑÑ‚Ğ° Ğ²Ğ¾ÑĞ¿Ñ€Ğ¾Ğ¸Ğ·Ğ²Ğ¾Ğ´Ğ¸Ğ¼Ğ¾ÑÑ‚Ğ¸
        """
        logger.info(f"ğŸ§ª Ğ¢ĞµÑÑ‚ Ğ²Ğ¾ÑĞ¿Ñ€Ğ¾Ğ¸Ğ·Ğ²Ğ¾Ğ´Ğ¸Ğ¼Ğ¾ÑÑ‚Ğ¸: {model_name}")

        results = []

        # ĞĞ±ÑƒÑ‡Ğ°ĞµĞ¼ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ Ğ´Ğ²Ğ°Ğ¶Ğ´Ñ‹ Ñ Ğ¾Ğ´Ğ¸Ğ½Ğ°ĞºĞ¾Ğ²Ñ‹Ğ¼Ğ¸ Ğ¿Ğ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ğ°Ğ¼Ğ¸
        for run_num in [1, 2]:
            logger.info(f"   Ğ—Ğ°Ğ¿ÑƒÑĞº #{run_num}")

            # ĞĞ±ÑƒÑ‡ĞµĞ½Ğ¸Ğµ
            model = create_model(model_name, params)
            X_train, X_test, y_train, y_test = load_and_split_data(data_path)

            set_reproducible_environment(params.get('random_state', 42))
            model.fit(X_train, y_train)
            y_pred = model.predict(X_test)

            metrics = {
                "r2_score": r2_score(y_test, y_pred),
                "rmse": np.sqrt(mean_squared_error(y_test, y_pred)),
                "predictions_hash": hashlib.md5(y_pred.tobytes()).hexdigest()
            }

            results.append(metrics)

        # Ğ¡Ñ€Ğ°Ğ²Ğ½ĞµĞ½Ğ¸Ğµ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ğ¾Ğ²
        r2_diff = abs(results[0]["r2_score"] - results[1]["r2_score"])
        rmse_diff = abs(results[0]["rmse"] - results[1]["rmse"])
        predictions_identical = results[0]["predictions_hash"] == results[1]["predictions_hash"]

        is_reproducible = (
            r2_diff < tolerance and
            rmse_diff < tolerance and
            predictions_identical
        )

        test_result = {
            "model_name": model_name,
            "is_reproducible": is_reproducible,
            "r2_difference": r2_diff,
            "rmse_difference": rmse_diff,
            "predictions_identical": predictions_identical,
            "tolerance": tolerance,
            "run1_results": results[0],
            "run2_results": results[1],
        }

        if is_reproducible:
            logger.success(f"âœ… ĞœĞ¾Ğ´ĞµĞ»ÑŒ {model_name} Ğ²Ğ¾ÑĞ¿Ñ€Ğ¾Ğ¸Ğ·Ğ²Ğ¾Ğ´Ğ¸Ğ¼Ğ°")
        else:
            logger.warning(f"âš ï¸ ĞœĞ¾Ğ´ĞµĞ»ÑŒ {model_name} ĞĞ• Ğ²Ğ¾ÑĞ¿Ñ€Ğ¾Ğ¸Ğ·Ğ²Ğ¾Ğ´Ğ¸Ğ¼Ğ°")
            logger.warning(f"   RÂ² Ñ€Ğ°Ğ·Ğ½Ğ¾ÑÑ‚ÑŒ: {r2_diff}")
            logger.warning(f"   RMSE Ñ€Ğ°Ğ·Ğ½Ğ¾ÑÑ‚ÑŒ: {rmse_diff}")

        return test_result

# Ğ˜Ğ½Ñ‚ĞµĞ³Ñ€Ğ°Ñ†Ğ¸Ñ Ğ² Airflow DAG
@task
def test_reproducibility() -> dict:
    """Task Ğ´Ğ»Ñ Ñ‚ĞµÑÑ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ Ğ²Ğ¾ÑĞ¿Ñ€Ğ¾Ğ¸Ğ·Ğ²Ğ¾Ğ´Ğ¸Ğ¼Ğ¾ÑÑ‚Ğ¸ ĞºĞ»ÑÑ‡ĞµĞ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹."""

    cache = MinIOCache(bucket_name="reproducibility-tests")
    tester = ReproducibilityTester(cache)

    # Ğ¢ĞµÑÑ‚Ğ¸Ñ€ÑƒĞµĞ¼ Ñ‚Ğ¾Ğ¿-3 Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸
    test_models = [
        {"name": "random_forest", "params": {"n_estimators": 100, "random_state": 42}},
        {"name": "gradient_boosting", "params": {"n_estimators": 100, "random_state": 42}},
        {"name": "ridge", "params": {"alpha": 1.0, "random_state": 42}},
    ]

    test_results = []
    for model_config in test_models:
        result = tester.test_model_reproducibility(
            model_config["name"],
            model_config["params"],
            "/opt/airflow/data/raw/housing.csv"
        )
        test_results.append(result)

    # Ğ¡Ğ²Ğ¾Ğ´Ğ½Ğ°Ñ ÑÑ‚Ğ°Ñ‚Ğ¸ÑÑ‚Ğ¸ĞºĞ°
    reproducible_count = sum(1 for r in test_results if r["is_reproducible"])
    total_count = len(test_results)

    summary = {
        "total_tests": total_count,
        "reproducible_count": reproducible_count,
        "reproducibility_rate": reproducible_count / total_count,
        "test_results": test_results,
    }

    logger.info(f"ğŸ§ª Ğ¢ĞµÑÑ‚Ñ‹ Ğ²Ğ¾ÑĞ¿Ñ€Ğ¾Ğ¸Ğ·Ğ²Ğ¾Ğ´Ğ¸Ğ¼Ğ¾ÑÑ‚Ğ¸: {reproducible_count}/{total_count}")

    return summary
```

### **3. Ğ’ĞµÑ€ÑĞ¸Ğ¾Ğ½Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ñ‡ĞµÑ€ĞµĞ· DVC**

```python
@task
def validate_data_version() -> dict:
    """ĞŸÑ€Ğ¾Ğ²ĞµÑ€ĞºĞ° Ğ²ĞµÑ€ÑĞ¸Ğ¸ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ´Ğ»Ñ Ğ¾Ğ±ĞµÑĞ¿ĞµÑ‡ĞµĞ½Ğ¸Ñ Ğ²Ğ¾ÑĞ¿Ñ€Ğ¾Ğ¸Ğ·Ğ²Ğ¾Ğ´Ğ¸Ğ¼Ğ¾ÑÑ‚Ğ¸."""

    import subprocess

    try:
        # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼ ÑÑ‚Ğ°Ñ‚ÑƒÑ DVC
        result = subprocess.run(
            ["dvc", "status"],
            cwd="/opt/airflow",
            capture_output=True,
            text=True,
            timeout=30
        )

        if result.returncode == 0:
            if not result.stdout.strip():
                logger.success("âœ… DVC: Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ Ğ°ĞºÑ‚ÑƒĞ°Ğ»ÑŒĞ½Ñ‹")
                data_status = "up_to_date"
            else:
                logger.warning("âš ï¸ DVC: Ğ¾Ğ±Ğ½Ğ°Ñ€ÑƒĞ¶ĞµĞ½Ñ‹ Ğ¸Ğ·Ğ¼ĞµĞ½ĞµĞ½Ğ¸Ñ Ğ² Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…")
                logger.info(f"DVC ÑÑ‚Ğ°Ñ‚ÑƒÑ:\n{result.stdout}")
                data_status = "modified"
        else:
            logger.error(f"âŒ DVC Ğ¾ÑˆĞ¸Ğ±ĞºĞ°: {result.stderr}")
            data_status = "error"

        # ĞŸĞ¾Ğ»ÑƒÑ‡Ğ°ĞµĞ¼ Ñ…ÑÑˆ Ñ‚ĞµĞºÑƒÑ‰Ğ¸Ñ… Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…
        data_path = "/opt/airflow/data/raw/housing.csv"
        with open(data_path, "rb") as f:
            data_hash = hashlib.md5(f.read()).hexdigest()

        return {
            "data_status": data_status,
            "data_hash": data_hash,
            "dvc_output": result.stdout,
        }

    except subprocess.TimeoutExpired:
        logger.error("âŒ DVC ĞºĞ¾Ğ¼Ğ°Ğ½Ğ´Ğ° Ğ¿Ñ€ĞµĞ²Ñ‹ÑĞ¸Ğ»Ğ° Ñ‚Ğ°Ğ¹Ğ¼Ğ°ÑƒÑ‚")
        return {"data_status": "timeout"}
    except FileNotFoundError:
        logger.warning("âš ï¸ DVC Ğ½Ğµ ÑƒÑÑ‚Ğ°Ğ½Ğ¾Ğ²Ğ»ĞµĞ½")
        return {"data_status": "dvc_not_found"}
```

---

## ğŸ“š Ğ”Ğ¾ĞºÑƒĞ¼ĞµĞ½Ñ‚Ğ°Ñ†Ğ¸Ñ Ğ¿Ñ€Ğ¾ĞµĞºÑ‚Ğ°

ĞŸĞ¾Ğ´Ñ€Ğ¾Ğ±Ğ½Ñ‹Ğµ Ñ€ÑƒĞºĞ¾Ğ²Ğ¾Ğ´ÑÑ‚Ğ²Ğ° Ğ½Ğ°Ñ…Ğ¾Ğ´ÑÑ‚ÑÑ Ğ² Ğ´Ğ¸Ñ€ĞµĞºÑ‚Ğ¾Ñ€Ğ¸Ğ¸ `docs/guides/`:

| Ğ¤Ğ°Ğ¹Ğ» | ĞĞ¿Ğ¸ÑĞ°Ğ½Ğ¸Ğµ |
|------|----------|
| [`MLFLOW+DVC+MINIO.md`](../docs/guides/MLFLOW+DVC+MINIO.md) | ĞŸĞ¾Ğ»Ğ½Ğ¾Ğµ Ñ€ÑƒĞºĞ¾Ğ²Ğ¾Ğ´ÑÑ‚Ğ²Ğ¾ Ğ¿Ğ¾ MLflow + DVC + MinIO |
| [`MINIO+DVC.md`](../docs/guides/MINIO+DVC.md) | ĞĞ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ° MinIO Ğ¸ DVC |
| [`PRE-COMMIT.md`](../docs/guides/PRE-COMMIT.md) | ĞĞ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ° pre-commit Ñ…ÑƒĞºĞ¾Ğ² |
| [`DOCKER.md`](../docs/guides/DOCKER.md) | Ğ ÑƒĞºĞ¾Ğ²Ğ¾Ğ´ÑÑ‚Ğ²Ğ¾ Ğ¿Ğ¾ Docker Ğ¸ ĞºĞ¾Ğ½Ñ‚ĞµĞ¹Ğ½ĞµÑ€Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸ |
| [`ENV.md`](../docs/guides/ENV.md) | ĞĞ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ° Ğ¿ĞµÑ€ĞµĞ¼ĞµĞ½Ğ½Ñ‹Ñ… Ğ¾ĞºÑ€ÑƒĞ¶ĞµĞ½Ğ¸Ñ |
| [`EXPERIMENTS.md`](../docs/guides/EXPERIMENTS.md) | Ğ ÑƒĞºĞ¾Ğ²Ğ¾Ğ´ÑÑ‚Ğ²Ğ¾ Ğ¿Ğ¾ Ğ¿Ñ€Ğ¾Ğ²ĞµĞ´ĞµĞ½Ğ¸Ñ ÑĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚Ğ¾Ğ² |
| [`EXPERIMENTS-ADVANCED.md`](../docs/guides/EXPERIMENTS-ADVANCED.md) | ĞŸÑ€Ğ¾Ğ´Ğ²Ğ¸Ğ½ÑƒÑ‚Ñ‹Ğµ Ñ‚ĞµÑ…Ğ½Ğ¸ĞºĞ¸ ÑĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚Ğ¾Ğ² |
| [`TRACKING-INTEGRATION.md`](../docs/guides/TRACKING-INTEGRATION.md) | Ğ˜Ğ½Ñ‚ĞµĞ³Ñ€Ğ°Ñ†Ğ¸Ñ ÑĞ¸ÑÑ‚ĞµĞ¼Ñ‹ Ñ‚Ñ€ĞµĞºĞ¸Ğ½Ğ³Ğ° |
| [`airflow_ml_pipeline.md`](../docs/guides/airflow_ml_pipeline.md) | Airflow ML Ğ¿Ğ°Ğ¹Ğ¿Ğ»Ğ°Ğ¹Ğ½Ñ‹ |

---

## ğŸ“ Ğ—Ğ°ĞºĞ»ÑÑ‡ĞµĞ½Ğ¸Ğµ

Ğ’ Ñ€Ğ°Ğ¼ĞºĞ°Ñ… Ğ»Ğ°Ğ±Ğ¾Ñ€Ğ°Ñ‚Ğ¾Ñ€Ğ½Ğ¾Ğ¹ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ñ‹ Ğ²Ñ‹Ğ¿Ğ¾Ğ»Ğ½ĞµĞ½Ñ‹ Ğ²ÑĞµ Ğ¿Ğ¾ÑÑ‚Ğ°Ğ²Ğ»ĞµĞ½Ğ½Ñ‹Ğµ Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ¸:

### 1. ĞĞ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ° Ğ²Ñ‹Ğ±Ñ€Ğ°Ğ½Ğ½Ğ¾Ğ³Ğ¾ Ğ¸Ğ½ÑÑ‚Ñ€ÑƒĞ¼ĞµĞ½Ñ‚Ğ° Ñ‚Ñ€ĞµĞºĞ¸Ğ½Ğ³Ğ°

**ĞÑĞ½Ğ¾Ğ²Ğ½Ñ‹Ğµ Ğ´Ğ¾ÑÑ‚Ğ¸Ğ¶ĞµĞ½Ğ¸Ñ:**
- Ğ£ÑÑ‚Ğ°Ğ½Ğ¾Ğ²Ğ»ĞµĞ½ MLflow 3.7.0+ Ñ Ğ¿Ğ¾Ğ´Ğ´ĞµÑ€Ğ¶ĞºĞ¾Ğ¹ Ğ°ÑƒÑ‚ĞµĞ½Ñ‚Ğ¸Ñ„Ğ¸ĞºĞ°Ñ†Ğ¸Ğ¸
- Ğ Ğ°Ğ·Ğ²Ñ‘Ñ€Ğ½ÑƒÑ‚Ğ¾ Ğ¾Ğ±Ğ»Ğ°Ñ‡Ğ½Ğ¾Ğµ Ñ…Ñ€Ğ°Ğ½Ğ¸Ğ»Ğ¸Ñ‰Ğµ MinIO Ğ´Ğ»Ñ Ğ°Ñ€Ñ‚ĞµÑ„Ğ°ĞºÑ‚Ğ¾Ğ²
- ĞĞ°ÑÑ‚Ñ€Ğ¾ĞµĞ½Ğ° Ğ´Ğ²ÑƒÑ…ÑƒÑ€Ğ¾Ğ²Ğ½ĞµĞ²Ğ°Ñ Ğ°ÑƒÑ‚ĞµĞ½Ñ‚Ğ¸Ñ„Ğ¸ĞºĞ°Ñ†Ğ¸Ñ (Nginx + MLflow + MinIO)
- ĞŸÑ€Ğ¾Ğ²ĞµĞ´ĞµĞ½Ğ¾ 19 ÑĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚Ğ¾Ğ² Ñ Ñ€Ğ°Ğ·Ğ»Ğ¸Ñ‡Ğ½Ñ‹Ğ¼Ğ¸ Ğ°Ğ»Ğ³Ğ¾Ñ€Ğ¸Ñ‚Ğ¼Ğ°Ğ¼Ğ¸
- Ğ˜Ğ½Ñ‚ĞµĞ³Ñ€Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½ MLflow Ğ² Python ĞºĞ¾Ğ´ (5 Ğ´ĞµĞºĞ¾Ñ€Ğ°Ñ‚Ğ¾Ñ€Ğ¾Ğ², 2 ĞºĞ¾Ğ½Ñ‚ĞµĞºÑÑ‚Ğ½Ñ‹Ñ… Ğ¼ĞµĞ½ĞµĞ´Ğ¶ĞµÑ€Ğ°, 9 ÑƒÑ‚Ğ¸Ğ»Ğ¸Ñ‚)

### 2. ĞĞ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ° Ğ²Ñ‹Ğ±Ñ€Ğ°Ğ½Ğ½Ğ¾Ğ³Ğ¾ Ğ¸Ğ½ÑÑ‚Ñ€ÑƒĞ¼ĞµĞ½Ñ‚Ğ° Ğ¾Ñ€ĞºĞµÑÑ‚Ñ€Ğ°Ñ†Ğ¸Ğ¸

**âœ… Ğ£ÑÑ‚Ğ°Ğ½Ğ¾Ğ²Ğ»ĞµĞ½ Ğ¸ Ğ½Ğ°ÑÑ‚Ñ€Ğ¾ĞµĞ½ Apache Airflow 2.8.1**
- Ğ Ğ°Ğ·Ğ²Ñ‘Ñ€Ğ½ÑƒÑ‚ Ñ‡ĞµÑ€ĞµĞ· Docker Compose Ñ CeleryExecutor
- ĞĞ°ÑÑ‚Ñ€Ğ¾ĞµĞ½Ğ° Ğ¸Ğ½Ñ‚ĞµĞ³Ñ€Ğ°Ñ†Ğ¸Ñ Ñ PostgreSQL (Ğ¼ĞµÑ‚Ğ°Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ) Ğ¸ Redis (Ğ±Ñ€Ğ¾ĞºĞµÑ€)
- Ğ˜Ğ½Ñ‚ĞµĞ³Ñ€Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½ Ñ MLflow Ğ¸ MinIO

**âœ… Ğ¡Ğ¾Ğ·Ğ´Ğ°Ğ½ workflow Ğ´Ğ»Ñ ML Ğ¿Ğ°Ğ¹Ğ¿Ğ»Ğ°Ğ¹Ğ½Ğ°**
- Ğ ĞµĞ°Ğ»Ğ¸Ğ·Ğ¾Ğ²Ğ°Ğ½Ğ¾ 3 DAG Ñ Ñ€Ğ°Ğ·Ğ»Ğ¸Ñ‡Ğ½Ñ‹Ğ¼Ğ¸ Ğ¿Ğ°Ñ‚Ñ‚ĞµÑ€Ğ½Ğ°Ğ¼Ğ¸:
  - `boston_housing_simple` â€” Ğ¿Ğ¾ÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ÑŒĞ½Ñ‹Ğ¹ Ğ¿Ğ°Ğ¹Ğ¿Ğ»Ğ°Ğ¹Ğ½ Ğ´Ğ»Ñ Ğ¿Ñ€Ğ¾Ñ‚Ğ¾Ñ‚Ğ¸Ğ¿Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ
  - `boston_housing_experiments` â€” Ğ¿Ğ°Ñ€Ğ°Ğ»Ğ»ĞµĞ»ÑŒĞ½Ğ¾Ğµ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ğµ 19 Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹
  - `boston_housing_cached` â€” Ğ¿Ğ°Ğ¹Ğ¿Ğ»Ğ°Ğ¹Ğ½ Ñ Ğ¸Ğ½Ñ‚ĞµĞ»Ğ»ĞµĞºÑ‚ÑƒĞ°Ğ»ÑŒĞ½Ñ‹Ğ¼ ĞºÑÑˆĞ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸ĞµĞ¼

**âœ… ĞĞ°ÑÑ‚Ñ€Ğ¾ĞµĞ½Ñ‹ Ğ·Ğ°Ğ²Ğ¸ÑĞ¸Ğ¼Ğ¾ÑÑ‚Ğ¸ Ğ¼ĞµĞ¶Ğ´Ñƒ ÑÑ‚Ğ°Ğ¿Ğ°Ğ¼Ğ¸**
- Ğ›Ğ¸Ğ½ĞµĞ¹Ğ½Ñ‹Ğµ Ğ·Ğ°Ğ²Ğ¸ÑĞ¸Ğ¼Ğ¾ÑÑ‚Ğ¸ (Ğ¿Ğ¾ÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ÑŒĞ½Ğ¾Ğµ Ğ²Ñ‹Ğ¿Ğ¾Ğ»Ğ½ĞµĞ½Ğ¸Ğµ)
- ĞŸĞ°Ñ€Ğ°Ğ»Ğ»ĞµĞ»ÑŒĞ½Ñ‹Ğµ Ğ·Ğ°Ğ²Ğ¸ÑĞ¸Ğ¼Ğ¾ÑÑ‚Ğ¸ (Ñ‡ĞµÑ€ĞµĞ· `expand()` operator)
- Ğ£ÑĞ»Ğ¾Ğ²Ğ½Ñ‹Ğµ Ğ·Ğ°Ğ²Ğ¸ÑĞ¸Ğ¼Ğ¾ÑÑ‚Ğ¸ (Ñ‡ĞµÑ€ĞµĞ· `ShortCircuitOperator`)
- Trigger rules Ğ´Ğ»Ñ Ğ³Ğ¸Ğ±ĞºĞ¾Ğ¹ Ğ»Ğ¾Ğ³Ğ¸ĞºĞ¸ Ğ·Ğ°Ğ¿ÑƒÑĞºĞ°

**âœ… Ğ ĞµĞ°Ğ»Ğ¸Ğ·Ğ¾Ğ²Ğ°Ğ½Ğ¾ ĞºÑÑˆĞ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ¸ Ğ¿Ğ°Ñ€Ğ°Ğ»Ğ»ĞµĞ»ÑŒĞ½Ğ¾Ğµ Ğ²Ñ‹Ğ¿Ğ¾Ğ»Ğ½ĞµĞ½Ğ¸Ğµ**
- Ğ¡Ğ¸ÑÑ‚ĞµĞ¼Ğ° ĞºÑÑˆĞ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ Ğ½Ğ° Ğ±Ğ°Ğ·Ğµ MinIO Ñ Ğ¿Ñ€Ğ¾Ğ²ĞµÑ€ĞºĞ¾Ğ¹ MD5 Ñ…ÑÑˆĞµĞ¹
- ĞŸĞ°Ñ€Ğ°Ğ»Ğ»ĞµĞ»Ğ¸Ğ·Ğ¼ Ğ´Ğ¾ 8 Ğ·Ğ°Ğ´Ğ°Ñ‡ Ğ¾Ğ´Ğ½Ğ¾Ğ²Ñ€ĞµĞ¼ĞµĞ½Ğ½Ğ¾
- ĞĞ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ°Ñ Ğ¸Ğ½Ğ²Ğ°Ğ»Ğ¸Ğ´Ğ°Ñ†Ğ¸Ñ ĞºÑÑˆĞ° Ğ¿Ñ€Ğ¸ Ğ¸Ğ·Ğ¼ĞµĞ½ĞµĞ½Ğ¸Ğ¸ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ¸Ğ»Ğ¸ Ğ¿Ğ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ğ¾Ğ²

### 3. ĞĞ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ° Ğ²Ñ‹Ğ±Ñ€Ğ°Ğ½Ğ½Ğ¾Ğ³Ğ¾ Ğ¸Ğ½ÑÑ‚Ñ€ÑƒĞ¼ĞµĞ½Ñ‚Ğ° ĞºĞ¾Ğ½Ñ„Ğ¸Ğ³ÑƒÑ€Ğ°Ñ†Ğ¸Ğ¹

**âœ… ĞĞ°ÑÑ‚Ñ€Ğ¾ĞµĞ½ Ğ¸Ğ½ÑÑ‚Ñ€ÑƒĞ¼ĞµĞ½Ñ‚ Ğ´Ğ»Ñ ÑƒĞ¿Ñ€Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ñ ĞºĞ¾Ğ½Ñ„Ğ¸Ğ³ÑƒÑ€Ğ°Ñ†Ğ¸ÑĞ¼Ğ¸**
- Ğ ĞµĞ°Ğ»Ğ¸Ğ·Ğ¾Ğ²Ğ°Ğ½Ğ° ÑĞ¸ÑÑ‚ĞµĞ¼Ğ° Ğ½Ğ° Ğ±Ğ°Ğ·Ğµ **Hydra + Pydantic**
- Hydra Ğ¾Ğ±ĞµÑĞ¿ĞµÑ‡Ğ¸Ğ²Ğ°ĞµÑ‚ ĞºĞ¾Ğ¼Ğ¿Ğ¾Ğ·Ğ¸Ñ†Ğ¸Ñ YAML-ĞºĞ¾Ğ½Ñ„Ğ¸Ğ³ÑƒÑ€Ğ°Ñ†Ğ¸Ğ¹ Ğ¸ CLI Ğ¿ĞµÑ€ĞµĞ¾Ğ¿Ñ€ĞµĞ´ĞµĞ»ĞµĞ½Ğ¸Ğµ
- Pydantic Ğ³Ğ°Ñ€Ğ°Ğ½Ñ‚Ğ¸Ñ€ÑƒĞµÑ‚ ÑÑ‚Ñ€Ğ¾Ğ³ÑƒÑ Ğ²Ğ°Ğ»Ğ¸Ğ´Ğ°Ñ†Ğ¸Ñ Ñ‚Ğ¸Ğ¿Ğ¾Ğ² Ğ¸ Ğ¿Ğ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ğ¾Ğ²

**âœ… Ğ¡Ğ¾Ğ·Ğ´Ğ°Ğ½Ñ‹ ĞºĞ¾Ğ½Ñ„Ğ¸Ğ³ÑƒÑ€Ğ°Ñ†Ğ¸Ğ¸ Ğ´Ğ»Ñ Ñ€Ğ°Ğ·Ğ½Ñ‹Ñ… Ğ°Ğ»Ğ³Ğ¾Ñ€Ğ¸Ñ‚Ğ¼Ğ¾Ğ²**
- 14 YAML-ĞºĞ¾Ğ½Ñ„Ğ¸Ğ³ÑƒÑ€Ğ°Ñ†Ğ¸Ğ¹ Ğ² `conf/model/`:
  - 6 Ğ»Ğ¸Ğ½ĞµĞ¹Ğ½Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ (Linear Regression, Ridge, Lasso, ElasticNet, Huber, SGD)
  - 5 Ğ°Ğ½ÑĞ°Ğ¼Ğ±Ğ»ĞµĞ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ (Random Forest, Extra Trees, Gradient Boosting, AdaBoost, Bagging)
  - 3 Ğ´Ñ€ÑƒĞ³Ğ¸Ñ… Ğ°Ğ»Ğ³Ğ¾Ñ€Ğ¸Ñ‚Ğ¼Ğ° (Decision Tree, SVR, KNN)
- ĞšĞ°Ğ¶Ğ´Ğ°Ñ ĞºĞ¾Ğ½Ñ„Ğ¸Ğ³ÑƒÑ€Ğ°Ñ†Ğ¸Ñ ÑĞ¾Ğ´ĞµÑ€Ğ¶Ğ¸Ñ‚ Ğ´Ğ¾ĞºÑƒĞ¼ĞµĞ½Ñ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ğµ Ğ¿Ğ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ñ‹ Ñ Ğ·Ğ½Ğ°Ñ‡ĞµĞ½Ğ¸ÑĞ¼Ğ¸ Ğ¿Ğ¾ ÑƒĞ¼Ğ¾Ğ»Ñ‡Ğ°Ğ½Ğ¸Ñ

**âœ… ĞĞ°ÑÑ‚Ñ€Ğ¾ĞµĞ½Ğ° Ğ²Ğ°Ğ»Ğ¸Ğ´Ğ°Ñ†Ğ¸Ñ ĞºĞ¾Ğ½Ñ„Ğ¸Ğ³ÑƒÑ€Ğ°Ñ†Ğ¸Ğ¹**
- Ğ ĞµĞ°Ğ»Ğ¸Ğ·Ğ¾Ğ²Ğ°Ğ½Ñ‹ Pydantic ÑÑ…ĞµĞ¼Ñ‹ Ğ² `src/schemas/`:
  - Ğ¡Ñ‚Ñ€Ğ¾Ğ³Ğ°Ñ Ğ²Ğ°Ğ»Ğ¸Ğ´Ğ°Ñ†Ğ¸Ñ Ñ‚Ğ¸Ğ¿Ğ¾Ğ² Ğ´Ğ»Ñ Ğ²ÑĞµÑ… Ğ¿Ğ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ğ¾Ğ²
  - ĞĞ³Ñ€Ğ°Ğ½Ğ¸Ñ‡ĞµĞ½Ğ¸Ñ Ğ´Ğ¸Ğ°Ğ¿Ğ°Ğ·Ğ¾Ğ½Ğ¾Ğ² (`n_estimators >= 10`, `0 < alpha <= 1000`)
  - ĞšĞ°ÑÑ‚Ğ¾Ğ¼Ğ½Ñ‹Ğµ Ğ²Ğ°Ğ»Ğ¸Ğ´Ğ°Ñ‚Ğ¾Ñ€Ñ‹ Ñ‡ĞµÑ€ĞµĞ· `@field_validator`
  - ĞĞ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ°Ñ Ğ´Ğ¾ĞºÑƒĞ¼ĞµĞ½Ñ‚Ğ°Ñ†Ğ¸Ñ Ñ‡ĞµÑ€ĞµĞ· `Field(description=...)`

**âœ… Ğ¡Ğ¾Ğ·Ğ´Ğ°Ğ½Ğ° ÑĞ¸ÑÑ‚ĞµĞ¼Ğ° ĞºĞ¾Ğ¼Ğ¿Ğ¾Ğ·Ğ¸Ñ†Ğ¸Ğ¸ ĞºĞ¾Ğ½Ñ„Ğ¸Ğ³ÑƒÑ€Ğ°Ñ†Ğ¸Ğ¹**
- Hydra ĞºĞ¾Ğ¼Ğ¿Ğ¾Ğ·Ğ¸Ñ†Ğ¸Ñ Ñ‡ĞµÑ€ĞµĞ· `defaults` Ğ² `config.yaml`
- Ğ“Ñ€ÑƒĞ¿Ğ¿Ñ‹ ÑĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚Ğ¾Ğ² Ğ² `conf/experiment/`
- CLI Ğ¿ĞµÑ€ĞµĞ¾Ğ¿Ñ€ĞµĞ´ĞµĞ»ĞµĞ½Ğ¸Ğµ: `model=ridge model.alpha=0.5`
- Multirun Ñ€ĞµĞ¶Ğ¸Ğ¼: `--multirun model=ridge,lasso,elastic_net`

### 4. Ğ˜Ğ½Ñ‚ĞµĞ³Ñ€Ğ°Ñ†Ğ¸Ñ Ğ¸ Ñ‚ĞµÑÑ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ

**âœ… Ğ˜Ğ½Ñ‚ĞµĞ³Ñ€Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ñ‹ Ğ²Ñ‹Ğ±Ñ€Ğ°Ğ½Ğ½Ñ‹Ğµ Ğ¸Ğ½ÑÑ‚Ñ€ÑƒĞ¼ĞµĞ½Ñ‚Ñ‹**
- ĞŸĞ¾Ğ»Ğ½Ğ°Ñ Ğ¸Ğ½Ñ‚ĞµĞ³Ñ€Ğ°Ñ†Ğ¸Ñ Airflow + MLflow + MinIO + Hydra
- Ğ•Ğ´Ğ¸Ğ½Ñ‹Ğµ Ğ¿ĞµÑ€ĞµĞ¼ĞµĞ½Ğ½Ñ‹Ğµ Ğ¾ĞºÑ€ÑƒĞ¶ĞµĞ½Ğ¸Ñ Ñ‡ĞµÑ€ĞµĞ· `.env`
- Docker Compose Ğ¾Ñ€ĞºĞµÑÑ‚Ñ€Ğ°Ñ†Ğ¸Ñ 10 ÑĞµÑ€Ğ²Ğ¸ÑĞ¾Ğ²
- ĞĞ±Ñ‰Ğ°Ñ Ğ°ÑƒÑ‚ĞµĞ½Ñ‚Ğ¸Ñ„Ğ¸ĞºĞ°Ñ†Ğ¸Ñ Ñ‡ĞµÑ€ĞµĞ· Nginx

**âœ… Ğ¡Ğ¾Ğ·Ğ´Ğ°Ğ½Ğ° ÑĞ¸ÑÑ‚ĞµĞ¼Ğ° Ğ¼Ğ¾Ğ½Ğ¸Ñ‚Ğ¾Ñ€Ğ¸Ğ½Ğ³Ğ° Ğ²Ñ‹Ğ¿Ğ¾Ğ»Ğ½ĞµĞ½Ğ¸Ñ**
- Ğ£Ñ€Ğ¾Ğ²ĞµĞ½ÑŒ 1: Ğ¡Ñ‚Ñ€ÑƒĞºÑ‚ÑƒÑ€Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ğµ Ğ»Ğ¾Ğ³Ğ¸ Ñ‡ĞµÑ€ĞµĞ· loguru
- Ğ£Ñ€Ğ¾Ğ²ĞµĞ½ÑŒ 2: ĞœĞ¾Ğ½Ğ¸Ñ‚Ğ¾Ñ€Ğ¸Ğ½Ğ³ Airflow Ñ callbacks (on_failure, on_success)
- Ğ£Ñ€Ğ¾Ğ²ĞµĞ½ÑŒ 3: ĞœĞ¾Ğ½Ğ¸Ñ‚Ğ¾Ñ€Ğ¸Ğ½Ğ³ Ğ¿Ñ€Ğ¾Ğ¸Ğ·Ğ²Ğ¾Ğ´Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ÑÑ‚Ğ¸ Ğ² MLflow (CPU, Ğ¿Ğ°Ğ¼ÑÑ‚ÑŒ, Ğ²Ñ€ĞµĞ¼Ñ)

**âœ… ĞĞ°ÑÑ‚Ñ€Ğ¾ĞµĞ½Ñ‹ ÑƒĞ²ĞµĞ´Ğ¾Ğ¼Ğ»ĞµĞ½Ğ¸Ñ Ğ¾ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ğ°Ñ…**
- Airflow UI Dashboard Ñ rich-ÑƒĞ²ĞµĞ´Ğ¾Ğ¼Ğ»ĞµĞ½Ğ¸ÑĞ¼Ğ¸
- MLflow UI Ñ Ğ°Ğ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ğ¼Ğ¸ ÑĞ²Ğ¾Ğ´Ğ½Ñ‹Ğ¼Ğ¸ Ğ¾Ñ‚Ñ‡Ñ‘Ñ‚Ğ°Ğ¼Ğ¸
- ĞŸĞ¾Ğ´Ğ´ĞµÑ€Ğ¶ĞºĞ° webhook'Ğ¾Ğ² Ğ´Ğ»Ñ Ğ²Ğ½ĞµÑˆĞ½Ğ¸Ñ… ÑĞ¸ÑÑ‚ĞµĞ¼ (Slack, Discord)

**âœ… ĞŸÑ€Ğ¾Ñ‚ĞµÑÑ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ° Ğ²Ğ¾ÑĞ¿Ñ€Ğ¾Ğ¸Ğ·Ğ²Ğ¾Ğ´Ğ¸Ğ¼Ğ¾ÑÑ‚ÑŒ**
- Ğ”ĞµÑ‚ĞµÑ€Ğ¼Ğ¸Ğ½Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ğ¾ÑÑ‚ÑŒ Ñ‡ĞµÑ€ĞµĞ· Ñ„Ğ¸ĞºÑĞ°Ñ†Ğ¸Ñ random seeds
- ĞšĞ»Ğ°ÑÑ `ReproducibilityTester` Ğ´Ğ»Ñ Ğ¿Ñ€Ğ¾Ğ²ĞµÑ€ĞºĞ¸ Ğ¸Ğ´ĞµĞ½Ñ‚Ğ¸Ñ‡Ğ½Ğ¾ÑÑ‚Ğ¸ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ğ¾Ğ²
- Ğ’ĞµÑ€ÑĞ¸Ğ¾Ğ½Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ñ‡ĞµÑ€ĞµĞ· DVC
- ĞšÑÑˆĞ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ´Ğ»Ñ Ğ¿Ñ€Ğ¾Ğ²ĞµÑ€ĞºĞ¸ ĞºĞ¾Ğ½ÑĞ¸ÑÑ‚ĞµĞ½Ñ‚Ğ½Ğ¾ÑÑ‚Ğ¸

### 5. ĞÑ‚Ñ‡Ñ‘Ñ‚ Ğ¾ Ğ¿Ñ€Ğ¾Ğ´ĞµĞ»Ğ°Ğ½Ğ½Ğ¾Ğ¹ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğµ

**âœ… Ğ¡Ğ¾Ğ·Ğ´Ğ°Ğ½ Ğ¿Ğ¾Ğ´Ñ€Ğ¾Ğ±Ğ½Ñ‹Ğ¹ Ğ¾Ñ‚Ñ‡Ñ‘Ñ‚**
- ĞÑ‚Ñ‡Ñ‘Ñ‚ Ğ² Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ‚Ğµ Markdown Ñ Ğ¾Ğ¿Ğ¸ÑĞ°Ğ½Ğ¸ĞµĞ¼ Ğ²ÑĞµÑ… ĞºĞ¾Ğ¼Ğ¿Ğ¾Ğ½ĞµĞ½Ñ‚Ğ¾Ğ²
- Ğ”Ğ¾Ğ±Ğ°Ğ²Ğ»ĞµĞ½Ñ‹ ÑÑ…ĞµĞ¼Ñ‹ Ğ°Ñ€Ñ…Ğ¸Ñ‚ĞµĞºÑ‚ÑƒÑ€Ñ‹ Ğ¸ Ğ¿Ñ€Ğ¸Ğ¼ĞµÑ€Ñ‹ ĞºĞ¾Ğ´Ğ°
- ĞÑ‚Ñ‡Ñ‘Ñ‚ Ğ¾Ğ±Ğ½Ğ¾Ğ²Ğ»Ñ‘Ğ½ Ğ½Ğ° Ğ¾ÑĞ½Ğ¾Ğ²Ğµ Ğ°ĞºÑ‚ÑƒĞ°Ğ»ÑŒĞ½Ğ¾Ğ¹ ÑÑ‚Ñ€ÑƒĞºÑ‚ÑƒÑ€Ñ‹ Ğ¿Ñ€Ğ¾ĞµĞºÑ‚Ğ°
- Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½Ñ‘Ğ½ Ğ² Git Ñ€ĞµĞ¿Ğ¾Ğ·Ğ¸Ñ‚Ğ¾Ñ€Ğ¸Ğ¸

**Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµĞ¼Ñ‹Ğ¹ ÑÑ‚ĞµĞº Ñ‚ĞµÑ…Ğ½Ğ¾Ğ»Ğ¾Ğ³Ğ¸Ğ¹:**

| ĞšĞ°Ñ‚ĞµĞ³Ğ¾Ñ€Ğ¸Ñ | Ğ¢ĞµÑ…Ğ½Ğ¾Ğ»Ğ¾Ğ³Ğ¸Ñ | Ğ’ĞµÑ€ÑĞ¸Ñ | ĞĞ°Ğ·Ğ½Ğ°Ñ‡ĞµĞ½Ğ¸Ğµ |
|-----------|------------|--------|------------|
| **Ğ¯Ğ·Ñ‹Ğº Ğ¸ Ğ¿Ğ°ĞºĞµÑ‚Ñ‹** | Python + uv | 3.13 | ĞÑĞ½Ğ¾Ğ²Ğ½Ğ¾Ğ¹ ÑĞ·Ñ‹Ğº Ñ€Ğ°Ğ·Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ¸, Ğ¿Ğ°ĞºĞµÑ‚Ğ½Ñ‹Ğ¹ Ğ¼ĞµĞ½ĞµĞ´Ğ¶ĞµÑ€ |
| **ĞÑ€ĞºĞµÑÑ‚Ñ€Ğ°Ñ†Ğ¸Ñ** | Apache Airflow | 2.8.1 | ĞÑ€ĞºĞµÑÑ‚Ñ€Ğ°Ñ†Ğ¸Ñ ML Ğ¿Ğ°Ğ¹Ğ¿Ğ»Ğ°Ğ¹Ğ½Ğ¾Ğ², Ğ¿Ğ»Ğ°Ğ½Ğ¸Ñ€Ğ¾Ğ²Ñ‰Ğ¸Ğº Ğ·Ğ°Ğ´Ğ°Ñ‡ |
| **Ğ¢Ñ€ĞµĞºĞ¸Ğ½Ğ³** | MLflow | 3.7.0+ | Ğ¢Ñ€ĞµĞºĞ¸Ğ½Ğ³ ÑĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚Ğ¾Ğ², Model Registry |
| **Ğ¥Ñ€Ğ°Ğ½Ğ¸Ğ»Ğ¸Ñ‰Ğµ** | MinIO | latest | S3-ÑĞ¾Ğ²Ğ¼ĞµÑÑ‚Ğ¸Ğ¼Ğ¾Ğµ Ñ…Ñ€Ğ°Ğ½Ğ¸Ğ»Ğ¸Ñ‰Ğµ Ğ°Ñ€Ñ‚ĞµÑ„Ğ°ĞºÑ‚Ğ¾Ğ² Ğ¸ ĞºÑÑˆĞ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ |
| **Ğ’ĞµÑ€ÑĞ¸Ğ¾Ğ½Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…** | DVC + DVCLive | 3.64.2+ | Ğ’ĞµÑ€ÑĞ¸Ğ¾Ğ½Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ¸ Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹, Ğ¼ĞµÑ‚Ñ€Ğ¸ĞºĞ¸ |
| **Ğ‘Ğ°Ğ·Ğ° Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…** | PostgreSQL | 15 | ĞœĞµÑ‚Ğ°Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ Airflow |
| **Ğ‘Ñ€Ğ¾ĞºĞµÑ€ ÑĞ¾Ğ¾Ğ±Ñ‰ĞµĞ½Ğ¸Ğ¹** | Redis | 7-alpine | Celery broker Ğ´Ğ»Ñ Airflow |
| **ĞšĞ¾Ğ½Ñ‚ĞµĞ¹Ğ½ĞµÑ€Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ** | Docker + Docker Compose | â€” | Ğ Ğ°Ğ·Ğ²ĞµÑ€Ñ‚Ñ‹Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ¸Ğ½Ñ„Ñ€Ğ°ÑÑ‚Ñ€ÑƒĞºÑ‚ÑƒÑ€Ñ‹ |
| **ĞĞ±Ñ€Ğ°Ñ‚Ğ½Ñ‹Ğ¹ Ğ¿Ñ€Ğ¾ĞºÑĞ¸** | Nginx | alpine | ĞÑƒÑ‚ĞµĞ½Ñ‚Ğ¸Ñ„Ğ¸ĞºĞ°Ñ†Ğ¸Ñ Ğ¸ Ğ¼Ğ°Ñ€ÑˆÑ€ÑƒÑ‚Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ |
| **ML Ğ±Ğ¸Ğ±Ğ»Ğ¸Ğ¾Ñ‚ĞµĞºĞ°** | scikit-learn | 1.7.2+ | 13 Ğ°Ğ»Ğ³Ğ¾Ñ€Ğ¸Ñ‚Ğ¼Ğ¾Ğ² Ğ¼Ğ°ÑˆĞ¸Ğ½Ğ½Ğ¾Ğ³Ğ¾ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ |
| **ĞšĞ¾Ğ½Ñ„Ğ¸Ğ³ÑƒÑ€Ğ°Ñ†Ğ¸Ğ¸** | Hydra + Pydantic | 1.3.2+ / 2.0+ | ĞšĞ¾Ğ¼Ğ¿Ğ¾Ğ·Ğ¸Ñ†Ğ¸Ñ YAML-ĞºĞ¾Ğ½Ñ„Ğ¸Ğ³ÑƒÑ€Ğ°Ñ†Ğ¸Ğ¹, Ğ²Ğ°Ğ»Ğ¸Ğ´Ğ°Ñ†Ğ¸Ñ ÑÑ…ĞµĞ¼, CLI Ğ¿ĞµÑ€ĞµĞ¾Ğ¿Ñ€ĞµĞ´ĞµĞ»ĞµĞ½Ğ¸Ğµ |
| **Ğ›Ğ¾Ğ³Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ** | loguru | 0.7.3+ | Ğ¡Ñ‚Ñ€ÑƒĞºÑ‚ÑƒÑ€Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ğ¾Ğµ Ğ»Ğ¾Ğ³Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ |
| **ĞšĞ°Ñ‡ĞµÑÑ‚Ğ²Ğ¾ ĞºĞ¾Ğ´Ğ°** | Ruff + pre-commit | 0.14.6+ | Ğ›Ğ¸Ğ½Ñ‚Ğ¸Ğ½Ğ³ Ğ¸ Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ ĞºĞ¾Ğ´Ğ° |
| **Ğ‘ĞµĞ·Ğ¾Ğ¿Ğ°ÑĞ½Ğ¾ÑÑ‚ÑŒ** | detect-secrets | 1.5.0+ | ĞĞ±Ğ½Ğ°Ñ€ÑƒĞ¶ĞµĞ½Ğ¸Ğµ ÑĞµĞºÑ€ĞµÑ‚Ğ¾Ğ² Ğ² ĞºĞ¾Ğ´Ğµ |
| **Ğ£Ñ‚Ğ¸Ğ»Ğ¸Ñ‚Ñ‹** | click, pandas, numpy | 2.3.3+ | CLI, Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ° Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…, Ğ²Ñ‹Ñ‡Ğ¸ÑĞ»ĞµĞ½Ğ¸Ñ |

---
