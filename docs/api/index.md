# API Reference

–î–æ–±—Ä–æ –ø–æ–∂–∞–ª–æ–≤–∞—Ç—å –≤ —Å–ø—Ä–∞–≤–æ—á–Ω–∏–∫ API –ø—Ä–æ–µ–∫—Ç–∞ Boston Housing Price Prediction.

---

## üìö –û–±–∑–æ—Ä –º–æ–¥—É–ª–µ–π

–ü—Ä–æ–µ–∫—Ç –æ—Ä–≥–∞–Ω–∏–∑–æ–≤–∞–Ω –≤ —Å–ª–µ–¥—É—é—â–∏–µ –æ—Å–Ω–æ–≤–Ω—ã–µ –º–æ–¥—É–ª–∏:

| –ú–æ–¥—É–ª—å | –û–ø–∏—Å–∞–Ω–∏–µ | –ü—É—Ç—å |
|--------|----------|------|
| **ml_models** | –ó–∞–≥—Ä—É–∑—á–∏–∫ –º–æ–¥–µ–ª–µ–π (14 –∞–ª–≥–æ—Ä–∏—Ç–º–æ–≤ —Ä–µ–≥—Ä–µ—Å—Å–∏–∏) | `src/ml_models/` |
| **tracking** | MLflow —Ç—Ä–µ–∫–∏–Ω–≥ (–¥–µ–∫–æ—Ä–∞—Ç–æ—Ä—ã, –º–µ–Ω–µ–¥–∂–µ—Ä—ã) | `src/tracking/` |
| **config** | –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –∏ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ | `conf/` |
| **dataset** | –†–∞–±–æ—Ç–∞ —Å –¥–∞–Ω–Ω—ã–º–∏ | `src/data/` |
| **schemas** | Pydantic —Å—Ö–µ–º—ã –≤–∞–ª–∏–¥–∞—Ü–∏–∏ | `src/schemas/` |

---

## üîç –ë—ã—Å—Ç—Ä—ã–π –ø–æ–∏—Å–∫

### –ú–æ–¥–µ–ª–∏

```python
from src.ml_models.model_loader import create_model, save_model, load_model

# –°–æ–∑–¥–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏
model = create_model("random_forest", custom_params={"n_estimators": 200})

# –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏
save_model(model, "my_rf_model")

# –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏
model = load_model("random_forest")
```

–ü–æ–¥—Ä–æ–±–Ω–µ–µ —Å–º. –º–æ–¥—É–ª—å `src/ml_models/model_loader.py`

### –¢—Ä–µ–∫–∏–Ω–≥

```python
from src.tracking.decorators import mlflow_run, log_metrics

@mlflow_run(experiment_name="my_experiment")
@log_metrics()
def train_model():
    # –í–∞—à –∫–æ–¥ –æ–±—É—á–µ–Ω–∏—è
    return {"rmse": 3.5, "r2": 0.85}
```

–ü–æ–¥—Ä–æ–±–Ω–µ–µ —Å–º. –º–æ–¥—É–ª—å `src/tracking/`

### –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏

```python
from hydra import compose, initialize
from src.schemas import ExperimentConfig

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è Hydra
with initialize(config_path="../conf", version_base=None):
    cfg = compose(config_name="config")

# –í–∞–ª–∏–¥–∞—Ü–∏—è —á–µ—Ä–µ–∑ Pydantic
config = ExperimentConfig(**cfg)
```

–ü–æ–¥—Ä–æ–±–Ω–µ–µ —Å–º. [–†—É–∫–æ–≤–æ–¥—Å—Ç–≤–æ –ø–æ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è–º](../guides/CONFIGURATION_MANAGEMENT.md)

---

## üìñ –î–µ—Ç–∞–ª—å–Ω–∞—è –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è

### –ú–æ–¥–µ–ª–∏ (ml_models)

–ú–æ–¥—É–ª—å `src/ml_models/model_loader.py`:

- `create_model()` ‚Äî —Å–æ–∑–¥–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏ –ø–æ –∏–º–µ–Ω–∏
- `save_model()` ‚Äî —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏
- `load_model()` ‚Äî –∑–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏
- `get_available_models()` ‚Äî —Å–ø–∏—Å–æ–∫ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π
- `get_model_info()` ‚Äî –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –º–æ–¥–µ–ª–∏

### –¢—Ä–µ–∫–∏–Ω–≥ (tracking)

–ú–æ–¥—É–ª—å `src/tracking/`:

- `@mlflow_run` ‚Äî –¥–µ–∫–æ—Ä–∞—Ç–æ—Ä –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ MLflow run
- `@log_params` ‚Äî –¥–µ–∫–æ—Ä–∞—Ç–æ—Ä –¥–ª—è –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
- `@log_metrics` ‚Äî –¥–µ–∫–æ—Ä–∞—Ç–æ—Ä –¥–ª—è –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è –º–µ—Ç—Ä–∏–∫
- `MLflowExperimentTracker` ‚Äî –∫–ª–∞—Å—Å –¥–ª—è —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞–º–∏
- `get_best_run()` ‚Äî –ø–æ–ª—É—á–µ–Ω–∏–µ –ª—É—á—à–µ–≥–æ –∑–∞–ø—É—Å–∫–∞
- `load_best_model()` ‚Äî –∑–∞–≥—Ä—É–∑–∫–∞ –ª—É—á—à–µ–π –º–æ–¥–µ–ª–∏

### –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ (config)

–ú–æ–¥—É–ª—å `src/schemas/` (—Å–º. [–†—É–∫–æ–≤–æ–¥—Å—Ç–≤–æ –ø–æ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è–º](../guides/CONFIGURATION_MANAGEMENT.md)):

- `BaseConfig` ‚Äî –±–∞–∑–æ–≤—ã–π –∫–ª–∞—Å—Å –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
- `ModelConfig` ‚Äî –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –º–æ–¥–µ–ª–∏
- `DataConfig` ‚Äî –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö
- `TrainingConfig` ‚Äî –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –æ–±—É—á–µ–Ω–∏—è
- `ExperimentConfig` ‚Äî –ø–æ–ª–Ω–∞—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞
- –°–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –¥–ª—è –∫–∞–∂–¥–æ–π –º–æ–¥–µ–ª–∏

### –î–∞—Ç–∞—Å–µ—Ç (dataset)

–ú–æ–¥—É–ª—å `src/data/`:

- `load_boston_housing()` ‚Äî –∑–∞–≥—Ä—É–∑–∫–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞
- `validate_data()` ‚Äî –≤–∞–ª–∏–¥–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö
- `split_data()` ‚Äî —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ –Ω–∞ train/test
- `get_data_info()` ‚Äî –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –¥–∞—Ç–∞—Å–µ—Ç–µ

---

## üéØ –ü—Ä–∏–º–µ—Ä—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è

### –ü–æ–ª–Ω—ã–π –ø—Ä–∏–º–µ—Ä –æ–±—É—á–µ–Ω–∏—è

```python
from src.ml_models.model_loader import create_model
from src.tracking.decorators import mlflow_run, log_metrics, log_params
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score
import pandas as pd

@mlflow_run(experiment_name="boston_housing")
@log_params(params={"model_type": "random_forest"})
@log_metrics()
def train_and_evaluate():
    # –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö
    data = pd.read_csv("data/raw/housing.csv")
    X = data.drop("MEDV", axis=1)
    y = data["MEDV"]

    # –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, random_state=42
    )

    # –°–æ–∑–¥–∞–Ω–∏–µ –∏ –æ–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏
    model = create_model("random_forest", custom_params={
        "n_estimators": 200,
        "max_depth": 15,
        "random_state": 42
    })
    model.fit(X_train, y_train)

    # –û—Ü–µ–Ω–∫–∞
    y_pred = model.predict(X_test)
    rmse = mean_squared_error(y_test, y_pred, squared=False)
    r2 = r2_score(y_test, y_pred)

    return {"rmse": rmse, "r2": r2}

# –ó–∞–ø—É—Å–∫
metrics = train_and_evaluate()
print(f"RMSE: {metrics['rmse']:.3f}, R¬≤: {metrics['r2']:.3f}")
```

### –†–∞–±–æ—Ç–∞ —Å Hydra –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è–º–∏

```python
import hydra
from omegaconf import DictConfig
from src.ml_models.model_loader import create_model

@hydra.main(version_base=None, config_path="../conf", config_name="config")
def main(cfg: DictConfig) -> None:
    # –°–æ–∑–¥–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏ –∏–∑ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
    model = create_model(
        cfg.model.name,
        custom_params=cfg.model.get("params", {})
    )

    # –û–±—É—á–µ–Ω–∏–µ
    # ...

if __name__ == "__main__":
    main()
```

---

## üîó –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ —Ä–µ—Å—É—Ä—Å—ã

- [–ü—Ä–∏–º–µ—Ä—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è](../examples/index.md) ‚Äî –±–æ–ª—å—à–µ –ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏—Ö –ø—Ä–∏–º–µ—Ä–æ–≤
- [–†—É–∫–æ–≤–æ–¥—Å—Ç–≤–∞](../guides/index.md) ‚Äî –ø–æ–¥—Ä–æ–±–Ω—ã–µ –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏
- [GitHub Repository](https://github.com/yourusername/ipml_boston_housing) ‚Äî –∏—Å—Ö–æ–¥–Ω—ã–π –∫–æ–¥

---

## üìù –ö–æ–Ω–≤–µ–Ω—Ü–∏–∏ –∫–æ–¥–∞

–ü—Ä–æ–µ–∫—Ç —Å–ª–µ–¥—É–µ—Ç —Å–ª–µ–¥—É—é—â–∏–º –∫–æ–Ω–≤–µ–Ω—Ü–∏—è–º:

### –¢–∏–ø–∏–∑–∞—Ü–∏—è

–í—Å–µ —Ñ—É–Ω–∫—Ü–∏–∏ –∏–º–µ—é—Ç type hints:

```python
def train_model(
    X_train: np.ndarray,
    y_train: np.ndarray,
    model_name: str = "random_forest"
) -> tuple[Any, dict[str, float]]:
    """Train model and return it with metrics."""
    ...
```

### Docstrings

–ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è Google style:

```python
def create_model(model_name: str, custom_params: dict | None = None) -> Any:
    """Create a scikit-learn model by name.

    Args:
        model_name: Name of the model to create.
        custom_params: Custom parameters to override defaults.

    Returns:
        Instantiated scikit-learn model.

    Raises:
        ValueError: If model_name is not recognized.

    Example:
        >>> model = create_model("random_forest", {"n_estimators": 200})
        >>> model.fit(X_train, y_train)
    """
    ...
```

### –ò–º–µ–Ω–æ–≤–∞–Ω–∏–µ

- **–§—É–Ω–∫—Ü–∏–∏**: `snake_case`
- **–ö–ª–∞—Å—Å—ã**: `PascalCase`
- **–ö–æ–Ω—Å—Ç–∞–Ω—Ç—ã**: `UPPER_SNAKE_CASE`
- **–ü—Ä–∏–≤–∞—Ç–Ω—ã–µ**: `_leading_underscore`

---

## ü§ù –í–∫–ª–∞–¥ –≤ –ø—Ä–æ–µ–∫—Ç

–ü—Ä–∏ –¥–æ–±–∞–≤–ª–µ–Ω–∏–∏ –Ω–æ–≤–æ–≥–æ –∫–æ–¥–∞:

1. ‚úÖ –î–æ–±–∞–≤—å—Ç–µ type hints
2. ‚úÖ –ù–∞–ø–∏—à–∏—Ç–µ docstrings (Google style)
3. ‚úÖ –î–æ–±–∞–≤—å—Ç–µ unit tests
4. ‚úÖ –ó–∞–ø—É—Å—Ç–∏—Ç–µ `make lint` –∏ `make format`
5. ‚úÖ –û–±–Ω–æ–≤–∏—Ç–µ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—é

–°–º. [Contributing Guide](../about.md) –¥–ª—è –¥–µ—Ç–∞–ª–µ–π.
