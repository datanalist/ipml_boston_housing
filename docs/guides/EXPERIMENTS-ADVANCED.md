# üî¨ –ü—Ä–æ–¥–≤–∏–Ω—É—Ç–æ–µ —Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤–æ –ø–æ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞–º

–≠—Ç–æ —Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤–æ –æ–ø–∏—Å—ã–≤–∞–µ—Ç –ø—Ä–æ–≤–µ–¥–µ–Ω–∏–µ –º–∞—Å—à—Ç–∞–±–Ω—ã—Ö —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤ —Å —Ä–∞–∑–ª–∏—á–Ω—ã–º–∏ –∞–ª–≥–æ—Ä–∏—Ç–º–∞–º–∏ –º–∞—à–∏–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è, –Ω–∞—Å—Ç—Ä–æ–π–∫—É –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è –∏ —Å–∏—Å—Ç–µ–º—É —Å—Ä–∞–≤–Ω–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤.

## üìã –°–æ–¥–µ—Ä–∂–∞–Ω–∏–µ

1. [–û–±–∑–æ—Ä](#–æ–±–∑–æ—Ä)
2. [–î–æ—Å—Ç—É–ø–Ω—ã–µ –∞–ª–≥–æ—Ä–∏—Ç–º—ã](#–¥–æ—Å—Ç—É–ø–Ω—ã–µ-–∞–ª–≥–æ—Ä–∏—Ç–º—ã)
3. [–ü—Ä–æ–≤–µ–¥–µ–Ω–∏–µ 19 —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤](#–ø—Ä–æ–≤–µ–¥–µ–Ω–∏–µ-19-—ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤)
4. [–ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è](#–Ω–∞—Å—Ç—Ä–æ–π–∫–∞-–ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è)
5. [–°–∏—Å—Ç–µ–º–∞ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤](#—Å–∏—Å—Ç–µ–º–∞-—Å—Ä–∞–≤–Ω–µ–Ω–∏—è-—ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤)
6. [–§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –∏ –ø–æ–∏—Å–∫ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤](#—Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è-–∏-–ø–æ–∏—Å–∫-—ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤)
7. [–ê–≤—Ç–æ–º–∞—Ç–∏–∑–∞—Ü–∏—è —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤](#–∞–≤—Ç–æ–º–∞—Ç–∏–∑–∞—Ü–∏—è-—ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤)
8. [Best Practices](#best-practices)

---

## –û–±–∑–æ—Ä

–í –ø—Ä–æ–µ–∫—Ç–µ –¥–æ—Å—Ç—É–ø–Ω–æ **14 –∞–ª–≥–æ—Ä–∏—Ç–º–æ–≤ —Ä–µ–≥—Ä–µ—Å—Å–∏–∏** –∏–∑ scikit-learn, –∫–æ—Ç–æ—Ä—ã–µ –º–æ–∂–Ω–æ –∫–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞—Ç—å —Å —Ä–∞–∑–ª–∏—á–Ω—ã–º–∏ –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏ –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è **19 —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤**. –î–ª—è —Ç—Ä–µ–∫–∏–Ω–≥–∞ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —Å–≤—è–∑–∫–∞:

| –ò–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç | –ù–∞–∑–Ω–∞—á–µ–Ω–∏–µ |
|------------|------------|
| **MLflow** | –¶–µ–Ω—Ç—Ä–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–π —Ç—Ä–µ–∫–∏–Ω–≥ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤, UI –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è |
| **DVCLive** | –õ–æ–∫–∞–ª—å–Ω—ã–π —Ç—Ä–µ–∫–∏–Ω–≥ —Å –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–µ–π –≤ Git/DVC |
| **MinIO** | –•—Ä–∞–Ω–µ–Ω–∏–µ –∞—Ä—Ç–µ—Ñ–∞–∫—Ç–æ–≤ (–º–æ–¥–µ–ª–∏, –≥—Ä–∞—Ñ–∏–∫–∏) |

---

## –î–æ—Å—Ç—É–ø–Ω—ã–µ –∞–ª–≥–æ—Ä–∏—Ç–º—ã

### –õ–∏–Ω–µ–π–Ω—ã–µ –º–æ–¥–µ–ª–∏

| –ê–ª–≥–æ—Ä–∏—Ç–º | –ö–ª—é—á | –û–ø–∏—Å–∞–Ω–∏–µ | –ö–ª—é—á–µ–≤—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã |
|----------|------|----------|-------------------|
| Linear Regression | `linear_regression` | –û–±—ã—á–Ω–∞—è –ª–∏–Ω–µ–π–Ω–∞—è —Ä–µ–≥—Ä–µ—Å—Å–∏—è (–ú–ù–ö) | ‚Äî |
| Ridge | `ridge` | L2-—Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏—è | `alpha` |
| Lasso | `lasso` | L1-—Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏—è | `alpha` |
| Elastic Net | `elastic_net` | L1+L2 —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏—è | `alpha`, `l1_ratio` |
| Huber Regressor | `huber` | –†–æ–±–∞—Å—Ç–Ω–∞—è —Ä–µ–≥—Ä–µ—Å—Å–∏—è | `epsilon` |
| SGD Regressor | `sgd` | –°—Ç–æ—Ö–∞—Å—Ç–∏—á–µ—Å–∫–∏–π –≥—Ä–∞–¥–∏–µ–Ω—Ç–Ω—ã–π —Å–ø—É—Å–∫ | `learning_rate`, `max_iter` |

### –î—Ä–µ–≤–æ–≤–∏–¥–Ω—ã–µ –º–æ–¥–µ–ª–∏ –∏ –∞–Ω—Å–∞–º–±–ª–∏

| –ê–ª–≥–æ—Ä–∏—Ç–º | –ö–ª—é—á | –û–ø–∏—Å–∞–Ω–∏–µ | –ö–ª—é—á–µ–≤—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã |
|----------|------|----------|-------------------|
| Decision Tree | `decision_tree` | –î–µ—Ä–µ–≤–æ —Ä–µ—à–µ–Ω–∏–π | `max_depth` |
| Random Forest | `random_forest` | –°–ª—É—á–∞–π–Ω—ã–π –ª–µ—Å | `n_estimators`, `max_depth` |
| Extra Trees | `extra_trees` | –≠–∫—Å—Ç—Ä–µ–º–∞–ª—å–Ω–æ —Ä–∞–Ω–¥–æ–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –¥–µ—Ä–µ–≤—å—è | `n_estimators`, `max_depth` |
| Gradient Boosting | `gradient_boosting` | –ì—Ä–∞–¥–∏–µ–Ω—Ç–Ω—ã–π –±—É—Å—Ç–∏–Ω–≥ | `n_estimators`, `learning_rate` |
| AdaBoost | `adaboost` | –ê–¥–∞–ø—Ç–∏–≤–Ω—ã–π –±—É—Å—Ç–∏–Ω–≥ | `n_estimators`, `learning_rate` |
| Bagging | `bagging` | –ë—ç–≥–≥–∏–Ω–≥ —Ä–µ–≥—Ä–µ—Å—Å–æ—Ä | `n_estimators` |

### –î—Ä—É–≥–∏–µ –º–æ–¥–µ–ª–∏

| –ê–ª–≥–æ—Ä–∏—Ç–º | –ö–ª—é—á | –û–ø–∏—Å–∞–Ω–∏–µ | –ö–ª—é—á–µ–≤—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã |
|----------|------|----------|-------------------|
| SVR | `svr` | –û–ø–æ—Ä–Ω—ã–µ –≤–µ–∫—Ç–æ—Ä–∞ | `kernel`, `C`, `epsilon` |
| KNN | `knn` | K –±–ª–∏–∂–∞–π—à–∏—Ö —Å–æ—Å–µ–¥–µ–π | `n_neighbors`, `weights` |

---

## –ü—Ä–æ–≤–µ–¥–µ–Ω–∏–µ 19 —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤

### –°–∫—Ä–∏–ø—Ç –¥–ª—è –º–∞—Å—Å–æ–≤—ã—Ö —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤

–°–∫—Ä–∏–ø—Ç `scripts/run_experiments.py` —Å–æ–¥–µ—Ä–∂–∏—Ç –ø–æ–ª–Ω—É—é —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—é:

```python
"""
–°–∫—Ä–∏–ø—Ç –¥–ª—è –∑–∞–ø—É—Å–∫–∞ –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã—Ö —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤ —Å —Ä–∞–∑–Ω—ã–º–∏ –∞–ª–≥–æ—Ä–∏—Ç–º–∞–º–∏ ML.

–õ–æ–≥–∏—Ä—É–µ—Ç –º–µ—Ç—Ä–∏–∫–∏, –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –∏ –∞—Ä—Ç–µ—Ñ–∞–∫—Ç—ã –≤ MLflow.
"""

import os
import sys
import time
import pickle
import tempfile
from pathlib import Path
from datetime import datetime

import mlflow
import mlflow.sklearn
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
from loguru import logger

# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å –∫ src
sys.path.insert(0, str(Path(__file__).resolve().parents[1]))

from src.ml_models.model_loader import create_model, MODEL_REGISTRY
from src.config import RAW_DATA_DIR, HOUSING_DATA_FILE, MODELS_DIR


# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# –ö–û–ù–§–ò–ì–£–†–ê–¶–ò–Ø 19 –≠–ö–°–ü–ï–†–ò–ú–ï–ù–¢–û–í
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

EXPERIMENTS_CONFIG = [
    # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    # –õ–∏–Ω–µ–π–Ω—ã–µ –º–æ–¥–µ–ª–∏ (7 —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤)
    # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    {"name": "linear_regression", "params": {}, "description": "Baseline –ª–∏–Ω–µ–π–Ω–∞—è —Ä–µ–≥—Ä–µ—Å—Å–∏—è"},
    {"name": "ridge", "params": {"alpha": 0.1}, "description": "Ridge —Å–æ —Å–ª–∞–±–æ–π —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏–µ–π"},
    {"name": "ridge", "params": {"alpha": 1.0}, "description": "Ridge —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π"},
    {"name": "ridge", "params": {"alpha": 10.0}, "description": "Ridge —Å —Å–∏–ª—å–Ω–æ–π —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏–µ–π"},
    {"name": "lasso", "params": {"alpha": 0.1}, "description": "Lasso –¥–ª—è –æ—Ç–±–æ—Ä–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤"},
    {"name": "elastic_net", "params": {"alpha": 0.5, "l1_ratio": 0.5}, "description": "Elastic Net –∫–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–π"},
    {"name": "huber", "params": {"epsilon": 1.35}, "description": "Huber —Ä–æ–±–∞—Å—Ç–Ω–∞—è —Ä–µ–≥—Ä–µ—Å—Å–∏—è"},

    # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    # –î—Ä–µ–≤–æ–≤–∏–¥–Ω—ã–µ –º–æ–¥–µ–ª–∏ –∏ –∞–Ω—Å–∞–º–±–ª–∏ (9 —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤)
    # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    {"name": "decision_tree", "params": {"max_depth": 5}, "description": "–î–µ—Ä–µ–≤–æ —Ä–µ—à–µ–Ω–∏–π (shallow)"},
    {"name": "decision_tree", "params": {"max_depth": 10}, "description": "–î–µ—Ä–µ–≤–æ —Ä–µ—à–µ–Ω–∏–π (deep)"},
    {"name": "random_forest", "params": {"n_estimators": 100, "max_depth": 10}, "description": "Random Forest —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π"},
    {"name": "random_forest", "params": {"n_estimators": 200, "max_depth": 15}, "description": "Random Forest –±–æ–ª—å—à–æ–π"},
    {"name": "extra_trees", "params": {"n_estimators": 100, "max_depth": 10}, "description": "Extra Trees"},
    {"name": "gradient_boosting", "params": {"n_estimators": 100, "learning_rate": 0.1}, "description": "Gradient Boosting —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π"},
    {"name": "gradient_boosting", "params": {"n_estimators": 200, "learning_rate": 0.05}, "description": "Gradient Boosting –º–µ–¥–ª–µ–Ω–Ω—ã–π"},
    {"name": "adaboost", "params": {"n_estimators": 50, "learning_rate": 1.0}, "description": "AdaBoost"},
    {"name": "bagging", "params": {"n_estimators": 20}, "description": "Bagging —Ä–µ–≥—Ä–µ—Å—Å–æ—Ä"},

    # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    # –î—Ä—É–≥–∏–µ –º–æ–¥–µ–ª–∏ (3 —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞)
    # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    {"name": "svr", "params": {"kernel": "rbf", "C": 1.0}, "description": "SVR —Å RBF —è–¥—Ä–æ–º"},
    {"name": "knn", "params": {"n_neighbors": 5, "weights": "uniform"}, "description": "KNN k=5 uniform"},
    {"name": "knn", "params": {"n_neighbors": 10, "weights": "distance"}, "description": "KNN k=10 distance"},
]


def load_data():
    """–ó–∞–≥—Ä—É–∑–∫–∞ –∏ –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö Boston Housing."""
    data_file = RAW_DATA_DIR / HOUSING_DATA_FILE

    if not data_file.exists():
        logger.error(f"–§–∞–π–ª –¥–∞–Ω–Ω—ã—Ö –Ω–µ –Ω–∞–π–¥–µ–Ω: {data_file}")
        logger.info("–í—ã–ø–æ–ª–Ω–∏—Ç–µ 'dvc pull' –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ –¥–∞–Ω–Ω—ã—Ö")
        sys.exit(1)

    df = pd.read_csv(data_file, sep=r"\s+", header=None)

    column_names = [
        "CRIM", "ZN", "INDUS", "CHAS", "NOX", "RM", "AGE",
        "DIS", "RAD", "TAX", "PTRATIO", "B", "LSTAT", "MEDV"
    ]
    df.columns = column_names

    X = df.drop("MEDV", axis=1)
    y = df["MEDV"]

    return train_test_split(X, y, test_size=0.2, random_state=42)


def get_algorithm_family(model_name: str) -> str:
    """–û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Å–µ–º–µ–π—Å—Ç–≤–∞ –∞–ª–≥–æ—Ä–∏—Ç–º–∞ –¥–ª—è —Ç–µ–≥–∏—Ä–æ–≤–∞–Ω–∏—è."""
    linear_models = ["linear_regression", "ridge", "lasso", "elastic_net", "huber", "sgd"]
    tree_models = ["decision_tree", "random_forest", "extra_trees", "gradient_boosting", "adaboost", "bagging"]

    if model_name in linear_models:
        return "linear"
    elif model_name in tree_models:
        return "tree_ensemble"
    else:
        return "other"


def evaluate_model(model, X_test, y_test):
    """–û—Ü–µ–Ω–∫–∞ –º–æ–¥–µ–ª–∏ –∏ —Ä–∞—Å—á—ë—Ç –º–µ—Ç—Ä–∏–∫."""
    y_pred = model.predict(X_test)

    return {
        "r2_score": float(r2_score(y_test, y_pred)),
        "rmse": float(np.sqrt(mean_squared_error(y_test, y_pred))),
        "mae": float(mean_absolute_error(y_test, y_pred)),
        "mape": float(np.mean(np.abs((y_test - y_pred) / y_test)) * 100),
    }, y_pred


def run_single_experiment(config, X_train, X_test, y_train, y_test, experiment_idx, total_experiments):
    """–ó–∞–ø—É—Å–∫ –æ–¥–Ω–æ–≥–æ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞ —Å –ø–æ–ª–Ω—ã–º –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ–º –≤ MLflow."""

    model_name = config["name"]
    custom_params = config["params"]
    description = config.get("description", "")

    # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —É–Ω–∏–∫–∞–ª—å–Ω–æ–≥–æ –∏–º–µ–Ω–∏ run
    param_str = "_".join([f"{k}={v}" for k, v in custom_params.items()])
    run_name = f"{model_name}_{param_str}" if param_str else model_name

    with mlflow.start_run(run_name=run_name):
        # –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
        mlflow.log_param("model_type", model_name)
        mlflow.log_param("model_description", MODEL_REGISTRY[model_name]["description"])
        mlflow.log_param("experiment_description", description)

        for param_name, param_value in custom_params.items():
            mlflow.log_param(param_name, param_value)

        mlflow.log_param("train_size", len(X_train))
        mlflow.log_param("test_size", len(X_test))
        mlflow.log_param("n_features", X_train.shape[1])
        mlflow.log_param("random_state", 42)

        # –û–±—É—á–µ–Ω–∏–µ —Å –∑–∞–º–µ—Ä–æ–º –≤—Ä–µ–º–µ–Ω–∏
        model = create_model(model_name, custom_params)

        start_train = time.time()
        model.fit(X_train, y_train)
        train_time = time.time() - start_train

        metrics, y_pred = evaluate_model(model, X_test, y_test)

        # –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –º–µ—Ç—Ä–∏–∫
        for metric_name, metric_value in metrics.items():
            mlflow.log_metric(metric_name, metric_value)

        mlflow.log_metric("train_time_seconds", train_time)

        # –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏ –∏ –∞—Ä—Ç–µ—Ñ–∞–∫—Ç–æ–≤
        mlflow.sklearn.log_model(model, "sklearn_model")

        # –¢–µ–≥–∏
        mlflow.set_tag("algorithm_family", get_algorithm_family(model_name))
        mlflow.set_tag("experiment_type", "model_comparison")
        mlflow.set_tag("dataset", "boston_housing")

        logger.info(f"‚úÖ {run_name}: R¬≤={metrics['r2_score']:.4f}, RMSE={metrics['rmse']:.4f}")

        return {
            "run_name": run_name,
            "model_type": model_name,
            **metrics,
            "train_time": train_time
        }


def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –∑–∞–ø—É—Å–∫–∞ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤."""

    # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ MLflow
    mlflow_uri = os.environ.get("MLFLOW_TRACKING_URI", "http://localhost:5000")
    mlflow.set_tracking_uri(mlflow_uri)
    mlflow.set_experiment("boston_housing_model_comparison")

    # –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö
    X_train, X_test, y_train, y_test = load_data()
    logger.info(f"–î–∞–Ω–Ω—ã–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã: train={len(X_train)}, test={len(X_test)}")

    # –ó–∞–ø—É—Å–∫ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤
    results = []
    total = len(EXPERIMENTS_CONFIG)

    for i, config in enumerate(EXPERIMENTS_CONFIG, 1):
        logger.info(f"\n[{i}/{total}] –ó–∞–ø—É—Å–∫: {config['name']}")
        result = run_single_experiment(config, X_train, X_test, y_train, y_test, i, total)
        results.append(result)

    # –°–≤–æ–¥–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    results_df = pd.DataFrame(results).sort_values("r2_score", ascending=False)

    logger.info("\n" + "=" * 60)
    logger.info("üìä –¢–û–ü-5 –ú–û–î–ï–õ–ï–ô –ü–û R¬≤ SCORE:")
    for _, row in results_df.head(5).iterrows():
        logger.info(f"  {row['run_name']}: R¬≤={row['r2_score']:.4f}")

    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    results_path = Path(__file__).parent.parent / "data" / "experiments" / "results_summary.csv"
    results_path.parent.mkdir(parents=True, exist_ok=True)
    results_df.to_csv(results_path, index=False)

    logger.info(f"\n‚úÖ –ó–∞–≤–µ—Ä—à–µ–Ω–æ {len(EXPERIMENTS_CONFIG)} —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤")
    logger.info(f"üíæ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã: {results_path}")
    logger.info(f"üåê –û—Ç–∫—Ä–æ–π—Ç–µ MLflow UI: {mlflow_uri}")


if __name__ == "__main__":
    main()
```

### –ó–∞–ø—É—Å–∫ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤

```bash
# 1. –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ MLflow —Å–µ—Ä–≤–µ—Ä –∑–∞–ø—É—â–µ–Ω
docker-compose up -d mlflow

# 2. –ù–∞—Å—Ç—Ä–æ–π—Ç–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è
export MLFLOW_TRACKING_URI=http://localhost:5000
export MLFLOW_TRACKING_USERNAME=admin
export MLFLOW_TRACKING_PASSWORD=password

# 3. –ó–∞–ø—É—Å—Ç–∏—Ç–µ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—ã
python scripts/run_experiments.py
```

### –ü–ª–∞–Ω 19 —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤

| # | –ê–ª–≥–æ—Ä–∏—Ç–º | –ü–∞—Ä–∞–º–µ—Ç—Ä—ã | –¶–µ–ª—å —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞ |
|---|----------|-----------|-------------------|
| 1 | Linear Regression | –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é | Baseline –ª–∏–Ω–µ–π–Ω–∞—è —Ä–µ–≥—Ä–µ—Å—Å–∏—è |
| 2 | Ridge | Œ±=0.1 | Ridge —Å–æ —Å–ª–∞–±–æ–π —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏–µ–π |
| 3 | Ridge | Œ±=1.0 | Ridge —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π |
| 4 | Ridge | Œ±=10.0 | Ridge —Å —Å–∏–ª—å–Ω–æ–π —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏–µ–π |
| 5 | Lasso | Œ±=0.1 | Lasso –¥–ª—è –æ—Ç–±–æ—Ä–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ |
| 6 | Elastic Net | Œ±=0.5, l1_ratio=0.5 | Elastic Net –∫–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–π |
| 7 | Huber | Œµ=1.35 | Huber —Ä–æ–±–∞—Å—Ç–Ω–∞—è —Ä–µ–≥—Ä–µ—Å—Å–∏—è |
| 8 | Decision Tree | depth=5 | –î–µ—Ä–µ–≤–æ —Ä–µ—à–µ–Ω–∏–π (shallow) |
| 9 | Decision Tree | depth=10 | –î–µ—Ä–µ–≤–æ —Ä–µ—à–µ–Ω–∏–π (deep) |
| 10 | Random Forest | n=100, depth=10 | Random Forest —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π |
| 11 | Random Forest | n=200, depth=15 | Random Forest –±–æ–ª—å—à–æ–π |
| 12 | Extra Trees | n=100, depth=10 | Extra Trees |
| 13 | Gradient Boosting | n=100, lr=0.1 | Gradient Boosting —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π |
| 14 | Gradient Boosting | n=200, lr=0.05 | Gradient Boosting –º–µ–¥–ª–µ–Ω–Ω—ã–π |
| 15 | AdaBoost | n=50, lr=1.0 | AdaBoost |
| 16 | Bagging | n=20 | Bagging —Ä–µ–≥—Ä–µ—Å—Å–æ—Ä |
| 17 | SVR (RBF) | kernel=rbf, C=1.0 | SVR —Å RBF —è–¥—Ä–æ–º |
| 18 | KNN | k=5, uniform | KNN k=5 uniform |
| 19 | KNN | k=10, distance | KNN k=10 distance |

---

## –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è

### –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                         –ß—Ç–æ –ª–æ–≥–∏—Ä–æ–≤–∞—Ç—å?                               ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                                                       ‚îÇ
‚îÇ  –ü–ê–†–ê–ú–ï–¢–†–´ (log_param)              –ú–ï–¢–†–ò–ö–ò (log_metric)              ‚îÇ
‚îÇ  ‚îú‚îÄ‚îÄ model_type                     ‚îú‚îÄ‚îÄ r2_score                      ‚îÇ
‚îÇ  ‚îú‚îÄ‚îÄ model_description              ‚îú‚îÄ‚îÄ rmse                          ‚îÇ
‚îÇ  ‚îú‚îÄ‚îÄ experiment_description         ‚îú‚îÄ‚îÄ mae                           ‚îÇ
‚îÇ  ‚îú‚îÄ‚îÄ n_estimators, max_depth...     ‚îú‚îÄ‚îÄ mape                          ‚îÇ
‚îÇ  ‚îú‚îÄ‚îÄ train_size                     ‚îú‚îÄ‚îÄ train_time_seconds            ‚îÇ
‚îÇ  ‚îú‚îÄ‚îÄ test_size                      ‚îú‚îÄ‚îÄ inference_time_seconds        ‚îÇ
‚îÇ  ‚îú‚îÄ‚îÄ n_features                     ‚îî‚îÄ‚îÄ predictions_per_second        ‚îÇ
‚îÇ  ‚îú‚îÄ‚îÄ random_state                                                     ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ test_split_ratio                                                 ‚îÇ
‚îÇ                                                                       ‚îÇ
‚îÇ  –ê–†–¢–ï–§–ê–ö–¢–´ (log_artifact)           –¢–ï–ì–ò (set_tag)                    ‚îÇ
‚îÇ  ‚îú‚îÄ‚îÄ sklearn_model/                 ‚îú‚îÄ‚îÄ algorithm_family              ‚îÇ
‚îÇ  ‚îú‚îÄ‚îÄ model_artifacts/*.pkl          ‚îú‚îÄ‚îÄ experiment_type               ‚îÇ
‚îÇ  ‚îú‚îÄ‚îÄ plots/predictions_scatter.png  ‚îú‚îÄ‚îÄ dataset                       ‚îÇ
‚îÇ  ‚îú‚îÄ‚îÄ plots/residuals.png            ‚îú‚îÄ‚îÄ author                        ‚îÇ
‚îÇ  ‚îú‚îÄ‚îÄ plots/feature_importance.png   ‚îú‚îÄ‚îÄ environment                   ‚îÇ
‚îÇ  ‚îú‚îÄ‚îÄ predictions/predictions.csv    ‚îî‚îÄ‚îÄ mlflow.note.content           ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ config/experiment_config.json                                    ‚îÇ
‚îÇ                                                                       ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### –ü—Ä–∏–º–µ—Ä –ø–æ–ª–Ω–æ–≥–æ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è

```python
import mlflow
import mlflow.sklearn
from datetime import datetime
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import pickle
import json
import time

def run_full_experiment(model, model_name, X_train, X_test, y_train, y_test, custom_params):
    """–ü–æ–ª–Ω—ã–π —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç —Å —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–º –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ–º."""

    mlflow.set_experiment("boston_housing_model_comparison")

    with mlflow.start_run(run_name=f"{model_name}_{datetime.now().strftime('%Y%m%d_%H%M%S')}"):

        # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
        # 1. –õ–û–ì–ò–†–û–í–ê–ù–ò–ï –ü–ê–†–ê–ú–ï–¢–†–û–í
        # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

        # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –º–æ–¥–µ–ª–∏
        mlflow.log_param("model_type", model_name)
        for param_name, param_value in custom_params.items():
            mlflow.log_param(param_name, param_value)

        # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–∞–Ω–Ω—ã—Ö
        mlflow.log_param("train_size", len(X_train))
        mlflow.log_param("test_size", len(X_test))
        mlflow.log_param("n_features", X_train.shape[1])
        mlflow.log_param("feature_names", list(X_train.columns))

        # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
        # 2. –û–ë–£–ß–ï–ù–ò–ï –° –ó–ê–ú–ï–†–û–ú –í–†–ï–ú–ï–ù–ò
        # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

        import time

        start_train = time.time()
        model.fit(X_train, y_train)
        train_time = time.time() - start_train

        start_inference = time.time()
        y_pred = model.predict(X_test)
        inference_time = time.time() - start_inference

        # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
        # 3. –õ–û–ì–ò–†–û–í–ê–ù–ò–ï –ú–ï–¢–†–ò–ö
        # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

        # –û—Å–Ω–æ–≤–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞
        mlflow.log_metric("r2_score", r2_score(y_test, y_pred))
        mlflow.log_metric("rmse", np.sqrt(mean_squared_error(y_test, y_pred)))
        mlflow.log_metric("mae", mean_absolute_error(y_test, y_pred))
        mlflow.log_metric("mape", np.mean(np.abs((y_test - y_pred) / y_test)) * 100)

        # –ú–µ—Ç—Ä–∏–∫–∏ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
        mlflow.log_metric("train_time_seconds", train_time)
        mlflow.log_metric("inference_time_seconds", inference_time)
        mlflow.log_metric("predictions_per_second", len(X_test) / inference_time)

        # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
        # 4. –õ–û–ì–ò–†–û–í–ê–ù–ò–ï –ê–†–¢–ï–§–ê–ö–¢–û–í
        # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

        # 4.1 –ú–æ–¥–µ–ª—å (–∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π MLflow —Ñ–æ—Ä–º–∞—Ç)
        mlflow.sklearn.log_model(model, "sklearn_model")

        # 4.2 –ú–æ–¥–µ–ª—å –≤ pickle —Ñ–æ—Ä–º–∞—Ç–µ
        with open("/tmp/model.pkl", "wb") as f:
            pickle.dump(model, f)
        mlflow.log_artifact("/tmp/model.pkl", "model_artifacts")

        # 4.3 –ì—Ä–∞—Ñ–∏–∫ –≤–∞–∂–Ω–æ—Å—Ç–∏ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ (–¥–ª—è tree-based –º–æ–¥–µ–ª–µ–π)
        if hasattr(model, "feature_importances_"):
            fig, ax = plt.subplots(figsize=(10, 6))
            importances = pd.DataFrame({
                "feature": X_train.columns,
                "importance": model.feature_importances_
            }).sort_values("importance", ascending=True)

            ax.barh(importances["feature"], importances["importance"])
            ax.set_title("Feature Importance")
            ax.set_xlabel("Importance")

            fig.tight_layout()
            fig.savefig("/tmp/feature_importance.png", dpi=150)
            mlflow.log_artifact("/tmp/feature_importance.png", "plots")
            plt.close(fig)

        # 4.4 –ì—Ä–∞—Ñ–∏–∫ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π vs —Ä–µ–∞–ª—å–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π
        fig, ax = plt.subplots(figsize=(8, 8))
        ax.scatter(y_test, y_pred, alpha=0.5)
        ax.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)
        ax.set_xlabel("Actual Values")
        ax.set_ylabel("Predicted Values")
        ax.set_title("Predictions vs Actual")

        fig.tight_layout()
        fig.savefig("/tmp/predictions_scatter.png", dpi=150)
        mlflow.log_artifact("/tmp/predictions_scatter.png", "plots")
        plt.close(fig)

        # 4.5 CSV —Å –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è–º–∏
        predictions_df = pd.DataFrame({
            "actual": y_test.values,
            "predicted": y_pred,
            "error": y_test.values - y_pred,
            "abs_error": np.abs(y_test.values - y_pred)
        })
        predictions_df.to_csv("/tmp/predictions.csv", index=False)
        mlflow.log_artifact("/tmp/predictions.csv", "predictions")

        # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
        # 5. –õ–û–ì–ò–†–û–í–ê–ù–ò–ï –¢–ï–ì–û–í
        # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

        mlflow.set_tag("algorithm_family", get_algorithm_family(model_name))
        mlflow.set_tag("experiment_type", "model_comparison")
        mlflow.set_tag("dataset", "boston_housing")
        mlflow.set_tag("author", "data_scientist")
        mlflow.set_tag("environment", "development")
        mlflow.set_tag("mlflow.note.content", f"–≠–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç —Å {model_name}")

        # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
        # 6. –õ–û–ì–ò–†–û–í–ê–ù–ò–ï –ö–û–ù–§–ò–ì–£–†–ê–¶–ò–ò
        # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

        config = {
            "model_type": model_name,
            "params": custom_params,
            "data": {
                "train_size": len(X_train),
                "test_size": len(X_test),
                "features": list(X_train.columns)
            },
            "timestamp": datetime.now().isoformat()
        }

        with open("/tmp/config.json", "w") as f:
            json.dump(config, f, indent=2)
        mlflow.log_artifact("/tmp/config.json", "config")

        return mlflow.active_run().info.run_id
```

### –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –≤ DVCLive (–∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–∞)

```python
from dvclive import Live
import json

def run_dvclive_experiment(model, model_name, X_train, X_test, y_train, y_test, params):
    """–≠–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç —Å –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ–º —á–µ—Ä–µ–∑ DVCLive."""

    with Live(save_dvc_exp=True, dir=f"dvclive/{model_name}") as live:
        # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã
        live.log_param("model_type", model_name)
        for param_name, param_value in params.items():
            live.log_param(param_name, param_value)

        # –û–±—É—á–µ–Ω–∏–µ
        model.fit(X_train, y_train)
        y_pred = model.predict(X_test)

        # –ú–µ—Ç—Ä–∏–∫–∏
        live.log_metric("r2_score", r2_score(y_test, y_pred))
        live.log_metric("rmse", np.sqrt(mean_squared_error(y_test, y_pred)))
        live.log_metric("mae", mean_absolute_error(y_test, y_pred))

        # –ê—Ä—Ç–µ—Ñ–∞–∫—Ç –º–æ–¥–µ–ª–∏
        model_path = f"data/models/{model_name}.pkl"
        with open(model_path, "wb") as f:
            pickle.dump(model, f)
        live.log_artifact(model_path, type="model", name=model_name)

        # –ì—Ä–∞—Ñ–∏–∫ (DVCLive –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç matplotlib)
        if hasattr(model, "feature_importances_"):
            live.log_sklearn_plot("feature_importances", model, X_train.columns)
```

---

## –°–∏—Å—Ç–µ–º–∞ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤

### MLflow UI ‚Äî –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —á–µ—Ä–µ–∑ –≤–µ–±-–∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å

```bash
# –û—Ç–∫—Ä–æ–π—Ç–µ MLflow UI
open http://localhost:5000
```

**–§—É–Ω–∫—Ü–∏–∏ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è –≤ UI:**

1. **Compare** ‚Äî –≤—ã–±–æ—Ä –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤ –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
2. **Charts** ‚Äî –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –º–µ—Ç—Ä–∏–∫ –Ω–∞ –≥—Ä–∞—Ñ–∏–∫–∞—Ö
3. **Parallel Coordinates** ‚Äî –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã–µ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π
4. **Scatter Plot** ‚Äî scatter-–≥—Ä–∞—Ñ–∏–∫–∏ –¥–ª—è –ª—é–±—ã—Ö –¥–≤—É—Ö –º–µ—Ç—Ä–∏–∫/–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤

### –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —á–µ—Ä–µ–∑ Python API

```python
import mlflow
from mlflow.tracking import MlflowClient

def compare_experiments(experiment_name: str, metric: str = "r2_score", top_n: int = 10):
    """–°—Ä–∞–≤–Ω–µ–Ω–∏–µ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤ –ø—Ä–æ–≥—Ä–∞–º–º–Ω–æ."""

    client = MlflowClient()

    # –ü–æ–ª—É—á–µ–Ω–∏–µ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞
    experiment = client.get_experiment_by_name(experiment_name)
    if experiment is None:
        raise ValueError(f"–≠–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç '{experiment_name}' –Ω–µ –Ω–∞–π–¥–µ–Ω")

    # –ü–æ–ª—É—á–µ–Ω–∏–µ –≤—Å–µ—Ö –∑–∞–ø—É—Å–∫–æ–≤
    runs = client.search_runs(
        experiment_ids=[experiment.experiment_id],
        order_by=[f"metrics.{metric} DESC"],
        max_results=top_n
    )

    # –§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ —Ç–∞–±–ª–∏—Ü—ã —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
    comparison = []
    for run in runs:
        comparison.append({
            "run_id": run.info.run_id[:8],
            "run_name": run.info.run_name,
            "model_type": run.data.params.get("model_type", "unknown"),
            "r2_score": run.data.metrics.get("r2_score"),
            "rmse": run.data.metrics.get("rmse"),
            "mae": run.data.metrics.get("mae"),
            "train_time": run.data.metrics.get("train_time_seconds"),
        })

    df = pd.DataFrame(comparison)
    print(f"\nüìä –¢–û–ü-{top_n} —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤ –ø–æ {metric}:\n")
    print(df.to_string(index=False))

    return df


def compare_runs_detailed(run_ids: list[str]):
    """–î–µ—Ç–∞–ª—å–Ω–æ–µ —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã—Ö –∑–∞–ø—É—Å–∫–æ–≤."""

    client = MlflowClient()

    print("\n" + "=" * 80)
    print("üìä –î–ï–¢–ê–õ–¨–ù–û–ï –°–†–ê–í–ù–ï–ù–ò–ï –ó–ê–ü–£–°–ö–û–í")
    print("=" * 80)

    for run_id in run_ids:
        run = client.get_run(run_id)

        print(f"\nüîπ Run: {run.info.run_name} ({run_id[:8]})")
        print("-" * 40)

        print("  –ü–∞—Ä–∞–º–µ—Ç—Ä—ã:")
        for param, value in sorted(run.data.params.items()):
            print(f"    {param}: {value}")

        print("  –ú–µ—Ç—Ä–∏–∫–∏:")
        for metric, value in sorted(run.data.metrics.items()):
            print(f"    {metric}: {value:.4f}" if isinstance(value, float) else f"    {metric}: {value}")

        print("  –¢–µ–≥–∏:")
        for tag, value in sorted(run.data.tags.items()):
            if not tag.startswith("mlflow."):
                print(f"    {tag}: {value}")


# –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ
compare_experiments("boston_housing_model_comparison", metric="r2_score", top_n=5)
compare_runs_detailed(["run_id_1", "run_id_2", "run_id_3"])
```

### –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è

```python
import matplotlib.pyplot as plt
import seaborn as sns

def plot_metrics_comparison(experiment_name: str):
    """–í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è –º–µ—Ç—Ä–∏–∫."""

    client = MlflowClient()
    experiment = client.get_experiment_by_name(experiment_name)

    runs = client.search_runs(
        experiment_ids=[experiment.experiment_id],
        max_results=50
    )

    # –°–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö
    data = []
    for run in runs:
        data.append({
            "model": run.data.params.get("model_type", "unknown"),
            "r2_score": run.data.metrics.get("r2_score", 0),
            "rmse": run.data.metrics.get("rmse", 0),
            "mae": run.data.metrics.get("mae", 0),
            "family": run.data.tags.get("algorithm_family", "unknown")
        })

    df = pd.DataFrame(data)

    # –ì—Ä–∞—Ñ–∏–∫ 1: R¬≤ Score –ø–æ –º–æ–¥–µ–ª—è–º
    fig, axes = plt.subplots(2, 2, figsize=(14, 10))

    # Bar chart: R¬≤ Score
    ax1 = axes[0, 0]
    df_sorted = df.sort_values("r2_score", ascending=True)
    colors = df_sorted["family"].map({
        "linear": "#3498db",
        "tree_ensemble": "#2ecc71",
        "other": "#e74c3c"
    })
    ax1.barh(df_sorted["model"], df_sorted["r2_score"], color=colors)
    ax1.set_xlabel("R¬≤ Score")
    ax1.set_title("R¬≤ Score –ø–æ –º–æ–¥–µ–ª—è–º")
    ax1.axvline(x=0.8, color='r', linestyle='--', label='Threshold (0.8)')

    # Bar chart: RMSE
    ax2 = axes[0, 1]
    df_sorted = df.sort_values("rmse", ascending=False)
    ax2.barh(df_sorted["model"], df_sorted["rmse"], color="#9b59b6")
    ax2.set_xlabel("RMSE")
    ax2.set_title("RMSE –ø–æ –º–æ–¥–µ–ª—è–º (–º–µ–Ω—å—à–µ = –ª—É—á—à–µ)")

    # Scatter: R¬≤ vs RMSE
    ax3 = axes[1, 0]
    for family in df["family"].unique():
        family_df = df[df["family"] == family]
        ax3.scatter(family_df["r2_score"], family_df["rmse"], label=family, s=100, alpha=0.7)
    ax3.set_xlabel("R¬≤ Score")
    ax3.set_ylabel("RMSE")
    ax3.set_title("R¬≤ Score vs RMSE")
    ax3.legend()

    # Box plot –ø–æ —Å–µ–º–µ–π—Å—Ç–≤–∞–º
    ax4 = axes[1, 1]
    df.boxplot(column="r2_score", by="family", ax=ax4)
    ax4.set_title("–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ R¬≤ –ø–æ —Å–µ–º–µ–π—Å—Ç–≤–∞–º –∞–ª–≥–æ—Ä–∏—Ç–º–æ–≤")
    ax4.set_xlabel("Algorithm Family")
    ax4.set_ylabel("R¬≤ Score")
    plt.suptitle("")

    plt.tight_layout()
    plt.savefig("experiment_comparison.png", dpi=150)
    plt.show()
```

### DVC –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤

```bash
# –ü—Ä–æ—Å–º–æ—Ç—Ä –≤—Å–µ—Ö —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤
dvc exp show

# –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã—Ö —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤
dvc exp diff exp-abc123 exp-def456

# –¢–∞–±–ª–∏—á–Ω—ã–π –≤—ã–≤–æ–¥ —Å —Å–æ—Ä—Ç–∏—Ä–æ–≤–∫–æ–π
dvc exp show --sort-by r2_score --sort-order desc

# –≠–∫—Å–ø–æ—Ä—Ç –≤ CSV
dvc exp show --csv > experiments.csv
```

---

## –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –∏ –ø–æ–∏—Å–∫ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤

### MLflow Search API

```python
from mlflow.tracking import MlflowClient

client = MlflowClient()

# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# –§–ò–õ–¨–¢–†–ê–¶–ò–Ø –ü–û –ú–ï–¢–†–ò–ö–ê–ú
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

# –ù–∞–π—Ç–∏ –≤—Å–µ –∑–∞–ø—É—Å–∫–∏ —Å R¬≤ > 0.85
runs = client.search_runs(
    experiment_ids=["1"],
    filter_string="metrics.r2_score > 0.85",
    order_by=["metrics.r2_score DESC"]
)

# –ù–∞–π—Ç–∏ –∑–∞–ø—É—Å–∫–∏ —Å RMSE < 3.0
runs = client.search_runs(
    experiment_ids=["1"],
    filter_string="metrics.rmse < 3.0"
)

# –ö–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ñ–∏–ª—å—Ç—Ä: R¬≤ > 0.8 AND RMSE < 3.5
runs = client.search_runs(
    experiment_ids=["1"],
    filter_string="metrics.r2_score > 0.8 AND metrics.rmse < 3.5"
)

# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# –§–ò–õ–¨–¢–†–ê–¶–ò–Ø –ü–û –ü–ê–†–ê–ú–ï–¢–†–ê–ú
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

# –ù–∞–π—Ç–∏ –≤—Å–µ Random Forest –º–æ–¥–µ–ª–∏
runs = client.search_runs(
    experiment_ids=["1"],
    filter_string="params.model_type = 'random_forest'"
)

# –ù–∞–π—Ç–∏ –º–æ–¥–µ–ª–∏ —Å n_estimators >= 100
runs = client.search_runs(
    experiment_ids=["1"],
    filter_string="params.n_estimators >= '100'"  # —Å—Ç—Ä–æ–∫–æ–≤–æ–µ —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ!
)

# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# –§–ò–õ–¨–¢–†–ê–¶–ò–Ø –ü–û –¢–ï–ì–ê–ú
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

# –ù–∞–π—Ç–∏ –≤—Å–µ tree-based –º–æ–¥–µ–ª–∏
runs = client.search_runs(
    experiment_ids=["1"],
    filter_string="tags.algorithm_family = 'tree_ensemble'"
)

# –ù–∞–π—Ç–∏ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—ã –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ –∞–≤—Ç–æ—Ä–∞
runs = client.search_runs(
    experiment_ids=["1"],
    filter_string="tags.author = 'data_scientist'"
)

# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# –§–ò–õ–¨–¢–†–ê–¶–ò–Ø –ü–û –°–¢–ê–¢–£–°–£ –ò –í–†–ï–ú–ï–ù–ò
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

# –¢–æ–ª—å–∫–æ —É—Å–ø–µ—à–Ω—ã–µ –∑–∞–ø—É—Å–∫–∏
runs = client.search_runs(
    experiment_ids=["1"],
    filter_string="attributes.status = 'FINISHED'"
)

# –ó–∞–ø—É—Å–∫–∏ –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–µ 7 –¥–Ω–µ–π
from datetime import datetime, timedelta
week_ago = int((datetime.now() - timedelta(days=7)).timestamp() * 1000)

runs = client.search_runs(
    experiment_ids=["1"],
    filter_string=f"attributes.start_time > {week_ago}"
)

# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# –ö–û–ú–ü–õ–ï–ö–°–ù–´–ï –ó–ê–ü–†–û–°–´
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

# –õ—É—á—à–∏–µ tree-based –º–æ–¥–µ–ª–∏ —Å R¬≤ > 0.85
runs = client.search_runs(
    experiment_ids=["1"],
    filter_string="""
        tags.algorithm_family = 'tree_ensemble'
        AND metrics.r2_score > 0.85
        AND attributes.status = 'FINISHED'
    """,
    order_by=["metrics.r2_score DESC"],
    max_results=10
)

for run in runs:
    print(f"{run.info.run_name}: R¬≤={run.data.metrics['r2_score']:.4f}")
```

### –£—Ç–∏–ª–∏—Ç–∞ –¥–ª—è –ø–æ–∏—Å–∫–∞

```python
def search_experiments(
    experiment_name: str,
    metric_filters: dict = None,
    param_filters: dict = None,
    tag_filters: dict = None,
    top_n: int = 10,
    sort_by: str = "r2_score",
    ascending: bool = False
):
    """
    –£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –ø–æ–∏—Å–∫–∞ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤.

    Args:
        experiment_name: –ò–º—è —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞
        metric_filters: {"r2_score": "> 0.8", "rmse": "< 4.0"}
        param_filters: {"model_type": "random_forest"}
        tag_filters: {"algorithm_family": "tree_ensemble"}
        top_n: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        sort_by: –ú–µ—Ç—Ä–∏–∫–∞ –¥–ª—è —Å–æ—Ä—Ç–∏—Ä–æ–≤–∫–∏
        ascending: –ü–æ—Ä—è–¥–æ–∫ —Å–æ—Ä—Ç–∏—Ä–æ–≤–∫–∏

    Returns:
        DataFrame —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏
    """
    client = MlflowClient()
    experiment = client.get_experiment_by_name(experiment_name)

    # –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ filter_string
    conditions = []

    if metric_filters:
        for metric, condition in metric_filters.items():
            conditions.append(f"metrics.{metric} {condition}")

    if param_filters:
        for param, value in param_filters.items():
            conditions.append(f"params.{param} = '{value}'")

    if tag_filters:
        for tag, value in tag_filters.items():
            conditions.append(f"tags.{tag} = '{value}'")

    filter_string = " AND ".join(conditions) if conditions else ""

    # –í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –ø–æ–∏—Å–∫–∞
    order_direction = "ASC" if ascending else "DESC"
    runs = client.search_runs(
        experiment_ids=[experiment.experiment_id],
        filter_string=filter_string,
        order_by=[f"metrics.{sort_by} {order_direction}"],
        max_results=top_n
    )

    # –§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    results = []
    for run in runs:
        results.append({
            "run_id": run.info.run_id[:8],
            "run_name": run.info.run_name,
            "model_type": run.data.params.get("model_type"),
            **{f"metric_{k}": v for k, v in run.data.metrics.items()}
        })

    return pd.DataFrame(results)


# –ü—Ä–∏–º–µ—Ä—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

# –ù–∞–π—Ç–∏ –ª—É—á—à–∏–µ tree-based –º–æ–¥–µ–ª–∏
df = search_experiments(
    "boston_housing_model_comparison",
    metric_filters={"r2_score": "> 0.85"},
    tag_filters={"algorithm_family": "tree_ensemble"},
    top_n=5
)

# –ù–∞–π—Ç–∏ –≤—Å–µ Random Forest —Å —Ä–∞–∑–Ω—ã–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏
df = search_experiments(
    "boston_housing_model_comparison",
    param_filters={"model_type": "random_forest"},
    sort_by="r2_score"
)

# –ù–∞–π—Ç–∏ –º–æ–¥–µ–ª–∏ —Å –Ω–∏–∑–∫–æ–π –æ—à–∏–±–∫–æ–π
df = search_experiments(
    "boston_housing_model_comparison",
    metric_filters={"rmse": "< 3.0", "mae": "< 2.5"},
    top_n=10
)
```

### –ü–æ–∏—Å–∫ —á–µ—Ä–µ–∑ MLflow UI

–í –≤–µ–±-–∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–µ MLflow –¥–æ—Å—Ç—É–ø–µ–Ω –ø–æ–∏—Å–∫ —á–µ—Ä–µ–∑ —Å—Ç—Ä–æ–∫—É —Ñ–∏–ª—å—Ç—Ä–∞:

```
# –ü—Ä–∏–º–µ—Ä—ã —Ñ–∏–ª—å—Ç—Ä–æ–≤ –¥–ª—è UI
metrics.r2_score > 0.85
params.model_type = "random_forest"
tags.algorithm_family = "tree_ensemble"
metrics.r2_score > 0.8 AND metrics.rmse < 4.0
```

### –ü–æ–∏—Å–∫ —á–µ—Ä–µ–∑ DVC

```bash
# –ü–æ–∏—Å–∫ –ø–æ –º–µ—Ç—Ä–∏–∫–∞–º
dvc exp show --drop-param --keep-metric r2_score --sort-by r2_score

# –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –ø–æ –∑–Ω–∞—á–µ–Ω–∏—é
dvc exp show | grep "random_forest"

# –≠–∫—Å–ø–æ—Ä—Ç –¥–ª—è –¥–∞–ª—å–Ω–µ–π—à–µ–≥–æ –∞–Ω–∞–ª–∏–∑–∞
dvc exp show --json > experiments.json
```

---

## –ê–≤—Ç–æ–º–∞—Ç–∏–∑–∞—Ü–∏—è —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤

### Bash —Å–∫—Ä–∏–ø—Ç –¥–ª—è –∑–∞–ø—É—Å–∫–∞ –≤—Å–µ—Ö —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤

```bash
#!/bin/bash
# –ó–∞–ø—É—Å–∫ –≤—Å–µ—Ö 19 —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤

set -e

echo "üöÄ –ó–∞–ø—É—Å–∫ –≤—Å–µ—Ö —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤..."

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –æ–∫—Ä—É–∂–µ–Ω–∏—è
export MLFLOW_TRACKING_URI=http://localhost:5000
export MLFLOW_TRACKING_USERNAME=admin
export MLFLOW_TRACKING_PASSWORD=password

# –ó–∞–ø—É—Å–∫ –≤—Å–µ—Ö —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤ —á–µ—Ä–µ–∑ –µ–¥–∏–Ω—ã–π —Å–∫—Ä–∏–ø—Ç
python scripts/run_experiments.py

echo "üéâ –í—Å–µ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—ã –∑–∞–≤–µ—Ä—à–µ–Ω—ã!"
echo "–û—Ç–∫—Ä–æ–π—Ç–µ MLflow UI: http://localhost:5000"
echo "–†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ data/experiments/results_summary.csv"
```

### Grid Search —Å –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ–º

```python
from sklearn.model_selection import GridSearchCV
import mlflow

def run_grid_search_experiment(
    model_name: str,
    param_grid: dict,
    X_train, X_test, y_train, y_test,
    cv: int = 5
):
    """Grid Search —Å –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–º –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ–º –≤ MLflow."""

    mlflow.set_experiment("boston_housing_grid_search")

    with mlflow.start_run(run_name=f"gridsearch_{model_name}"):
        # –°–æ–∑–¥–∞–Ω–∏–µ –±–∞–∑–æ–≤–æ–π –º–æ–¥–µ–ª–∏
        base_model = create_model(model_name)

        # Grid Search
        grid_search = GridSearchCV(
            estimator=base_model,
            param_grid=param_grid,
            cv=cv,
            scoring="r2",
            n_jobs=-1,
            verbose=1
        )

        grid_search.fit(X_train, y_train)

        # –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –ª—É—á—à–∏—Ö –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
        mlflow.log_param("model_type", model_name)
        mlflow.log_param("cv_folds", cv)
        for param, value in grid_search.best_params_.items():
            mlflow.log_param(f"best_{param}", value)

        # –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ CV
        mlflow.log_metric("best_cv_score", grid_search.best_score_)

        # –û—Ü–µ–Ω–∫–∞ –Ω–∞ —Ç–µ—Å—Ç–æ–≤–æ–π –≤—ã–±–æ—Ä–∫–µ
        y_pred = grid_search.predict(X_test)
        test_r2 = r2_score(y_test, y_pred)
        test_rmse = np.sqrt(mean_squared_error(y_test, y_pred))

        mlflow.log_metric("test_r2_score", test_r2)
        mlflow.log_metric("test_rmse", test_rmse)

        # –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –ª—É—á—à–µ–π –º–æ–¥–µ–ª–∏
        mlflow.sklearn.log_model(grid_search.best_estimator_, "best_model")

        # –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –≤—Å–µ—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ CV
        cv_results = pd.DataFrame(grid_search.cv_results_)
        cv_results.to_csv("/tmp/cv_results.csv", index=False)
        mlflow.log_artifact("/tmp/cv_results.csv", "cv_results")

        return grid_search.best_estimator_, grid_search.best_params_


# –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
param_grid = {
    "n_estimators": [50, 100, 200],
    "max_depth": [5, 10, 15, None],
    "min_samples_split": [2, 5, 10]
}

best_model, best_params = run_grid_search_experiment(
    "random_forest",
    param_grid,
    X_train, X_test, y_train, y_test
)
```

---

## Best Practices

### 1. –ò–º–µ–Ω–æ–≤–∞–Ω–∏–µ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤

```python
# ‚úÖ –•–æ—Ä–æ—à–æ: –∏–Ω—Ñ–æ—Ä–º–∞—Ç–∏–≤–Ω—ã–µ –∏–º–µ–Ω–∞
mlflow.set_experiment("boston_housing_regression_v2")
run_name = f"rf_n{n_estimators}_d{max_depth}_{datetime.now().strftime('%Y%m%d')}"

# ‚ùå –ü–ª–æ—Ö–æ: –Ω–µ–∏–Ω—Ñ–æ—Ä–º–∞—Ç–∏–≤–Ω—ã–µ –∏–º–µ–Ω–∞
mlflow.set_experiment("test")
run_name = "experiment_1"
```

### 2. –°—Ç—Ä—É–∫—Ç—É—Ä–∞ —Ç–µ–≥–æ–≤

```python
# –†–µ–∫–æ–º–µ–Ω–¥—É–µ–º—ã–µ —Ç–µ–≥–∏
mlflow.set_tag("algorithm_family", "tree_ensemble")  # –°–µ–º–µ–π—Å—Ç–≤–æ –∞–ª–≥–æ—Ä–∏—Ç–º–∞
mlflow.set_tag("experiment_type", "model_comparison") # –¢–∏–ø —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞
mlflow.set_tag("dataset", "boston_housing")          # –ù–∞–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö
mlflow.set_tag("data_version", "v1.2")               # –í–µ—Ä—Å–∏—è –¥–∞–Ω–Ω—ã—Ö
mlflow.set_tag("author", "your_name")                # –ê–≤—Ç–æ—Ä
mlflow.set_tag("environment", "development")         # –û–∫—Ä—É–∂–µ–Ω–∏–µ
```

### 3. –í–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏–º–æ—Å—Ç—å

```python
# –§–∏–∫—Å–∞—Ü–∏—è seed
random_state = 42
mlflow.log_param("random_state", random_state)

# –í–µ—Ä—Å–∏–∏ –±–∏–±–ª–∏–æ—Ç–µ–∫
mlflow.log_param("sklearn_version", sklearn.__version__)
mlflow.log_param("python_version", sys.version)

# –•—ç—à –¥–∞–Ω–Ω—ã—Ö
data_hash = hashlib.md5(X_train.values.tobytes()).hexdigest()[:8]
mlflow.log_param("data_hash", data_hash)
```

### 4. –î–æ–∫—É–º–µ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤

```python
# –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –∑–∞–º–µ—Ç–æ–∫ –∫ –∑–∞–ø—É—Å–∫—É
mlflow.set_tag("mlflow.note.content", """
## –¶–µ–ª—å —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞
–ü—Ä–æ–≤–µ—Ä–∫–∞ –≤–ª–∏—è–Ω–∏—è –≥–ª—É–±–∏–Ω—ã –¥–µ—Ä–µ–≤–∞ –Ω–∞ –∫–∞—á–µ—Å—Ç–≤–æ –º–æ–¥–µ–ª–∏.

## –ì–∏–ø–æ—Ç–µ–∑–∞
–£–≤–µ–ª–∏—á–µ–Ω–∏–µ max_depth —É–ª—É—á—à–∏—Ç R¬≤ –¥–æ –æ–ø—Ä–µ–¥–µ–ª—ë–Ω–Ω–æ–≥–æ –ø—Ä–µ–¥–µ–ª–∞.

## –†–µ–∑—É–ª—å—Ç–∞—Ç—ã
- max_depth=10: R¬≤=0.85
- max_depth=15: R¬≤=0.87
- max_depth=20: R¬≤=0.86 (–ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ)
""")
```

### 5. –û—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏—è –∞—Ä—Ç–µ—Ñ–∞–∫—Ç–æ–≤

```
artifacts/
‚îú‚îÄ‚îÄ sklearn_model/
‚îÇ   ‚îú‚îÄ‚îÄ model.pkl
‚îÇ   ‚îú‚îÄ‚îÄ MLmodel
‚îÇ   ‚îú‚îÄ‚îÄ conda.yaml
‚îÇ   ‚îî‚îÄ‚îÄ requirements.txt
‚îú‚îÄ‚îÄ model_artifacts/
‚îÇ   ‚îî‚îÄ‚îÄ {model_name}.pkl
‚îú‚îÄ‚îÄ plots/
‚îÇ   ‚îú‚îÄ‚îÄ predictions_scatter.png
‚îÇ   ‚îú‚îÄ‚îÄ residuals.png
‚îÇ   ‚îî‚îÄ‚îÄ feature_importance.png  # –¥–ª—è tree-based –º–æ–¥–µ–ª–µ–π
‚îú‚îÄ‚îÄ predictions/
‚îÇ   ‚îî‚îÄ‚îÄ predictions.csv
‚îî‚îÄ‚îÄ config/
    ‚îî‚îÄ‚îÄ experiment_config.json
```

---

## üöÄ –ë—ã—Å—Ç—Ä—ã–π —Å—Ç–∞—Ä—Ç

```bash
# 1. –ó–∞–ø—É—Å—Ç–∏—Ç–µ –∏–Ω—Ñ—Ä–∞—Å—Ç—Ä—É–∫—Ç—É—Ä—É
docker-compose up -d mlflow minio

# 2. –ù–∞—Å—Ç—Ä–æ–π—Ç–µ –æ–∫—Ä—É–∂–µ–Ω–∏–µ
export MLFLOW_TRACKING_URI=http://localhost:5000
export MLFLOW_TRACKING_USERNAME=admin
export MLFLOW_TRACKING_PASSWORD=password

# 3. –ó–∞–ø—É—Å—Ç–∏—Ç–µ –≤—Å–µ 19 —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤
python scripts/run_experiments.py

# 4. –û—Ç–∫—Ä–æ–π—Ç–µ UI –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
open http://localhost:5000

# 5. –ü—Ä–æ—Å–º–æ—Ç—Ä–∏—Ç–µ —Å–≤–æ–¥–∫—É —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
cat data/experiments/results_summary.csv
```

---

## üìö –ü–æ–ª–µ–∑–Ω—ã–µ —Å—Å—ã–ª–∫–∏

- [MLflow Documentation](https://mlflow.org/docs/latest/index.html)
- [MLflow Search Syntax](https://mlflow.org/docs/latest/search-syntax.html)
- [DVCLive Documentation](https://dvc.org/doc/dvclive)
- [scikit-learn Model Selection](https://scikit-learn.org/stable/model_selection.html)
