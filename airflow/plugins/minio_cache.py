"""
MinIO Cache Utilities –¥–ª—è Airflow
=================================
–ú–æ–¥—É–ª—å –¥–ª—è –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏—è –∞—Ä—Ç–µ—Ñ–∞–∫—Ç–æ–≤ –≤ MinIO —Å –ø—Ä–æ–≤–µ—Ä–∫–æ–π —Ö—ç—à–µ–π.
"""

import hashlib
import json
import os
from pathlib import Path
from typing import Optional

import boto3
from botocore.client import Config
from botocore.exceptions import ClientError
from loguru import logger


class MinIOCache:
    """
    –ö–ª–∞—Å—Å –¥–ª—è –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏—è –∞—Ä—Ç–µ—Ñ–∞–∫—Ç–æ–≤ –≤ MinIO.

    –ü–æ–∑–≤–æ–ª—è–µ—Ç:
    - –ü—Ä–æ–≤–µ—Ä—è—Ç—å —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ —Ñ–∞–π–ª–æ–≤
    - –í—ã—á–∏—Å–ª—è—Ç—å —Ö—ç—à–∏ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –∏–∑–º–µ–Ω–µ–Ω–∏–π
    - –ó–∞–≥—Ä—É–∂–∞—Ç—å/—Å–∫–∞—á–∏–≤–∞—Ç—å –∞—Ä—Ç–µ—Ñ–∞–∫—Ç—ã
    """

    def __init__(
        self,
        endpoint_url: Optional[str] = None,
        access_key: Optional[str] = None,
        secret_key: Optional[str] = None,
        bucket_name: str = "airflow-cache",
    ):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–ª–∏–µ–Ω—Ç–∞ MinIO.

        Args:
            endpoint_url: URL MinIO —Å–µ—Ä–≤–µ—Ä–∞
            access_key: Access Key
            secret_key: Secret Key
            bucket_name: –ò–º—è –±–∞–∫–µ—Ç–∞ –¥–ª—è –∫—ç—à–∞
        """
        self.endpoint_url = endpoint_url or os.environ.get(
            "MLFLOW_S3_ENDPOINT_URL", "http://minio:9000"
        )
        self.access_key = access_key or os.environ.get(
            "AWS_ACCESS_KEY_ID", "minioadmin"
        )
        self.secret_key = secret_key or os.environ.get(
            "AWS_SECRET_ACCESS_KEY", "minioadmin"
        )
        self.bucket_name = bucket_name

        self.client = boto3.client(
            "s3",
            endpoint_url=self.endpoint_url,
            aws_access_key_id=self.access_key,
            aws_secret_access_key=self.secret_key,
            config=Config(signature_version="s3v4"),
        )

        self._ensure_bucket_exists()

    def _ensure_bucket_exists(self) -> None:
        """–°–æ–∑–¥–∞—ë—Ç –±–∞–∫–µ—Ç –µ—Å–ª–∏ –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç."""
        try:
            self.client.head_bucket(Bucket=self.bucket_name)
        except ClientError:
            self.client.create_bucket(Bucket=self.bucket_name)
            logger.info(f"üì¶ –°–æ–∑–¥–∞–Ω –±–∞–∫–µ—Ç: {self.bucket_name}")

    def compute_file_hash(self, file_path: str) -> str:
        """
        –í—ã—á–∏—Å–ª—è–µ—Ç MD5 —Ö—ç—à —Ñ–∞–π–ª–∞.

        Args:
            file_path: –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É

        Returns:
            MD5 —Ö—ç—à –≤ hex —Ñ–æ—Ä–º–∞—Ç–µ
        """
        hash_md5 = hashlib.md5()
        with open(file_path, "rb") as f:
            for chunk in iter(lambda: f.read(4096), b""):
                hash_md5.update(chunk)
        return hash_md5.hexdigest()

    def compute_params_hash(self, params: dict) -> str:
        """
        –í—ã—á–∏—Å–ª—è–µ—Ç —Ö—ç—à –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ (–¥–ª—è –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏—è –ø–æ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º).

        Args:
            params: –°–ª–æ–≤–∞—Ä—å –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤

        Returns:
            MD5 —Ö—ç—à –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
        """
        params_str = json.dumps(params, sort_keys=True)
        return hashlib.md5(params_str.encode()).hexdigest()

    def exists(self, key: str) -> bool:
        """
        –ü—Ä–æ–≤–µ—Ä—è–µ—Ç —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ –æ–±—ä–µ–∫—Ç–∞ –≤ MinIO.

        Args:
            key: –ö–ª—é—á –æ–±—ä–µ–∫—Ç–∞

        Returns:
            True –µ—Å–ª–∏ –æ–±—ä–µ–∫—Ç —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
        """
        try:
            self.client.head_object(Bucket=self.bucket_name, Key=key)
            return True
        except ClientError:
            return False

    def get_cache_key(
        self, prefix: str, params: dict, data_hash: Optional[str] = None
    ) -> str:
        """
        –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –∫–ª—é—á –∫—ç—à–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –∏ —Ö—ç—à–∞ –¥–∞–Ω–Ω—ã—Ö.

        Args:
            prefix: –ü—Ä–µ—Ñ–∏–∫—Å –∫–ª—é—á–∞ (–Ω–∞–ø—Ä–∏–º–µ—Ä, "models/random_forest")
            params: –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –º–æ–¥–µ–ª–∏/—ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞
            data_hash: –•—ç—à –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)

        Returns:
            –ö–ª—é—á –∫—ç—à–∞
        """
        params_hash = self.compute_params_hash(params)
        if data_hash:
            return f"{prefix}_{params_hash}_{data_hash}"
        return f"{prefix}_{params_hash}"

    def check_cache(
        self,
        prefix: str,
        params: dict,
        data_path: Optional[str] = None,
    ) -> tuple[bool, str]:
        """
        –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –Ω–∞–ª–∏—á–∏–µ –∫—ç—à–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞.

        Args:
            prefix: –ü—Ä–µ—Ñ–∏–∫—Å –∫–ª—é—á–∞
            params: –ü–∞—Ä–∞–º–µ—Ç—Ä—ã
            data_path: –ü—É—Ç—å –∫ –≤—Ö–æ–¥–Ω—ã–º –¥–∞–Ω–Ω—ã–º (–¥–ª—è –≤—ã—á–∏—Å–ª–µ–Ω–∏—è —Ö—ç—à–∞)

        Returns:
            (exists, cache_key) - —Å—É—â–µ—Å—Ç–≤—É–µ—Ç –ª–∏ –∫—ç—à –∏ –∫–ª—é—á –∫—ç—à–∞
        """
        data_hash = None
        if data_path and Path(data_path).exists():
            data_hash = self.compute_file_hash(data_path)

        cache_key = self.get_cache_key(prefix, params, data_hash)
        exists = self.exists(cache_key)

        if exists:
            logger.info(f"‚úÖ –ö—ç—à –Ω–∞–π–¥–µ–Ω: {cache_key}")
        else:
            logger.info(f"‚ùå –ö—ç—à –Ω–µ –Ω–∞–π–¥–µ–Ω: {cache_key}")

        return exists, cache_key

    def upload(self, local_path: str, key: str) -> str:
        """
        –ó–∞–≥—Ä—É–∂–∞–µ—Ç —Ñ–∞–π–ª –≤ MinIO.

        Args:
            local_path: –õ–æ–∫–∞–ª—å–Ω—ã–π –ø—É—Ç—å –∫ —Ñ–∞–π–ª—É
            key: –ö–ª—é—á –≤ MinIO

        Returns:
            S3 URI –∑–∞–≥—Ä—É–∂–µ–Ω–Ω–æ–≥–æ —Ñ–∞–π–ª–∞
        """
        self.client.upload_file(local_path, self.bucket_name, key)
        s3_uri = f"s3://{self.bucket_name}/{key}"
        logger.info(f"üì§ –ó–∞–≥—Ä—É–∂–µ–Ω–æ: {s3_uri}")
        return s3_uri

    def download(self, key: str, local_path: str) -> str:
        """
        –°–∫–∞—á–∏–≤–∞–µ—Ç —Ñ–∞–π–ª –∏–∑ MinIO.

        Args:
            key: –ö–ª—é—á –≤ MinIO
            local_path: –õ–æ–∫–∞–ª—å–Ω—ã–π –ø—É—Ç—å –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è

        Returns:
            –õ–æ–∫–∞–ª—å–Ω—ã–π –ø—É—Ç—å –∫ —Å–∫–∞—á–∞–Ω–Ω–æ–º—É —Ñ–∞–π–ª—É
        """
        Path(local_path).parent.mkdir(parents=True, exist_ok=True)
        self.client.download_file(self.bucket_name, key, local_path)
        logger.info(f"üì• –°–∫–∞—á–∞–Ω–æ: {local_path}")
        return local_path

    def put_json(self, key: str, data: dict) -> str:
        """
        –°–æ—Ö—Ä–∞–Ω—è–µ—Ç JSON –≤ MinIO.

        Args:
            key: –ö–ª—é—á –≤ MinIO
            data: –°–ª–æ–≤–∞—Ä—å –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è

        Returns:
            S3 URI
        """
        json_bytes = json.dumps(data, indent=2).encode("utf-8")
        self.client.put_object(
            Bucket=self.bucket_name,
            Key=key,
            Body=json_bytes,
            ContentType="application/json",
        )
        return f"s3://{self.bucket_name}/{key}"

    def get_json(self, key: str) -> dict:
        """
        –ß–∏—Ç–∞–µ—Ç JSON –∏–∑ MinIO.

        Args:
            key: –ö–ª—é—á –≤ MinIO

        Returns:
            –°–ª–æ–≤–∞—Ä—å —Å –¥–∞–Ω–Ω—ã–º–∏
        """
        response = self.client.get_object(Bucket=self.bucket_name, Key=key)
        return json.loads(response["Body"].read().decode("utf-8"))


def check_model_cache(
    model_name: str,
    params: dict,
    data_path: str,
    bucket_name: str = "airflow-cache",
) -> bool:
    """
    –§—É–Ω–∫—Ü–∏—è –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è —Å ShortCircuitOperator.

    –ü—Ä–æ–≤–µ—Ä—è–µ—Ç, –µ—Å—Ç—å –ª–∏ –∫—ç—à–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –º–æ–¥–µ–ª—å —Å –∑–∞–¥–∞–Ω–Ω—ã–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏.
    –ï—Å–ª–∏ –º–æ–¥–µ–ª—å –Ω–∞–π–¥–µ–Ω–∞ –≤ –∫—ç—à–µ - –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç False (–ø—Ä–æ–ø—É—Å–∫ downstream –∑–∞–¥–∞—á).

    Args:
        model_name: –ò–º—è –º–æ–¥–µ–ª–∏
        params: –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –º–æ–¥–µ–ª–∏
        data_path: –ü—É—Ç—å –∫ –¥–∞–Ω–Ω—ã–º
        bucket_name: –ò–º—è –±–∞–∫–µ—Ç–∞

    Returns:
        True –µ—Å–ª–∏ –Ω—É–∂–Ω–æ –æ–±—É—á–∞—Ç—å (–∫—ç—à –Ω–µ –Ω–∞–π–¥–µ–Ω),
        False –µ—Å–ª–∏ –º–æ–∂–Ω–æ –ø—Ä–æ–ø—É—Å—Ç–∏—Ç—å (–∫—ç—à –Ω–∞–π–¥–µ–Ω)
    """
    cache = MinIOCache(bucket_name=bucket_name)
    prefix = f"models/{model_name}"
    exists, _ = cache.check_cache(prefix, params, data_path)

    # ShortCircuitOperator: True = –ø—Ä–æ–¥–æ–ª–∂–∏—Ç—å, False = –ø—Ä–æ–ø—É—Å—Ç–∏—Ç—å
    return not exists


def get_cached_model(
    model_name: str,
    params: dict,
    data_path: str,
    local_path: str,
    bucket_name: str = "airflow-cache",
) -> Optional[str]:
    """
    –ü–æ–ª—É—á–∞–µ—Ç –∫—ç—à–∏—Ä–æ–≤–∞–Ω–Ω—É—é –º–æ–¥–µ–ª—å –∏–∑ MinIO.

    Args:
        model_name: –ò–º—è –º–æ–¥–µ–ª–∏
        params: –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –º–æ–¥–µ–ª–∏
        data_path: –ü—É—Ç—å –∫ –¥–∞–Ω–Ω—ã–º
        local_path: –õ–æ–∫–∞–ª—å–Ω—ã–π –ø—É—Ç—å –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è
        bucket_name: –ò–º—è –±–∞–∫–µ—Ç–∞

    Returns:
        –õ–æ–∫–∞–ª—å–Ω—ã–π –ø—É—Ç—å –∫ –º–æ–¥–µ–ª–∏ –∏–ª–∏ None –µ—Å–ª–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞
    """
    cache = MinIOCache(bucket_name=bucket_name)
    prefix = f"models/{model_name}"
    exists, cache_key = cache.check_cache(prefix, params, data_path)

    if exists:
        return cache.download(f"{cache_key}.pkl", local_path)
    return None


def save_model_to_cache(
    model_path: str,
    model_name: str,
    params: dict,
    data_path: str,
    metrics: dict,
    bucket_name: str = "airflow-cache",
) -> str:
    """
    –°–æ—Ö—Ä–∞–Ω—è–µ—Ç –æ–±—É—á–µ–Ω–Ω—É—é –º–æ–¥–µ–ª—å –≤ –∫—ç—à MinIO.

    Args:
        model_path: –õ–æ–∫–∞–ª—å–Ω—ã–π –ø—É—Ç—å –∫ –º–æ–¥–µ–ª–∏
        model_name: –ò–º—è –º–æ–¥–µ–ª–∏
        params: –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –º–æ–¥–µ–ª–∏
        data_path: –ü—É—Ç—å –∫ –¥–∞–Ω–Ω—ã–º
        metrics: –ú–µ—Ç—Ä–∏–∫–∏ –º–æ–¥–µ–ª–∏
        bucket_name: –ò–º—è –±–∞–∫–µ—Ç–∞

    Returns:
        S3 URI —Å–æ—Ö—Ä–∞–Ω—ë–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏
    """
    cache = MinIOCache(bucket_name=bucket_name)

    # –í—ã—á–∏—Å–ª—è–µ–º —Ö—ç—à –¥–∞–Ω–Ω—ã—Ö
    data_hash = cache.compute_file_hash(data_path) if Path(data_path).exists() else None

    # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –∫–ª—é—á
    prefix = f"models/{model_name}"
    cache_key = cache.get_cache_key(prefix, params, data_hash)

    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–æ–¥–µ–ª—å
    model_uri = cache.upload(model_path, f"{cache_key}.pkl")

    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
    metadata = {
        "model_name": model_name,
        "params": params,
        "data_hash": data_hash,
        "metrics": metrics,
    }
    cache.put_json(f"{cache_key}_metadata.json", metadata)

    return model_uri
